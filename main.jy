# SPECIALISED CZI STITCHER v37.5 - UNIFIED WORKING VERSION
# Consolidated from all working versions to prevent regression
#
# ============================================================================
# FILE PLACEMENT: IMPORTANT!
# ============================================================================
# This script requires metadata_correction.py to be in the SAME DIRECTORY
#
# Correct placement:
#   /your/scripts/folder/main.jy                    <-- This file
#   /your/scripts/folder/metadata_correction.py     <-- Required module
#
# When you run this in Fiji, check the log window for:
#   SUCCESS: "[DEBUG] Metadata correction module loaded successfully"
#   ERROR:   "[DEBUG] Metadata correction module not available: ..."
#
# If you see the error, metadata_correction.py is not in the same folder!
# ============================================================================
#
# PROVEN WORKING COMPONENTS EXTRACTED FROM:
# - v31.16h: Dual 2D/3D stitching workflow, thread pool execution
# - v34.8:   Bug fixes for UTF-8, booleans, pixel size correction
# - v36.5:   LUT detection (RGBA format), single-pass metadata
# - v37.5:   Path selection improvements, z-projection, garbage collection
#
# DESIGN PRINCIPLE: Only include code that is PROVEN to work in isolation
# NO experimental features - keep it simple and robust
#
# UNICODE SAFETY: Handles German characters gracefully (micro, umlaut, etc.)
# - All string literals use u"..." unicode prefix
# - ensure_unicode() for all external inputs
# - .format() instead of + for string concatenation
# - codecs.open() for file I/O with UTF-8 encoding
#
# METADATA CORRECTION SYSTEM:
# - Adaptive correction for stage positioning errors (backlash, scale, skew)
# - 12-state machine with empirical measurements
# - Per-microscope configuration with thermal state support
# - Enable via checkbox in parameter dialog (disabled by default)
# - See METADATA_CORRECTION_README.md for detailed documentation

import os, time, shutil, math, re, sys, json, codecs
from java.lang import Runtime, Thread, System
from java.awt import Color, BasicStroke
from java.util.concurrent import Executors, Callable
from ij import IJ, ImagePlus, WindowManager, CompositeImage
from ij.plugin import ZProjector, HyperStackConverter, ChannelSplitter, RGBStackMerge, Duplicator
from ij.process import LUT
from ij.gui import Roi, Overlay, TextRoi
from loci.plugins import BF
from loci.plugins.in import ImporterOptions, ImportProcess
from java.io import File
from ij.gui import GenericDialog
import jarray

# ==============================================================================
# VERSION AND CONFIGURATION
# ==============================================================================
VERSION = "v37.5"
MICRO = u"\u00b5"

# Debug flags - ALL ENABLED for maximum debugging
VERBOSE = True
LOG_TILE_POS = True
LUT_DEBUG = True
DUMP_DEBUG = True
DEBUG_METADATA = True
DEBUG_STITCHING = True
DEBUG_FILE_OPS = True
DEBUG_MEMORY = True
PLAY_JINGLE_ON_DONE = True

# Regular expressions (compiled once for performance)
FLOAT_RE = re.compile(r"([-+]?\d*\.\d+|[-+]?\d+)(?:[eE][-+]?\d+)?")
ATTR_RE = re.compile(r'([A-Za-z_:][-A-Za-z0-9_:.]*)="([^"]*)"')
STAGELABEL_RE = re.compile(r'<(?:[A-Za-z0-9_]+:)?StageLabel\b([^>]*)/?>', re.IGNORECASE)
_PIXELS_TAG_RE = re.compile(r'<Pixels\b([^>]*)>', re.IGNORECASE)
_PHYSICAL_X_RE = re.compile(r'PhysicalSizeX\s*=\s*"([^"]+)"', re.IGNORECASE)
_PHYSICAL_XUNIT_RE = re.compile(r'PhysicalSizeXUnit\s*=\s*"([^"]+)"', re.IGNORECASE)
_CHANNEL_COLOR_RE = re.compile(r'<(?:[A-Za-z0-9_]+:)?Channel\b([^>]*)>', re.IGNORECASE)

# Config file for remembering last used directories (unique name to avoid conflicts)
_CONFIG_PATH = os.path.join(os.path.expanduser("~"), ".specialised_czi_stitcher_config.json")

# ==============================================================================
# PART 1: UTILITY FUNCTIONS (from v31.16h + v34.8 bug fixes)
# ==============================================================================

def _load_config():
    """Load last used directories from config file (UTF-8 safe)"""
    logd(u"Loading config from: {}".format(_CONFIG_PATH))
    try:
        if os.path.exists(_CONFIG_PATH):
            with codecs.open(_CONFIG_PATH, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
                logd(u"Config loaded: {}".format(cfg))
                return cfg
        else:
            logd(u"Config file does not exist, using defaults")
    except Exception as e:
        logd(u"Config load failed: {}".format(e))
    return {}

def _save_config(cfg):
    """Save directories to config file (UTF-8 safe)"""
    logd(u"Saving config: {}".format(cfg))
    try:
        with codecs.open(_CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
            logd(u"Config saved successfully")
    except Exception as e:
        logd(u"Config save failed: {}".format(e))

def ensure_unicode(o):
    """Convert any object to unicode safely (v34.8 fix for German characters)"""
    if o is None:
        return None
    if isinstance(o, unicode):
        return o
    
    # Try multiple conversion strategies with debug logging
    try:
        result = unicode(bytearray(o.getBytes("UTF-8")), 'utf-8', 'replace')
        if DUMP_DEBUG and len(str(result)) > 50:
            logd(u"Unicode conversion (method 1) succeeded for: {}...".format(str(result)[:50]))
        return result
    except Exception as e1:
        if DUMP_DEBUG:
            logd(u"Unicode conversion method 1 failed: {}".format(e1))
    
    try:
        result = unicode(o, 'utf-8', 'replace')
        return result
    except Exception as e2:
        if DUMP_DEBUG:
            logd(u"Unicode conversion method 2 failed: {}".format(e2))
    
    try:
        result = unicode(str(o), 'utf-8', 'replace')
        return result
    except Exception as e3:
        if DUMP_DEBUG:
            logd(u"Unicode conversion method 3 failed: {}".format(e3))
    
    try:
        return u"%s" % o
    except:
        if DUMP_DEBUG:
            logd(u"Unicode conversion: all methods failed, returning empty string")
        return u""

def safe_unicode(o):
    """Safe unicode conversion with fallback"""
    try:
        return ensure_unicode(o)
    except:
        try:
            return unicode(o)
        except:
            try:
                return u"%s" % o
            except:
                return u"<unrepresentable>"

def log(msg):
    """Thread-safe logging with unicode support (v34.8 fix + enhanced for German chars)"""
    try:
        # Use .format() to avoid string concatenation encoding issues
        IJ.log(u"[CZI-Stitcher] {}".format(safe_unicode(msg)))
    except UnicodeEncodeError:
        # Fallback for extreme unicode issues
        try:
            IJ.log("[CZI-Stitcher] <message contains unsupported characters>")
        except:
            pass
    except:
        try:
            IJ.log(str(msg))
        except:
            pass

def logv(msg):
    """Verbose logging"""
    if VERBOSE:
        log(u"[VERBOSE] {}".format(msg))

def logd(msg):
    """Debug logging"""
    if DUMP_DEBUG:
        log(u"[DEBUG] {}".format(msg))

def log_memory():
    """Log current memory usage"""
    if DEBUG_MEMORY:
        try:
            runtime = Runtime.getRuntime()
            total_mb = runtime.totalMemory() / (1024.0 * 1024.0)
            free_mb = runtime.freeMemory() / (1024.0 * 1024.0)
            used_mb = total_mb - free_mb
            max_mb = runtime.maxMemory() / (1024.0 * 1024.0)
            log(u"[MEMORY] Used: {:.1f}MB / Total: {:.1f}MB / Max: {:.1f}MB".format(used_mb, total_mb, max_mb))
        except Exception as e:
            logd(u"Memory logging failed: {}".format(e))

def get_safe_path(f):
    """Get safe file path as unicode (handles German chars)"""
    if f is None: 
        return u""
    try:
        # Get absolute path and ensure unicode
        path = f.getAbsolutePath()
        return ensure_unicode(path)
    except:
        try:
            return ensure_unicode(f)
        except:
            return u"<path>"

def find_floats(s):
    """Extract all float numbers from a string"""
    if s is None: 
        return []
    return [float(x) for x in FLOAT_RE.findall(u"{}".format(s))]

# ==============================================================================
# PART 2: METADATA EXTRACTION (from v31.16h + v36.5 improvements)
# ==============================================================================

def _parse_stagelabels_from_xml(xml):
    """Parse all StageLabel tags from OME-XML (v31.16h proven pattern)"""
    labels = []
    if not xml:
        return labels
    xml = ensure_unicode(xml)
    for m in STAGELABEL_RE.finditer(xml):
        attr_blob = m.group(1)
        attrs = dict(ATTR_RE.findall(attr_blob))
        name = attrs.get('Name') or attrs.get('name') or ""
        x_str = attrs.get('X') or attrs.get('x')
        y_str = attrs.get('Y') or attrs.get('y')
        z_str = attrs.get('Z') or attrs.get('z')
        xunit = attrs.get('XUnit') or attrs.get('xUnit') or attrs.get('xunit') or attrs.get('Xunit') or ""
        yunit = attrs.get('YUnit') or attrs.get('yUnit') or attrs.get('yunit') or ""
        zunit = attrs.get('ZUnit') or attrs.get('zUnit') or attrs.get('zunit') or ""
        try: 
            x = float(x_str) if x_str is not None else None
        except: 
            x = None
        try: 
            y = float(y_str) if y_str is not None else None
        except: 
            y = None
        try: 
            z = float(z_str) if z_str is not None else None
        except: 
            z = None
        labels.append({
            'name': name, 'x': x, 'y': y, 'z': z, 
            'xunit': xunit, 'yunit': yunit, 'zunit': zunit, 
            'raw_attrs': attrs
        })
    return labels

def _parse_pixels_physicalsize_from_xml(ome_xml):
    """Parse pixel physical size from OME-XML (v31.16h)"""
    if not ome_xml:
        return None, ""
    ome_xml = ensure_unicode(ome_xml)
    m = _PIXELS_TAG_RE.search(ome_xml)
    if m:
        attrs = m.group(1)
        pat = re.compile(r'PhysicalSizeX\s*=\s*"([^"]+)"', re.IGNORECASE)
        mm = pat.search(attrs)
        px = float(mm.group(1)) if mm else None
        um = re.search(r'PhysicalSizeXUnit\s*=\s*"([^"]+)"', attrs, re.IGNORECASE)
        unit_mm = um.group(1) if um else ""
        return px, unit_mm
    mxx = _PHYSICAL_X_RE.search(ome_xml)
    if mxx:
        val = float(mxx.group(1))
        um = _PHYSICAL_XUNIT_RE.search(ome_xml)
        unit = um.group(1) if um else ""
        return val, unit
    return None, ""

def _unit_to_um(value, unit):
    """Convert various units to micrometers (v31.16h)"""
    if value is None:
        return None
    if not unit:
        return float(value)
    
    # Ensure unit is unicode string to handle micro symbol safely
    try:
        u = ensure_unicode(unit).strip().lower()
    except:
        # If unicode conversion fails, try as-is
        try:
            u = unit.strip().lower()
        except:
            return float(value)
    
    # Replace all variants of micro symbol
    u = u.replace('micro', 'um').replace(u'\u00b5', 'um').replace(u'\u03bc', 'um').replace('\xc3\x82\xc2\xb5','um')
    
    if u in ('um', u'\u00b5m', u'\u03bcm', '\xc3\x82\xc2\xb5m', 'm'): 
        # Check for meters vs micrometers
        if u == 'm':
            return float(value) * 1e6
        return float(value)
    if u == 'cm': 
        return float(value) * 1e4
    if u == 'mm': 
        return float(value) * 1e3
    if u in ('nm',): 
        return float(value) * 1e-3
    if u in ('pm',): 
        return float(value) * 1e-6
    if 'meter' in u or 'metre' in u:
        if 'micrometer' in u or 'micron' in u: 
            return float(value)
        return float(value) * 1e6
    return float(value)

def _pixel_from_global_metadata(gMeta):
    """Extract pixel size from global metadata (v31.16h fallback)"""
    if not gMeta:
        return None, None
    cams = []
    generic = []
    for k in gMeta.keySet():
        try:
            keystr = safe_unicode(k)
            val = safe_unicode(gMeta.get(k))
        except:
            continue
        lkey = keystr.lower()
        nums = find_floats(val)
        nums = [n for n in nums if n > 0]
        if not nums:
            continue
        if "camerapixeldistance" in lkey or "camerapixeldistances" in lkey:
            cams.extend(nums)
        elif ("pixel" in lkey and "dist" in lkey) or ("pixel" in lkey and "size" in lkey) or ("physicalsizex" in lkey):
            generic.extend(nums)
    
    def pick_min_med(lst):
        if not lst: 
            return None, None
        lst = [c for c in lst if 0.01 <= c <= 50.0]
        if not lst: 
            return None, None
        lst.sort()
        mid = len(lst)//2
        med = lst[mid] if len(lst)%2==1 else 0.5*(lst[mid-1]+lst[mid])
        return lst[0], med
    
    cam_min, cam_med = pick_min_med(cams)
    gen_min, gen_med = pick_min_med(generic)
    if cam_med is not None:
        return cam_min, cam_med
    if gen_min is not None:
        return gen_min, gen_med
    return None, None

def get_pixel_size_um_strict(ome_xml, omeMeta, reader, gMeta):
    """Get pixel size in micrometers with fallback chain (v31.16h + v34.8 fix)"""
    logd(u"=== PIXEL SIZE EXTRACTION START ===")
    try:
        ome_xml = ensure_unicode(ome_xml)
        if ome_xml:
            logd(u"OME-XML length: {} characters".format(len(ome_xml)))
    except Exception as e:
        logd(u"OME-XML unicode conversion failed: {}".format(e))
        ome_xml = ome_xml
    
    # Priority: OME metadata object (method 1 removed - always failed with Unicode errors)
    logd(u"Attempting OME metadata object extraction")
    try:
        if omeMeta is not None:
            logd(u"  OMEMeta object is available")
            q = omeMeta.getPixelsPhysicalSizeX(0)
            logd(u"  getPixelsPhysicalSizeX returned: {}".format(q))
            if q is not None and q.value() is not None:
                # q.value() returns a Java Number object
                try:
                    v = float(q.value().doubleValue())
                except AttributeError:
                    # If q.value() is already a Python float/int
                    v = float(q.value())
                logd(u"  Raw value: {}".format(v))
                if abs(v) < 1e-3:
                    v_um = v * 1e6
                    log(u"Pixel size from OME metadata (meters->um): {} um".format(v_um))
                    logd(u"=== PIXEL SIZE EXTRACTION END (success) ===")
                    return float(v_um)
                else:
                    log(u"Pixel size from OME metadata (assumed um): {} um".format(v))
                    logd(u"=== PIXEL SIZE EXTRACTION END (success) ===")
                    return float(v)
            else:
                logd(u"  Query returned None")
        else:
            logd(u"  OMEMeta object is None")
    except Exception as e:
        logd(u"  Method 2 exception: {}".format(e))
    
    # Priority 3: Reader metadata store
    try:
        if reader is not None:
            md = reader.getMetadataStore()
            mdxml = None
            try:
                mdxml = md.dumpXML()
            except:
                try:
                    mdxml = md.toString()
                except:
                    mdxml = None
            if mdxml:
                mdxml = ensure_unicode(mdxml)
                m = re.search(r'PhysicalSizeX\s*=\s*"([^"]+)"', mdxml, re.IGNORECASE)
                if m:
                    val = float(m.group(1))
                    um = re.search(r'PhysicalSizeXUnit\s*=\s*"([^"]+)"', mdxml, re.IGNORECASE)
                    unitm = um.group(1) if um else ""
                    px_um = _unit_to_um(val, unitm)
                    log(u"Pixel size from reader metadata store: {} um".format(px_um))
                    return float(px_um)
    except:
        pass
    
    # Priority 4: Global metadata (with v34.8 fix - don't auto-apply correction factor)
    logd(u"Attempting method 4: Global metadata")
    cam_min, cam_med = _pixel_from_global_metadata(gMeta)
    logd(u"  Global metadata candidates - min: {}, median: {}".format(cam_min, cam_med))
    if cam_med is not None:
        log(u"Pixel size candidate (median) from global metadata: {} um (MAY NEED CORRECTION)".format(cam_med))
        if cam_min is not None and abs(cam_min - cam_med) > 1e-6:
            logd(u"  Pixel size candidate (min) from global metadata: {} um".format(cam_min))
        logd(u"=== PIXEL SIZE EXTRACTION END (success, method 4) ===")
        return float(cam_med)
    
    # Default fallback
    log(u"Pixel size not found in any source; defaulting to 0.345 um (FALLBACK)")
    logd(u"=== PIXEL SIZE EXTRACTION END (fallback default) ===")
    return 0.345

def _parse_stage_labels_list_from_xml(ome_xml):
    """Parse stage labels as simple list (v31.16h)"""
    labs = _parse_stagelabels_from_xml(ome_xml)
    out = []
    for L in labs:
        out.append((L.get('name', ''), L.get('x', None), L.get('y', None), L.get('xunit',''), L.get('yunit','')))
    return out

def try_ome_stage_labels_from_xml(xml, reader, series_index):
    """Try to get stage label position for specific series (v31.16h)"""
    if not xml: 
        return None
    xml = ensure_unicode(xml)
    labels = _parse_stagelabels_from_xml(xml)
    if not labels: 
        return None
    idx = series_index + 1
    for lab in labels:
        nm = lab.get('name', '') or ""
        if ("#{}".format(idx) in nm) or (re.search(r'\b{}$'.format(idx), nm)):
            return lab.get('x'), lab.get('y'), "StageLabel-Name-match"
    try:
        s_count = reader.getSeriesCount()
    except:
        s_count = None
    if s_count and len(labels) == s_count:
        lab = labels[series_index]
        return lab.get('x'), lab.get('y'), "StageLabel-order-map"
    if len(labels) > 0 and series_index < len(labels):
        lab = labels[series_index]
        return lab.get('x'), lab.get('y'), "StageLabel-best-effort-index"
    return None

# ==============================================================================
# PART 3: LUT/COLOR DETECTION (from v36.5 - RGBA format, first image only)
# ==============================================================================

def parse_channel_colors_from_ome_xml(ome_xml):
    """Parse channel colors from OME-XML (v36.5 fix: first image only, RGBA format)
    
    Only extracts colors from the first <Image> element to avoid
    duplicates when multiple images/series are present.
    """
    logd(u"=== PARSING CHANNEL COLORS FROM OME-XML ===")
    colors = []
    if not ome_xml:
        logd(u"  OME-XML is None, returning empty colors list")
        return colors
    xml = ensure_unicode(ome_xml)
    logd(u"  OME-XML length: {} characters".format(len(xml)))
    
    # Find the first <Image> element
    image_match = re.search(r'<(?:[A-Za-z0-9_]+:)?Image\b[^>]*>(.*?)</(?:[A-Za-z0-9_]+:)?Image>', xml, re.IGNORECASE | re.DOTALL)
    if image_match:
        logd(u"  Found <Image> tag, searching within first image only")
        # Only search for channels within the first image
        image_content = image_match.group(1)
        channel_count = 0
        for m in _CHANNEL_COLOR_RE.finditer(image_content):
            attrs = dict(ATTR_RE.findall(m.group(1)))
            c = attrs.get('Color') or attrs.get('color')
            logd(u"  Channel {} raw color value: {}".format(channel_count, c))
            if c:
                try: 
                    color_int = int(c)
                    colors.append(color_int)
                    logd(u"    Parsed as signed int: {}".format(color_int))
                except (ValueError, TypeError):
                    try: 
                        color_int = int(c,0)
                        colors.append(color_int)
                        logd(u"    Parsed with base detection: {}".format(color_int))
                    except (ValueError, TypeError) as e:
                        logd(u"    Failed to parse: {}".format(e))
            channel_count += 1
    else:
        logd(u"  No <Image> tag found, searching all Channel tags (fallback)")
        # Fallback: search all Channel tags if no Image tag found
        channel_count = 0
        for m in _CHANNEL_COLOR_RE.finditer(xml):
            attrs = dict(ATTR_RE.findall(m.group(1)))
            c = attrs.get('Color') or attrs.get('color')
            logd(u"  Channel {} raw color value: {}".format(channel_count, c))
            if c:
                try: 
                    color_int = int(c)
                    colors.append(color_int)
                    logd(u"    Parsed as signed int: {}".format(color_int))
                except (ValueError, TypeError):
                    try: 
                        color_int = int(c,0)
                        colors.append(color_int)
                        logd(u"    Parsed with base detection: {}".format(color_int))
                    except (ValueError, TypeError) as e:
                        logd(u"    Failed to parse: {}".format(e))
            channel_count += 1
    
    logd(u"  Total colors found: {}".format(len(colors)))
    logd(u"=== CHANNEL COLOR PARSING COMPLETE ===")
    return colors

def extract_channel_colors_from_gmeta(gMeta):
    """Extract channel colors from global metadata (v36.5)
    
    Looks for keys containing 'channel' and 'color' or similar patterns
    that indicate color information per channel.
    """
    colors = []
    if not gMeta:
        return colors
    
    # Try to find channel color information in global metadata
    color_map = {}
    try:
        for k in gMeta.keySet():
            try:
                keystr = safe_unicode(k)
                val = safe_unicode(gMeta.get(k))
            except (AttributeError, TypeError):
                continue
            
            lkey = keystr.lower()
            
            # Look for keys that contain channel and color information
            if ('channel' in lkey or 'ch' in lkey) and 'color' in lkey:
                # Try to extract channel index
                match = re.search(r'(\d+)', keystr)
                if match:
                    ch_idx = int(match.group(1))
                    # Try to parse the color value
                    try:
                        # Could be hex string or integer
                        if val.startswith('#'):
                            color_int = int(val[1:], 16)
                        elif val.startswith('0x'):
                            color_int = int(val, 16)
                        else:
                            color_int = int(val)
                        color_map[ch_idx] = color_int
                    except (ValueError, TypeError, AttributeError):
                        pass
    except Exception as e:
        logv(u"extract_channel_colors_from_gmeta error: {}".format(e))
    
    # Convert to ordered list
    if color_map:
        max_idx = max(color_map.keys())
        for i in range(max_idx + 1):
            if i in color_map:
                colors.append(color_map[i])
    
    return colors

def _hex_to_rgb(hexstr):
    """Convert hex string to RGB tuple (v31.16h)"""
    if not hexstr:
        return None
    s = hexstr.strip()
    if s.startswith('#'):
        s = s[1:]
    if len(s) == 6:
        r = int(s[0:2], 16)
        g = int(s[2:4], 16)
        b = int(s[4:6], 16)
    elif len(s) == 8:
        r = int(s[2:4], 16)
        g = int(s[4:6], 16)
        b = int(s[6:8], 16)
    else:
        try:
            r = int(s[-6:-4], 16)
            g = int(s[-4:-2], 16)
            b = int(s[-2:], 16)
        except:
            return None
    return (r, g, b)

def build_lut_from_rgb(rgb):
    """Build ImageJ LUT from RGB tuple (v31.16h + v36.5 array.array fix)"""
    if rgb is None:
        logd(u"  build_lut_from_rgb: rgb is None, returning None")
        return None
    
    R, G, B = rgb
    logd(u"  Building LUT from RGB({}, {}, {})".format(R, G, B))
    
    r_arr = [int(round((i/255.0)*R)) for i in range(256)]
    g_arr = [int(round((i/255.0)*G)) for i in range(256)]
    b_arr = [int(round((i/255.0)*B)) for i in range(256)]
    
    def to_signed_byte_list(lst):
        out = []
        for v in lst:
            out.append(v-256 if v>127 else v)
        return out
    
    rb = jarray.array(to_signed_byte_list(r_arr), 'b')
    gb = jarray.array(to_signed_byte_list(g_arr), 'b')
    bb = jarray.array(to_signed_byte_list(b_arr), 'b')
    
    logd(u"  Created Java byte arrays (length={})".format(len(rb)))
    
    try:
        lut = LUT(rb, gb, bb)
        logd(u"  LUT created successfully")
        return lut
    except Exception as e:
        logd(u"  LUT creation failed: {}".format(e))
        return None

def apply_channel_luts_to_image(imp, ome_xml, gMeta):
    """Apply channel LUTs to image (v37.1 FIX: Prevents double-wrapping CompositeImage)"""
    logd(u"=== APPLYING CHANNEL LUTS ===")
    
    if imp is None:
        logd(u"  Image is None, returning")
        return imp
    
    logd(u"  Image: {} channels, {} slices, stack size={}".format(
        imp.getNChannels(), imp.getNSlices(), imp.getStackSize()))
    
    colors_ome = parse_channel_colors_from_ome_xml(ome_xml)
    colors_gm = extract_channel_colors_from_gmeta(gMeta)
    colors = []
    
    # Prefer OME if present, else gMeta
    if colors_ome:
        colors = colors_ome
        logd(u"  Using OME-XML colors (preferred)")
    elif colors_gm:
        colors = colors_gm
        logd(u"  Using global metadata colors (fallback)")
    else:
        logd(u"  No colors found in either source")
    
    if LUT_DEBUG:
        log(u"LUT Debug: OME colors={}, GM colors={}, chosen={}".format(colors_ome, colors_gm, colors))
    
    # Build luts from colors (RGBA format: RR GG BB AA)
    logd(u"  Building LUTs from colors...")
    luts = []
    if colors and isinstance(colors[0], int):
        logd(u"  Colors are integers (RGBA format expected)")
        for i, ci in enumerate(colors):
            logd(u"  Channel {}: raw int = {}".format(i, ci))
            # Convert signed to unsigned 32-bit
            u = int(ci) & 0xFFFFFFFF
            hex8 = "%08X" % u
            logd(u"    As unsigned hex: 0x{}".format(hex8))
            
            # RGBA format: RR GG BB AA
            # Bytes: [0:2]=Red, [2:4]=Green, [4:6]=Blue, [6:8]=Alpha
            R = int(hex8[0:2], 16)
            G = int(hex8[2:4], 16)
            B = int(hex8[4:6], 16)
            A = int(hex8[6:8], 16)
            logd(u"    Parsed RGBA: R={}, G={}, B={}, A={}".format(R, G, B, A))
            
            rgb = (R, G, B)
            logd(u"    Using RGB tuple: {}".format(rgb))
            lut = build_lut_from_rgb(rgb)
            if lut: 
                luts.append(lut)
                logd(u"    LUT added successfully")
            else:
                logd(u"    LUT creation failed")
    else:
        logd(u"  Colors are not integers (hex string format?)")
        for i, c in enumerate(colors):
            logd(u"  Channel {}: {}".format(i, c))
            rgb = _hex_to_rgb(c)
            logd(u"    Converted to RGB: {}".format(rgb))
            lut = build_lut_from_rgb(rgb)
            if lut: 
                luts.append(lut)
                logd(u"    LUT added successfully")
            else:
                logd(u"    LUT creation failed")
    
    if LUT_DEBUG:
        log(u"LUT Debug: built {} LUTs from {} colors".format(len(luts), len(colors)))
    
    if not luts:
        logd(u"  No LUTs to apply, returning original image")
        logd(u"=== LUT APPLICATION COMPLETE (no LUTs) ===")
        return imp
    
    logd(u"  Attempting to apply {} LUTs to image...".format(len(luts)))
    
    # Multi-channel: Apply LUTs to CompositeImage
    if imp.getNChannels() > 1:
        try:
            # Create CompositeImage if not already one
            # HyperStackConverter.toHyperStack() creates a basic HyperStack, NOT a CompositeImage
            # We need to explicitly create CompositeImage to enable per-channel LUTs
            if imp.isComposite():
                logd(u"  Image is ALREADY a CompositeImage. Using existing instance.")
                cimp = imp
            else:
                logd(u"  Image is HyperStack. Creating CompositeImage for custom LUTs.")
                cimp = CompositeImage(imp, CompositeImage.COMPOSITE)
            
            # Force mode to COMPOSITE (required for custom LUTs)
            cimp.setMode(CompositeImage.COMPOSITE)
            logd(u"  CompositeImage mode set to COMPOSITE")
            
            nchan = cimp.getNChannels()
            logd(u"  CompositeImage has {} channels".format(nchan))
            
            for i in range(min(nchan, len(luts))):
                logd(u"  Applying LUT to channel {}".format(i+1))
                try: 
                    # Set position to ensure we are targeting the right channel processor
                    cimp.setPosition(i+1, 1, 1)
                    cimp.setChannelLut(luts[i], i+1)
                    logd(u"    setChannelLut succeeded")
                except Exception as e1:
                    logd(u"    setChannelLut failed: {}".format(e1))
            
            logd(u"  Calling updateAllChannelsAndDraw on CompositeImage")
            cimp.updateAllChannelsAndDraw()
            logd(u"  Returning CompositeImage (SUCCESS)")
            logd(u"=== LUT APPLICATION COMPLETE (CompositeImage) ===")
            return cimp
            
        except Exception as e:
            if LUT_DEBUG: 
                log(u"LUT Debug: multi-channel apply failed: {}".format(e))
            logd(u"  Multi-channel LUT application exception: {}".format(e))
            logd(u"  Returning original image (exception fallback)")
            logd(u"=== LUT APPLICATION COMPLETE (exception fallback) ===")
            return imp
    
    # Single channel: Apply color model
    else:
        logd(u"  Image is single channel")
        try:
            imp.getProcessor().setColorModel(luts[0].getColorModel())
            logd(u"  Set color model from first LUT")
            imp.updateAndDraw()
            logd(u"  updateAndDraw called")
            logd(u"=== LUT APPLICATION COMPLETE (single channel) ===")
            return imp
        except Exception as e:
            logd(u"  setColorModel failed: {}".format(e))
            logd(u"=== LUT APPLICATION COMPLETE (single channel fallback) ===")
            return imp

# ==============================================================================
# PART 4: METADATA CORRECTION SYSTEM (empirical measurements)
# ==============================================================================

# Import correction functions from separate module to avoid file size issues
try:
    import sys
    import os
    
    # Log where we're looking for the module (ALWAYS VISIBLE)
    script_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in dir() else os.getcwd()
    log(u"")
    log(u"Checking for metadata_correction.py in: {}".format(script_dir))
    module_path = os.path.join(script_dir, 'metadata_correction.py')
    log(u"metadata_correction.py exists: {}".format(os.path.exists(module_path)))
    
    # Add script directory to sys.path if not already there
    if script_dir not in sys.path:
        sys.path.insert(0, script_dir)
        log(u"Added {} to sys.path".format(script_dir))
    
    log(u"Attempting to import metadata_correction module...")
    import metadata_correction as mc
    create_default_correction_matrix = mc.create_default_correction_matrix
    create_movement_state = mc.create_movement_state
    apply_metadata_corrections = mc.apply_metadata_corrections
    visualize_grid_layout = mc.visualize_grid_layout
    METADATA_CORRECTION_AVAILABLE = True
    log(u"[SUCCESS] Metadata correction module loaded successfully")
    log(u"")
except Exception as e:
    import traceback
    log(u"")
    log(u"[ERROR] Metadata correction module not available: {}".format(e))
    log(u"[ERROR] Full traceback:")
    for line in traceback.format_exc().split('\n'):
        log(u"  {}".format(line))
    log(u"[WARNING] Using stub functions - corrections will NOT be applied")
    log(u"")
    METADATA_CORRECTION_AVAILABLE = False
    
    # Fallback: create stub functions with correct signatures
    def create_default_correction_matrix(microscope_id='default'):
        return {'enabled': False, 'microscope_id': microscope_id}
    
    def create_movement_state():
        return {'prev_x': None, 'prev_y': None, 'prev_dir_x': None, 'prev_dir_y': None, 
                'prev_state': None, 'tiles_processed': 0, 'first_y_negative_done': False}
    
    def apply_metadata_corrections(tile_x_um, tile_y_um, tile_index, tile_width_um, tile_height_um,
                                    correction_matrix, movement_state):
        return tile_x_um, tile_y_um, 'disabled'
    
    def visualize_grid_layout(tiles, grid_width, grid_height):
        return []


def _load_correction_matrix(cfg, microscope_id='default'):
    """Load correction matrix from config file"""
    default_matrix = create_default_correction_matrix(microscope_id)
    
    if 'metadata_correction' not in cfg:
        logd(u"No metadata_correction in config, using defaults")
        return default_matrix
    
    mc = cfg['metadata_correction']
    if microscope_id not in mc:
        logd(u"No correction matrix for microscope '{}', using defaults".format(microscope_id))
        return default_matrix
    
    loaded = mc[microscope_id]
    for key in default_matrix:
        if key not in loaded:
            loaded[key] = default_matrix[key]
    
    logd(u"Loaded correction matrix for microscope: {}".format(microscope_id))
    return loaded


def _save_correction_matrix(cfg, correction_matrix):
    """Save correction matrix to config file"""
    microscope_id = correction_matrix.get('microscope_id', 'default')
    
    if 'metadata_correction' not in cfg:
        cfg['metadata_correction'] = {}
    
    cfg['metadata_correction'][microscope_id] = correction_matrix
    
    logd(u"Saved correction matrix for microscope: {}".format(microscope_id))
    _save_config(cfg)

# ==============================================================================
# PART 5: STITCHING SUPPORT (from v31.16h)
# ==============================================================================

def suggest_stitcher_thresholds(tile_width_px, tile_height_px, avg_disp_px):
    """Calculate suggested stitching thresholds (v31.16h)"""
    ox = max(0.0, 1.0 - (avg_disp_px / float(tile_width_px)))
    oy = max(0.0, 1.0 - (avg_disp_px / float(tile_height_px)))
    avg_overlap = (ox + oy) / 2.0
    if avg_overlap >= 0.6: 
        reg = 0.3
    elif avg_overlap >= 0.4: 
        reg = 0.25
    elif avg_overlap >= 0.2: 
        reg = 0.18
    else: 
        reg = 0.12
    max_disp = max(tile_width_px, tile_height_px) * 0.5
    return {
        'avg_overlap': avg_overlap, 
        'suggested_regression_threshold': reg, 
        'suggested_max_disp_px': max_disp
    }

def get_full_res_series_indices(reader):
    """Get indices of full-resolution series (v31.16h)"""
    try:
        counts = []
        total = reader.getSeriesCount()
        for s in range(total):
            sx, sy = None, None
            try:
                sx = int(reader.getSizeX(s))
                sy = int(reader.getSizeY(s))
            except:
                try:
                    md = reader.getMetadataStore()
                    sx = int(md.getPixelsSizeX(s).getValue().doubleValue())
                    sy = int(md.getPixelsSizeY(s).getValue().doubleValue())
                except:
                    sx, sy = 0, 0
            counts.append((s, sx, sy))
        if not counts:
            return []
        max_area = max([x*y for (_, x, y) in counts])
        full = [s for (s, x, y) in counts if x*y == max_area]
        full.sort()
        return full
    except Exception as e:
        log(u"get_full_res_series_indices failed: {}".format(e))
        try:
            return list(range(reader.getSeriesCount()))
        except:
            return []

# ==============================================================================
# PART 5: TILE WORKER (from v31.16h - proven thread pool pattern)
# ==============================================================================

class TileWorker(Callable):
    """Worker thread for processing individual tiles (v31.16h)"""
    def __init__(self, czi_path, series_index, x, y, out_dir, rb_radius):
        self.czi_path = czi_path
        self.i = int(series_index)
        self.x = float(x)
        self.y = float(y)
        self.out_dir = out_dir
        self.rb_radius = int(rb_radius)
    
    def call(self):
        try:
            opts = ImporterOptions()
            opts.setId(self.czi_path)
            opts.setSeriesOn(self.i, True)
            opts.setGroupFiles(False)
            opts.setQuiet(True)
            opts.setWindowless(True)
            ims = BF.openImagePlus(opts)
            imp = ims[0]
            
            # Rolling ball background subtraction if enabled
            if self.rb_radius > 0:
                try:
                    IJ.run(imp, "Subtract Background...", "radius=" + str(self.rb_radius) + " stack")
                except Exception as e:
                    logv(u"Background subtraction failed for series {}: {}".format(self.i, e))
            
            # Save 3D stack
            nr = u"S{:03d}_3D.tif".format(self.i)
            try:
                IJ.saveAs(imp, "Tiff", os.path.join(self.out_dir, nr))
                logd(u"  Saved 3D stack: {}".format(nr))
            except Exception as e:
                log(u"  !!! CRITICAL: Failed to save 3D stack for series {}: {}".format(self.i, e))
                raise  # Re-raise because we can't continue without the 3D stack
            
            # Create and save 2D MIP for registration
            zp = ZProjector(imp)
            zp.setMethod(ZProjector.MAX_METHOD)
            zp.doProjection()
            mip = zp.getProjection()
            nm = u"S{:03d}_MIP.tif".format(self.i)
            try:
                if mip.getNChannels() > 1:
                    mip.setC(1)
                    t_mip = ImagePlus("MIP", mip.getProcessor())
                    IJ.saveAs(t_mip, "Tiff", os.path.join(self.out_dir, nm))
                    t_mip.close()
                else:
                    IJ.saveAs(mip, "Tiff", os.path.join(self.out_dir, nm))
            except Exception as e:
                logv(u"Saving MIP failed for series {}: {}".format(self.i, e))
            
            d = imp.getDimensions()
            
            try: 
                imp.close()
            except: 
                pass
            try: 
                mip.close()
            except: 
                pass
            
            return (nm, nr, self.x, self.y, d)
        except Exception as e:
            log(u"TileWorker series {} failed: {}".format(self.i, e))
            return None

# ==============================================================================
# PART 6: AUDIO FEEDBACK (from v31.16h)
# ==============================================================================

def play_clear_jingle():
    """Play completion jingle (v31.16h)"""
    try:
        from javax.sound.midi import MidiSystem
        syn = MidiSystem.getSynthesizer()
        syn.open()
        ch = syn.getChannels()[0]
        ch.programChange(11)
        noten = [64, 68, 72]
        laut = [100, 80, 60]
        for n, v in zip(noten, laut):
            ch.noteOn(n, v)
            ch.noteOn(n-20, max(0,v-10))
            ch.noteOn(n+10, max(0,v-10))
            time.sleep(0.2)
        time.sleep(4.0)
        for n in noten:
            ch.noteOff(n)
        syn.close()
    except Exception as e:
        logv(u"MIDI jingle failed: {}".format(e))

# ==============================================================================
# PART 7: FILE I/O HELPERS (from v31.16h)
# ==============================================================================

def get_original_omexml_str_and_reader(czi_path):
    """Get OME-XML and reader for CZI file (v31.16h)"""
    try:
        opts = ImporterOptions()
        opts.setId(czi_path)
        opts.setQuiet(True)
        opts.setGroupFiles(False)
        proc = ImportProcess(opts)
        proc.execute()
        try:
            xml = proc.getOMEXML()
        except:
            try:
                omeMeta = proc.getOMEMetadata()
                xml = omeMeta.dumpXML() if omeMeta is not None else None
            except:
                xml = None
        omeMeta = proc.getOMEMetadata()
        reader = proc.getReader()
        try:
            gMeta = reader.getGlobalMetadata()
        except:
            gMeta = {}
        if xml is not None:
            xml = ensure_unicode(xml)
        return xml, proc, omeMeta, reader, gMeta
    except Exception as e:
        log(u"get_original_omexml_str_and_reader failed: {}".format(e))
        return None, None, None, None, None

# ==============================================================================
# PART 9: MAIN STITCHER CLASS (from v31.16h - proven 2D->3D workflow)
# ==============================================================================

class UltimateStitcher:
    """Main stitcher class implementing proven 2D->3D workflow (v31.16h)"""
    
    def __init__(self, src, dst, t_limit, temp_root, fusion_method, rb_radius, reg_thresh, disp_thresh, 
                 do_show, do_save, do_clean, auto_adjust, corr_factor, correction_matrix):
        self.src = src
        self.dst = dst
        self.t_limit = t_limit
        self.temp_root = temp_root
        self.fusion_method = fusion_method
        self.rb_radius = rb_radius
        self.reg_thresh = reg_thresh
        self.disp_thresh = disp_thresh
        self.do_show = do_show
        self.do_save = do_save
        self.do_clean = do_clean
        self.auto_adjust = auto_adjust
        self.corr_factor = corr_factor
        self.correction_matrix = correction_matrix

    def process_file(self, czi_path):
        """Process single CZI file with proven 2D->3D stitching workflow"""
        # Ensure unicode path handling for German characters
        try:
            czi_path_unicode = ensure_unicode(czi_path)
        except Exception as e:
            logd(u"  Unicode conversion failed for path: {}".format(e))
            czi_path_unicode = czi_path
        
        base_name = os.path.splitext(os.path.basename(czi_path_unicode))[0]
        file_dst = os.path.join(self.temp_root, u"temp_{}".format(int(time.time())))
        if not os.path.exists(file_dst): 
            os.makedirs(file_dst)
        
        log(u"--- Processing: {} ---".format(base_name))

        ome_xml, proc, omeMeta, reader, gMeta = get_original_omexml_str_and_reader(czi_path)

        if reader is None:
            log(u"No reader available for {}; skipping.".format(base_name))
            if proc:
                try: 
                    proc.close()
                except: 
                    pass
            if self.do_clean:
                try: 
                    shutil.rmtree(file_dst)
                except: 
                    pass
            return False

        # Get pixel size (v34.8 fix: only apply correction if not from OME-XML)
        px_um = get_pixel_size_um_strict(ome_xml, omeMeta, reader, gMeta)
        try:
            cf = float(self.corr_factor)
        except Exception as e:
            logd(u"  Invalid correction factor, using default 10.0: {}".format(e))
            cf = 10.0
        
        # v34.8: Only apply correction factor if pixel size is NOT from OME-XML
        if px_um and 0.01 <= px_um <= 50.0:
            # Pixel size from OME-XML is already correct
            px_um_eff = px_um
            if cf != 1.0:
                log(u"px = {} um (from XML, correction factor NOT applied)".format(px_um_eff))
            else:
                log(u"px = {} um".format(px_um_eff))
        else:
            # Pixel size from fallback methods, apply correction factor
            px_um_eff = px_um / cf if cf != 1.0 else px_um
            if cf != 1.0:
                log(u"px = {} um, corr_factor {}, effective = {} um (fallback)".format(
                    px_um, cf, px_um_eff))
            else:
                log(u"px = {} um".format(px_um_eff))

        try:
            full_res_indices = get_full_res_series_indices(reader)
        except Exception as e:
            logv(u"Failed to determine full-res series: {}".format(e))
            full_res_indices = list(range(reader.getSeriesCount() or 0))

        stage_labels = _parse_stage_labels_list_from_xml(ome_xml)
        series_to_label = {}
        if stage_labels and len(stage_labels) == len(full_res_indices):
            for idx, s in enumerate(full_res_indices):
                name, x_um, y_um, xu, yu = stage_labels[idx]
                series_to_label[s] = (x_um, y_um, "StageLabel-order-map")
        else:
            for s in full_res_indices:
                sl = None
                try:
                    sl = try_ome_stage_labels_from_xml(ome_xml, reader, s)
                except Exception as e:
                    logd(u"  Stage label extraction failed for series {}: {}".format(s, e))
                    sl = None
                if sl:
                    series_to_label[s] = (sl[0], sl[1], sl[2])
                else:
                    series_to_label[s] = (None, None, None)

        tiles = []
        fx = []
        fy = []
        for s in full_res_indices:
            x_s, y_s, m = series_to_label.get(s,(None,None,None))
            if x_s is None: 
                x_s = 0.0
            if y_s is None: 
                y_s = 0.0
            if m is None: 
                m = "fallback-zero"
            tiles.append({'i': s, 'x_s': x_s, 'y_s': y_s, 'method': m})
            fx.append(x_s)
            fy.append(y_s)
            if LOG_TILE_POS:
                log(u"Series {} -> raw pos ({}, {}) via {}".format(s, x_s, y_s, m))

        # Apply metadata corrections if enabled
        if METADATA_CORRECTION_AVAILABLE and self.correction_matrix and self.correction_matrix.get('enabled', False):
            try:
                log(u"")
                log(u"=== APPLYING METADATA CORRECTIONS ===")
                log(u"  Microscope: {}".format(self.correction_matrix.get('microscope_id', 'default')))
                log(u"  Thermal state: {}".format(self.correction_matrix.get('thermal_state', 'unknown')))
                
                # Estimate grid dimensions from tile positions
                # Calculate typical spacing between tiles to infer grid structure
                try:
                    if len(tiles) > 1:
                        # Get all positions
                        positions = [(t['x_s'], t['y_s']) for t in tiles]
                        
                        # Find unique X and Y coordinates (with small tolerance for rounding)
                        tolerance = px_um_eff * 10  # 10 pixels tolerance
                        unique_x = []
                        unique_y = []
                        
                        for x, y in positions:
                            # Check if this X is new (not close to any existing)
                            if not any(abs(x - ux) < tolerance for ux in unique_x):
                                unique_x.append(x)
                            # Check if this Y is new
                            if not any(abs(y - uy) < tolerance for uy in unique_y):
                                unique_y.append(y)
                        
                        grid_width = len(unique_x)
                        grid_height = len(unique_y)
                        
                        logd(u"")
                        logd(u"  Grid dimensions: {} x {} (estimated from {} tiles)".format(grid_width, grid_height, len(tiles)))
                        logd(u"")
                except Exception as e:
                    logd(u"  Grid dimension estimation failed: {}".format(e))
                    grid_width = 1
                    grid_height = len(tiles)
                
                # Apply corrections to each tile
                movement_state = create_movement_state()
                corrected_tiles = []
                state_sequence = []
                
                for idx, t in enumerate(tiles):
                    # Get tile dimensions (use reader to get actual dimensions)
                    try:
                        reader.setSeries(t['i'])
                        tile_width_px = reader.getSizeX()
                        tile_height_px = reader.getSizeY()
                        num_channels = reader.getSizeC()
                        num_z = reader.getSizeZ()
                    except:
                        tile_width_px = 1216  # Default fallback
                        tile_height_px = 1028
                        num_channels = 1
                        num_z = 1
                    
                    # Convert tile dimensions from pixels to micrometers
                    tile_width_um = tile_width_px * px_um_eff
                    tile_height_um = tile_height_px * px_um_eff
                    
                    # Apply corrections (returns tuple: x_corrected, y_corrected, state_name)
                    x_corrected, y_corrected, state_name = apply_metadata_corrections(
                        t['x_s'], t['y_s'], 
                        idx,
                        tile_width_um, tile_height_um,
                        self.correction_matrix,
                        movement_state
                    )
                    
                    # Update tile with corrected position
                    t['x_s_orig'] = t['x_s']
                    t['y_s_orig'] = t['y_s']
                    t['x_s'] = x_corrected
                    t['y_s'] = y_corrected
                    t['correction_applied'] = True
                    t['movement_state'] = state_name
                    
                    state_sequence.append(state_name)
                    corrected_tiles.append(t)
                    
                    if LOG_TILE_POS:
                        dx = t['x_s'] - t['x_s_orig']
                        dy = t['y_s'] - t['y_s_orig']
                        log(u"Tile {}: ({:.2f}, {:.2f}) -> ({:.2f}, {:.2f}) [delta: ({:.2f}, {:.2f}) um] state: {}".format(
                            idx, t['x_s_orig'], t['y_s_orig'], t['x_s'], t['y_s'], dx, dy, state_name))
                
                # Log state sequence
                log(u"")
                log(u"  State Sequence: {}".format(", ".join(state_sequence)))
                log(u"  Corrections applied to {} tiles".format(len(corrected_tiles)))
                log(u"")
                
                # Update fx, fy with corrected positions
                fx = [t['x_s'] for t in tiles]
                fy = [t['y_s'] for t in tiles]
                
            except Exception as e:
                log(u"")
                log(u"ERROR: Metadata correction failed: {}".format(e))
                log(u"")
                import traceback
                log(u"Full Traceback:")
                for line in traceback.format_exc().split('\n'):
                    log(u"  {}".format(line))
                log(u"")
                log(u"Continuing with UNCORRECTED positions - corrections were NOT applied!")
                log(u"")
        else:
            # Log why corrections were skipped  
            if not self.correction_matrix or not self.correction_matrix.get('enabled', False):
                log(u"Metadata correction DISABLED in UI - using raw metadata positions")
            elif not METADATA_CORRECTION_AVAILABLE:
                log(u"Metadata correction module NOT AVAILABLE - using raw metadata positions")
        
        # Use first tile as reference (all positions relative to tile 0)
        ref_x = fx[0] if len(fx) > 0 else 0.0
        ref_y = fy[0] if len(fy) > 0 else 0.0
        for t in tiles:
            t['x'] = (t['x_s'] - ref_x) / px_um_eff
            t['y'] = (t['y_s'] - ref_y) / px_um_eff
        
        xs = [t['x'] for t in tiles]
        ys = [t['y'] for t in tiles]
        if xs and ys:
            log(u"Tiles: {} | px-range x=[{:.1f},{:.1f}] y=[{:.1f},{:.1f}]".format(
                len(tiles), min(xs), max(xs), min(ys), max(ys)))

        reg_local = self.reg_thresh
        disp_local = self.disp_thresh
        if self.auto_adjust and len(tiles) > 1:
            deltas = []
            for i in range(1, len(tiles)):
                dx = tiles[i]['x_s'] - tiles[i-1]['x_s']
                dy = tiles[i]['y_s'] - tiles[i-1]['y_s']
                deltas.append(math.hypot(dx, dy))
            if deltas:
                avg_sep_um = sum(deltas) / len(deltas)
                avg_sep_px = avg_sep_um / px_um_eff
                try:
                    sx = int(reader.getSizeX(0))
                    sy = int(reader.getSizeY(0))
                except:
                    sx, sy = 1216, 1028
                sug = suggest_stitcher_thresholds(sx, sy, avg_sep_px)
                reg_local = sug['suggested_regression_threshold']
                disp_local = sug['suggested_max_disp_px']
                log(u"Auto-adjust: avg_sep {:.1f}px, overlap {:.1%}, reg={}, max_disp={}".format(
                    avg_sep_px, sug['avg_overlap'], reg_local, disp_local))

        # Extract tiles using thread pool (v31.16h proven pattern)
        # Garbage collection before major processing step
        log_memory()
        System.gc()
        Thread.sleep(500)
        log(u"Garbage collection completed before tile extraction")
        log_memory()
        
        num_threads = min(self.t_limit, Runtime.getRuntime().availableProcessors())
        exc = Executors.newFixedThreadPool(num_threads)
        futs = [exc.submit(TileWorker(czi_path, t['i'], t['x'], t['y'], file_dst, self.rb_radius)) for t in tiles]
        exc.shutdown()
        while not exc.isTerminated():
            Thread.sleep(200)
        res = [f.get() for f in futs if f.get() is not None]

        if not res:
            log(u"No tile outputs were produced for {}. Skipping file.".format(base_name))
            try: 
                reader.close()
            except: 
                pass
            if proc:
                try: 
                    proc.close()
                except: 
                    pass
            if self.do_clean:
                try: 
                    shutil.rmtree(file_dst)
                except: 
                    pass
            return False

        if len(res) < 2:
            log(u"Only {} tile(s) for {} - skip stitching.".format(len(res), base_name))
            try:
                for r in res:
                    mip_name, nr = r[0], r[1]
                    src_mip = os.path.join(file_dst, mip_name)
                    src_3d = os.path.join(file_dst, nr)
                    try: 
                        shutil.copy(src_mip, os.path.join(self.dst, base_name + "_" + mip_name))
                    except: 
                        pass
                    try: 
                        shutil.copy(src_3d, os.path.join(self.dst, base_name + "_" + nr))
                    except: 
                        pass
            except Exception as e:
                logv(u"Copy single-tile outputs failed: {}".format(e))
            try: 
                reader.close()
            except: 
                pass
            if proc:
                try: 
                    proc.close()
                except: 
                    pass
            if self.do_clean:
                try: 
                    shutil.rmtree(file_dst)
                except: 
                    pass
            return True

        # Create tile configuration for 2D registration
        # The stitching plugin expects individual tile files in the directory
        # For 3D: each tile file is a complete z-stack (all channels, all slices)
        conf = os.path.join(file_dst, u"TileConfiguration.txt")
        
        if DEBUG_STITCHING:
            log(u"")
            log(u"=== CREATING TILE CONFIGURATION ===")
            log(u"  2D Configuration (for registration): {}".format(conf))
            log(u"  Number of tiles: {}".format(len(res)))
        
        with codecs.open(conf, 'w', encoding='utf-8') as f:
            f.write(u"dim = 2\n")
            for r in res:
                tile_line = u"{}; ; ({:.3f}, {:.3f})\n".format(r[0], r[2], r[3])
                f.write(tile_line)
                if DEBUG_STITCHING:
                    logd(u"    Tile: {} at ({:.1f}, {:.1f}) px".format(r[0], r[2], r[3]))
        
        if DEBUG_STITCHING:
            log(u"  2D TileConfiguration written")

        clean_dir = file_dst.replace(u"\\",u"/")
        
        if DEBUG_STITCHING:
            log(u"")
            log(u"=== STEP 1: 2D REGISTRATION ===")
            log(u"  Stitching 2D MIPs to compute tile positions...")
            log(u"  Fusion method: {}".format(self.fusion_method))
            log(u"  Regression threshold: {}".format(reg_local))
            log(u"  Max displacement: {}".format(disp_local))
        
        # Step 1: Stitch 2D MIPs for registration
        stitch_start = time.time()
        try:
            IJ.run("Grid/Collection stitching", 
                   "type=[Positions from file] order=[Defined by TileConfiguration] directory=[" + clean_dir + 
                   "] layout_file=TileConfiguration.txt fusion_method=[" + self.fusion_method + 
                   "] regression_threshold=" + str(reg_local) + 
                   " max/avg_displacement_threshold=" + str(disp_local) + 
                   " absolute_displacement_threshold=" + str(disp_local + 1.0) + 
                   " compute_overlap subpixel_accuracy image_output=[Fuse and display]")
            stitch_2d_time = time.time() - stitch_start
            if DEBUG_STITCHING:
                log(u"  2D registration completed in {:.1f} seconds".format(stitch_2d_time))
        except Exception as e:
            log(u"Stitching (2D) failed: {}".format(e))
            if DEBUG_STITCHING:
                import traceback
                logd(u"  Traceback:")
                for line in traceback.format_exc().split('\n'):
                    logd(u"    {}".format(line))

        if WindowManager.getCurrentImage(): 
            WindowManager.getCurrentImage().close()
        
        # Garbage collection after 2D registration
        log_memory()
        System.gc()
        Thread.sleep(500)
        log(u"Garbage collection completed after 2D registration")
        log_memory()

        # Step 2: Transfer registration to 3D configuration
        # CRITICAL: The stitching plugin needs 3D stacks (not 2D slices)
        # Each tile file (S000_3D.tif) contains the full z-stack with all channels
        # The (x, y, z) coordinates in TileConfiguration_3D.txt define:
        #   x, y: tile position in pixels (from 2D registration)
        #   z: always 0.0 (all tiles at same z-plane, stacks fused together)
        
        if DEBUG_STITCHING:
            log(u"")
            log(u"=== STEP 2: TRANSFER TO 3D ===")
            log(u"  Creating 3D configuration from 2D registration results...")
        
        final_conf = os.path.join(file_dst, u"TileConfiguration_3D.txt")
        reg_conf = os.path.join(file_dst, u"TileConfiguration.registered.txt")
        mip_to_3d = {r[0]: r[1] for r in res}
        src_c = reg_conf if os.path.exists(reg_conf) else conf

        def extract_xy_from_parentheses(s):
            try:
                a = s.index('(')
                b = s.index(')', a+1)
                inner = s[a+1:b]
                parts = [p.strip() for p in inner.split(',')]
                nums = []
                for p in parts:
                    m = FLOAT_RE.search(p)
                    if m: 
                        nums.append(m.group(0))
                    if len(nums) >= 2: 
                        break
                if len(nums) >= 2: 
                    return float(nums[0]), float(nums[1])
            except:
                pass
            return None

        # Parse registered configuration to detect failed alignments
        # Build tile position database with correlation scores and metadata predictions
        tile_positions = {}  # name -> {'xy': (x, y), 'correlation': R, 'failed': bool, 'predicted_xy': (px, py), 'movement_state': state}
        tile_count_parsed = 0
        
        with codecs.open(src_c, 'r', encoding='utf-8') as fr:
            for line in fr:
                if ".tif" in line and "(" in line and ")" in line:
                    xy = extract_xy_from_parentheses(line)
                    if xy is None:
                        continue
                    name = line.split(";")[0].strip()
                    
                    # Extract correlation score if present (format: "correlation (R)=0.8282859")
                    correlation = 1.0  # Default: assume success
                    if "correlation" in line and "=" in line:
                        try:
                            corr_part = line[line.index("correlation"):line.index(")", line.index("correlation"))]
                            corr_val = float(corr_part.split("=")[1].strip())
                            correlation = corr_val
                        except:
                            pass
                    
                    # Detect failed alignment: position (0.0, 0.0) indicates alignment failure
                    # Exception: Tile 0 is reference point and should be at (0, 0)
                    failed = (abs(xy[0]) < 0.01 and abs(xy[1]) < 0.01) and (tile_count_parsed > 0)
                    
                    # Store tile info
                    tile_positions[name] = {
                        'xy': xy,
                        'correlation': correlation,
                        'failed': failed,
                        'index': tile_count_parsed,
                        'predicted_xy': None,  # Will be filled from tiles[]
                        'movement_state': None,
                        'grid_pos': (0, 0)  # Will be filled from tiles[] if available
                    }
                    tile_count_parsed += 1
        
        # Link metadata predictions from tiles[] array (always store predictions, needed for fallback)
        # CRITICAL: Store raw metadata positions as fallback predictions
        # If corrections were applied, x_s/y_s contain corrected values
        # If corrections were NOT applied, x_s/y_s contain raw metadata (still useful for fallback!)
        for t in tiles:
            # Find corresponding MIP name for this tile
            mip_name = None
            for r in res:
                if r[2] == t['i']:  # Match series index
                    mip_name = r[0]
                    break
            
            if mip_name and mip_name in tile_positions:
                # ALWAYS store position as prediction (even if raw metadata, better than nothing!)
                # Convert from micrometers (stage coordinates) to pixels (image coordinates)
                pred_x = (t['x_s'] - ref_x) / px_um_eff
                pred_y = (t['y_s'] - ref_y) / px_um_eff
                tile_positions[mip_name]['predicted_xy'] = (pred_x, pred_y)
                tile_positions[mip_name]['movement_state'] = t.get('movement_state', 'UNKNOWN')
                tile_positions[mip_name]['grid_pos'] = (t.get('x_grid', 0), t.get('y_grid', 0))  # Store grid coordinates
        
        # Apply neighbor-constrained fallback for failed tiles
        failed_tiles = [name for name, info in tile_positions.items() if info['failed']]
        
        if len(failed_tiles) > 0:
            log(u"")
            log(u"=== NEIGHBOR-CONSTRAINED FALLBACK ===")
            log(u"  Detected {} failed tile alignment(s)".format(len(failed_tiles)))
            log(u"  Applying intelligent position recovery...")
            
            for failed_name in failed_tiles:
                failed_info = tile_positions[failed_name]
                failed_idx = failed_info['index']
                failed_grid = failed_info.get('grid_pos', (0, 0))
                
                log(u"")
                log(u"  [ANALYZING] Tile {} (idx {}, grid pos {})".format(failed_name, failed_idx, failed_grid))
                log(u"    Failed: {}, Correlation: {:.3f}".format(failed_info['failed'], failed_info['correlation']))
                log(u"    Has prediction: {}".format(failed_info['predicted_xy'] is not None))
                
                # Find confident neighbors (4-8 connectivity in grid)
                neighbors = []
                for cand_name, cand_info in tile_positions.items():
                    if cand_info['failed'] or cand_info['correlation'] < 0.3:
                        continue  # Skip unreliable tiles
                    
                    # Calculate grid distance (Manhattan distance if grid positions available)
                    cand_grid = cand_info.get('grid_pos', (0, 0))
                    if failed_grid != (0, 0) and cand_grid != (0, 0):
                        # Use grid-based distance (Manhattan)
                        grid_dist = abs(failed_grid[0] - cand_grid[0]) + abs(failed_grid[1] - cand_grid[1])
                        if grid_dist <= 2 and grid_dist > 0:  # Adjacent or near-adjacent in grid
                            neighbors.append((cand_name, cand_info, grid_dist))
                    else:
                        # Fallback to index-based distance
                        idx_dist = abs(cand_info['index'] - failed_idx)
                        if idx_dist <= 3 and idx_dist > 0:  # Wider search when no grid info
                            neighbors.append((cand_name, cand_info, max(idx_dist / 2.0, 1.0)))  # Scale down index distance
                
                log(u"    Found {} confident neighbors (R>0.3)".format(len(neighbors)))
                
                if len(neighbors) == 0:
                    log(u"    [NO NEIGHBORS] Cannot apply weighted correction")
                    # Use metadata prediction if available
                    if failed_info['predicted_xy']:
                        tile_positions[failed_name]['xy'] = failed_info['predicted_xy']
                        tile_positions[failed_name]['failed'] = False  # Mark as recovered
                        log(u"    [FALLBACK] Using pure metadata prediction: {}".format(failed_info['predicted_xy']))
                    else:
                        log(u"    [FAILED] No prediction available - tile remains at (0,0)")
                    continue
                
                # Calculate weighted position using inverse distance weighting
                if failed_info['predicted_xy']:
                    pred_x, pred_y = failed_info['predicted_xy']
                    log(u"    Metadata prediction: ({:.1f}, {:.1f})".format(pred_x, pred_y))
                    
                    # Compute weighted error correction from neighbors
                    total_weight = 0.0
                    weighted_error_x = 0.0
                    weighted_error_y = 0.0
                    
                    for neigh_name, neigh_info, distance in neighbors:
                        if not neigh_info['predicted_xy']:
                            log(u"      Neighbor {} skipped (no prediction)".format(neigh_name))
                            continue  # Skip if no prediction available
                        
                        # Calculate error: actual - predicted
                        error_x = neigh_info['xy'][0] - neigh_info['predicted_xy'][0]
                        error_y = neigh_info['xy'][1] - neigh_info['predicted_xy'][1]
                        
                        # Inverse distance weighting: w = (1/d) * correlation
                        weight = (1.0 / (distance * distance)) * neigh_info['correlation']
                        
                        # Movement-specific filtering: use errors from similar move types (more aggressive)
                        move_compat = 1.0
                        if failed_info['movement_state'] and neigh_info['movement_state']:
                            # Check if movements are compatible
                            failed_move = failed_info['movement_state']
                            neigh_move = neigh_info['movement_state']
                            
                            # Reduced penalty for mismatched movements (was 0.3, now 0.6 = more aggressive)
                            if ('RIGHT' in failed_move and 'RIGHT' not in neigh_move) or \
                               ('LEFT' in failed_move and 'LEFT' not in neigh_move):
                                move_compat *= 0.6  # Less strict penalty for mismatched X direction
                            
                            if ('DOWN' in failed_move and 'DOWN' not in neigh_move):
                                move_compat *= 0.6  # Less strict penalty for mismatched Y direction
                        
                        weight *= move_compat
                        
                        if DEBUG_STITCHING:
                            logd(u"      Neighbor {}: error=({:.1f},{:.1f}), dist={:.1f}, R={:.2f}, move_compat={:.2f}, weight={:.4f}".format(
                                neigh_name, error_x, error_y, distance, neigh_info['correlation'], move_compat, weight))
                        
                        weighted_error_x += weight * error_x
                        weighted_error_y += weight * error_y
                        total_weight += weight
                    
                    # Apply weighted correction
                    if total_weight > 0:
                        avg_error_x = weighted_error_x / total_weight
                        avg_error_y = weighted_error_y / total_weight
                        
                        log(u"    Weighted error correction: ({:+.1f}, {:+.1f})".format(avg_error_x, avg_error_y))
                        
                        # NO SAFETY LIMIT: Trust the weighted correction fully
                        # Having *some* fit from neighbors is always better than (0,0)
                        corrected_x = pred_x + avg_error_x
                        corrected_y = pred_y + avg_error_y
                        
                        tile_positions[failed_name]['xy'] = (corrected_x, corrected_y)
                        tile_positions[failed_name]['failed'] = False  # Mark as recovered
                        
                        # Calculate confidence
                        avg_correlation = sum(n[1]['correlation'] for n in neighbors) / len(neighbors)
                        confidence = avg_correlation * 0.75  # Reduce confidence for fallback
                        
                        log(u"    [SUCCESS] Final position: ({:.1f}, {:.1f}) [confidence: {:.2f}]".format(
                            corrected_x, corrected_y, confidence))
                    else:
                        # Fallback to pure prediction (all neighbors had no predictions)
                        tile_positions[failed_name]['xy'] = failed_info['predicted_xy']
                        tile_positions[failed_name]['failed'] = False
                        log(u"    [FALLBACK] No weighted neighbors available, using pure prediction")
                else:
                    log(u"    [FAILED] No metadata prediction available - tile remains at (0,0)")
            
            # Summary
            recovered_count = sum(1 for name in failed_tiles if not tile_positions[name]['failed'])
            log(u"")
            log(u"  FALLBACK SUMMARY:")
            log(u"    Total failed: {}".format(len(failed_tiles)))
            log(u"    Recovered: {}".format(recovered_count))
            log(u"    Still failed: {}".format(len(failed_tiles) - recovered_count))
            log(u"")
        
        # Write 3D configuration with corrected positions
        with codecs.open(final_conf, 'w', encoding='utf-8') as fw:
            fw.write(u"dim = 3\n")
            tile_count = 0
            for name in sorted(tile_positions.keys(), key=lambda n: tile_positions[n]['index']):
                info = tile_positions[name]
                name3d = mip_to_3d.get(name, name)
                xy = info['xy']
                tile_line = u"{}; ; ({:.6f}, {:.6f}, 0.0)\n".format(name3d, xy[0], xy[1])
                fw.write(tile_line)
                if DEBUG_STITCHING:
                    status = "[RECOVERED]" if (name in failed_tiles and not info['failed']) else ""
                    logd(u"    3D Tile: {} at ({:.1f}, {:.1f}, 0.0) {}".format(name3d, xy[0], xy[1], status))
                tile_count += 1
        
        if DEBUG_STITCHING:
            recovered_count = len([n for n in failed_tiles if not tile_positions[n]['failed']])
            log(u"  Wrote {} tiles to 3D configuration".format(tile_count))
            if recovered_count > 0:
                log(u"  Recovered {} failed alignment(s) using neighbor constraints".format(recovered_count))
            log(u"  3D config file: {}".format(final_conf))

        # Step 3: Stitch 3D stacks using transferred registration
        # IMPORTANT: Each file in TileConfiguration_3D.txt must be a 3D stack
        # The plugin will load each stack and fuse them at the specified x,y positions
        # All z-slices from each tile are preserved in the final stitched volume
        
        if DEBUG_STITCHING:
            log(u"")
            log(u"=== STEP 3: 3D FUSION ===")
            log(u"  Fusing 3D stacks using computed positions...")
            log(u"  This preserves all z-slices from each tile")
        
        stitch_3d_start = time.time()
        try:
            IJ.run("Grid/Collection stitching", 
                   "type=[Positions from file] order=[Defined by TileConfiguration] directory=[" + clean_dir + 
                   "] layout_file=TileConfiguration_3D.txt fusion_method=[" + self.fusion_method + 
                   "] subpixel_accuracy image_output=[Fuse and display]")
            stitch_3d_time = time.time() - stitch_3d_start
            if DEBUG_STITCHING:
                log(u"  3D fusion completed in {:.1f} seconds".format(stitch_3d_time))
                log(u"  Total stitching time: {:.1f} seconds".format(stitch_2d_time + stitch_3d_time))
        except Exception as e:
            log(u"Stitching (3D) failed: {}".format(e))
            if DEBUG_STITCHING:
                import traceback
                logd(u"  Traceback:")
                for line in traceback.format_exc().split('\n'):
                    logd(u"    {}".format(line))

        imp = WindowManager.getCurrentImage()
        if imp is None:
            log(u"No fused image produced; skipping save for {}.".format(base_name))
            try: 
                reader.close()
            except: 
                pass
            if proc:
                try: 
                    proc.close()
                except: 
                    pass
            if self.do_clean:
                try: 
                    shutil.rmtree(file_dst)
                except Exception as e:
                    logv(u"Cleanup temp dir failed: {}".format(e))
            return False
        
        # Garbage collection after 3D fusion
        log_memory()
        System.gc()
        Thread.sleep(500)
        log(u"Garbage collection completed after 3D fusion")
        log_memory()

        imp.setTitle(base_name + "_stitched")
        
        logd(u"")
        logd(u"=== IMAGE CONVERSION AND LUT APPLICATION ===")
        logd(u"  Initial image state:")
        logd(u"    - Stack size: {}".format(imp.getStackSize()))
        logd(u"    - Is composite: {}".format(imp.isComposite()))
        logd(u"    - Type: {}".format(imp.getType()))
        
        # Convert to hyperstack if needed (DO NOT create CompositeImage here - let apply_channel_luts_to_image do it)
        try:
            c_cnt, z_cnt = res[0][4][2], res[0][4][3]
            logd(u"  Expected: {} channels, {} slices (total: {})".format(c_cnt, z_cnt, c_cnt * z_cnt))
            
            if imp.getStackSize() == (c_cnt * z_cnt):
                # Just create basic HyperStack, LUT application will handle CompositeImage conversion
                logd(u"  Creating HyperStack (NOT CompositeImage yet)...")
                imp = HyperStackConverter.toHyperStack(imp, c_cnt, z_cnt, 1)
                logd(u"  >>> HyperStack created: {} channels, {} slices".format(c_cnt, z_cnt))
                logd(u"  >>> Is composite after HyperStack creation: {}".format(imp.isComposite()))
            else:
                logd(u"  Stack size mismatch, skipping HyperStack conversion")
        except Exception as e:
            log(u"  !!! HyperStack conversion EXCEPTION: {}".format(e))
            logd(u"  Stack will remain in original format")
            pass
        
        # Apply LUTs from metadata
        logd(u"")
        logd(u"  Applying channel LUTs...")
        logd(u"  Image before LUT application:")
        logd(u"    - Is composite: {}".format(imp.isComposite()))
        logd(u"    - Channels: {}".format(imp.getNChannels()))
        
        try:
            imp_with_luts = apply_channel_luts_to_image(imp, ome_xml, gMeta)
            if imp_with_luts is not None:
                logd(u"  LUT application SUCCESS - checking result...")
                logd(u"    - Returned image is composite: {}".format(imp_with_luts.isComposite()))
                logd(u"    - Returned image channels: {}".format(imp_with_luts.getNChannels()))
                imp = imp_with_luts
                log(u"  >>> LUTs applied successfully, CompositeImage created and assigned")
            else:
                log(u"  !!! LUT application returned None - keeping original image")
                logd(u"  WARNING: No LUTs will be applied to saved image")
        except Exception as e:
            log(u"  !!! LUT application EXCEPTION: {}".format(e))
            logd(u"  Keeping original image without custom LUTs")
            import traceback
            for line in traceback.format_exc().split('\n'):
                logd(u"    {}".format(line))
        
        # Ensure we're in composite mode for multi-channel display
        # Only call this if image is already a CompositeImage (has LUTs applied)
        logd(u"")
        logd(u"  Setting display mode...")
        if imp.isComposite():
            logd(u"  Image IS CompositeImage - setting COMPOSITE display mode")
            imp.setDisplayMode(IJ.COMPOSITE)
            imp.updateAndDraw()
            log(u"  >>> Display mode set to COMPOSITE, image updated")
        else:
            log(u"  !!! Image is NOT CompositeImage - skipping setDisplayMode")
            logd(u"  WARNING: Image will display with default grayscale/color mode")
            imp.updateAndDraw()
        
        logd(u"=== IMAGE CONVERSION COMPLETE ===")
        logd(u"")

        if self.do_save:
            if imp is None or imp.getProcessor() is None:
                log(u"Skipping save: image or processor is None for {}.".format(base_name))
            else:
                # Determine if BigTIFF is needed (>4GB or close to it)
                # Estimate size: width * height * slices * channels * bytesPerPixel
                width = imp.getWidth()
                height = imp.getHeight()
                slices = imp.getNSlices()
                channels = imp.getNChannels()
                frames = imp.getNFrames()
                bit_depth = imp.getBitDepth()
                bytes_per_pixel = 1 if bit_depth == 8 else 2 if bit_depth == 16 else 4
                estimated_size = width * height * slices * channels * frames * bytes_per_pixel
                # Use BigTIFF if size is > 3.5GB (leave safety margin below 4GB limit)
                use_bigtiff = estimated_size > (3.5 * 1024 * 1024 * 1024)
                
                out = os.path.join(self.dst, base_name + u"_stitched.tif")
                try:
                    if use_bigtiff:
                        # Save as BigTIFF for large files
                        log(u"File size ~{:.2f}GB, using BigTIFF format".format(estimated_size / (1024.0**3)))
                        IJ.run(imp, "Bio-Formats Exporter", "save=[" + out + "] compression=Uncompressed")
                        log(u"Saved stitched (BigTIFF): {}".format(out))
                    else:
                        # Save as standard TIFF for smaller files
                        log(u"File size ~{:.2f}GB, using standard TIFF format".format(estimated_size / (1024.0**3)))
                        IJ.saveAs(imp, "Tiff", out)
                        log(u"Saved stitched: {}".format(out))
                except Exception as e:
                    # Fallback: try the other format
                    try:
                        if use_bigtiff:
                            log(u"BigTIFF save failed, trying standard TIFF: {}".format(e))
                            IJ.saveAs(imp, "Tiff", out)
                            log(u"Saved stitched (standard TIFF fallback): {}".format(out))
                        else:
                            log(u"Standard TIFF save failed, trying BigTIFF: {}".format(e))
                            IJ.run(imp, "Bio-Formats Exporter", "save=[" + out + "] compression=Uncompressed")
                            log(u"Saved stitched (BigTIFF fallback): {}".format(out))
                    except Exception as e2:
                        log(u"Saving final stitched failed: {}".format(e2))
                
                
        # Garbage collection after saving
        log_memory()
        System.gc()
        Thread.sleep(500)
        log(u"Garbage collection completed after saving")
        log_memory()
        
        if not self.do_show:
            imp.close()

        try:
            reader.close()
        except:
            pass
        if proc:
            try:
                proc.close()
            except:
                pass
        if self.do_clean:
            System.gc()
            Thread.sleep(1000)
            try:
                shutil.rmtree(file_dst)
            except Exception as e:
                logv(u"Cleanup temp dir failed: {}".format(e))
        
        return True

# ==============================================================================
# PART 10: DIRECTORY PICKER (from v31.16h)
# ==============================================================================

def pick_directory_with_jfilechooser(title, default_path):
    """Pick directory using Swing file chooser (v31.16h + unicode safety)"""
    try:
        from javax.swing import JFileChooser
        jc = JFileChooser()
        _home = os.path.expanduser("~")
        try:
            # Ensure unicode path for Java File object
            path_to_use = ensure_unicode(default_path) if default_path and os.path.isdir(default_path) else _home
            # Convert to string for Java File constructor (Java handles UTF-8)
            jc.setCurrentDirectory(File(path_to_use.encode('utf-8') if isinstance(path_to_use, unicode) else path_to_use))
        except:
            pass
        jc.setFileSelectionMode(JFileChooser.DIRECTORIES_ONLY)
        jc.setDialogTitle(ensure_unicode(title))
        res = jc.showOpenDialog(None)
        from javax.swing import JFileChooser as _JC
        if res == _JC.APPROVE_OPTION:
            sel = jc.getSelectedFile()
            return ensure_unicode(sel.getAbsolutePath())
    except Exception as e:
        logv(u"JFileChooser failed: {}".format(e))
        return default_path
    return None

def compute_threads():
    """Compute optimal thread count (v31.16h)"""
    max_cores = int(Runtime.getRuntime().availableProcessors())
    if max_cores < 10:
        return max_cores
    return max_cores - 1

def estimate_file_metrics(czi_path):
    """
    Estimate file processing metrics without full load.
    Returns: (num_tiles, num_slices, num_channels, voxel_volume)
    """
    try:
        opts = ImporterOptions()
        opts.setId(czi_path)
        opts.setQuiet(True)
        opts.setGroupFiles(False)
        proc = ImportProcess(opts)
        proc.execute()
        reader = proc.getReader()
        
        # Get full-res series
        full_res_indices = get_full_res_series_indices(reader)
        num_tiles = len(full_res_indices)
        
        # Get dimensions from first tile
        if num_tiles > 0:
            reader.setSeries(full_res_indices[0])
            width = reader.getSizeX()
            height = reader.getSizeY()
            slices = reader.getSizeZ()
            channels = reader.getSizeC()
            
            # Calculate total voxel volume
            voxel_volume = num_tiles * width * height * slices * channels
            
            reader.close()  # CRITICAL: Close reader, not proc
            
            return (num_tiles, slices, channels, voxel_volume)
        
        reader.close()
        return (0, 0, 0, 0)
        
    except Exception as e:
        logd(u"Metadata Error: {}".format(e))
        return (0, 0, 0, 0)

def estimate_batch_time(files):
    """
    Estimate total batch processing time using composite linear model.
    Based on user's live data coefficients:
    - K_REG: 330ms per tile (2D registration)
    - K_IO: 105ms per slice (I/O overhead)
    - K_FUSION: 70.5ms per MVox (3D fusion)
    """
    log(u"")
    log(u"=== BATCH ANALYSIS ===")
    log(u"Analyzing {} files...".format(len(files)))
    
    # Coefficients from user's live data
    K_REG = 330.0     # ms per Tile (2D registration)
    K_IO = 105.0      # ms per Slice (I/O overhead)
    K_FUSION = 70.5   # ms per MVox (3D fusion)
    
    # Load config for performance scaling factor
    _config = _load_config()
    S = _config.get("performance_scale", 1.0)
    
    file_info = []
    total_time_sec = 0
    
    for f in files:
        fname = os.path.basename(f)
        tiles, slices, channels, voxels = estimate_file_metrics(f)
        
        if tiles == 0:
            log(u"  {}: Unable to read metadata, skipping estimate".format(fname))
            continue
        
        # Composite linear model: T = S * (K_REG*T + K_IO*Z + K_FUSION*V_MVox)
        mvox = voxels / 1e6
        est_time_ms = S * (K_REG * tiles + K_IO * slices + K_FUSION * mvox)
        est_time_sec = est_time_ms / 1000.0
        
        file_info.append({
            'path': f,
            'name': fname,
            'tiles': tiles,
            'slices': slices,
            'channels': channels,
            'voxels': voxels,
            'est_time_sec': est_time_sec
        })
        total_time_sec += est_time_sec
        
        log(u"  {}: {} tiles, {} slices, {} ch, ~{:.1f}s".format(
            fname, tiles, slices, channels, est_time_sec))
    
    total_time_min = total_time_sec / 60.0
    
    # Calculate estimated completion time in 24h format
    completion_timestamp = time.time() + total_time_sec
    completion_struct = time.localtime(completion_timestamp)
    completion_str = time.strftime("%H:%M:%S", completion_struct)
    
    log(u"")
    log(u"Total estimated processing time: {:.1f} minutes ({:.1f} seconds)".format(
        total_time_min, total_time_sec))
    log(u"Estimated completion time: {} (24h format)".format(completion_str))
    log(u"Performance scale factor: {:.2f}".format(S))
    log(u"=== END BATCH ANALYSIS ===")
    log(u"")
    
    return file_info, total_time_sec

def sort_files_by_size(files):
    """
    Sort files by estimated processing time (largest first).
    This allows users to see progress sooner on large batches.
    """
    log(u"Sorting files by size (largest first)...")
    
    file_metrics = []
    for f in files:
        try:
            tiles, slices, channels, voxels = estimate_file_metrics(f)
            file_metrics.append((f, voxels))
        except:
            file_metrics.append((f, 0))
    
    # Sort by voxels descending
    file_metrics.sort(key=lambda x: x[1], reverse=True)
    
    sorted_files = [fm[0] for fm in file_metrics]
    log(u"Files sorted: largest ({:.1f}M voxels) to smallest ({:.1f}M voxels)".format(
        file_metrics[0][1] / 1e6 if file_metrics else 0,
        file_metrics[-1][1] / 1e6 if file_metrics else 0))
    
    return sorted_files

def create_robust_projection(imp, projection_method, num_z_slices):
    """
    Create z-projection using proven channel-splitting method.
    Based on the working pipeline from user's reference script.
    
    Args:
        imp: Source ImagePlus (must be multi-slice stack)
        projection_method: String method name
        num_z_slices: Number of z-slices being projected
    
    Returns:
        ImagePlus with projection, or None if failed
    """
    try:
        logd(u"  Creating robust projection using channel-splitting method...")
        
        # Store original LUTs for color transfer
        source_luts = None
        if imp.isComposite():
            source_luts = imp.getLuts()
            logd(u"  Retrieved {} LUTs from source".format(len(source_luts) if source_luts else 0))
        
        # Create safe duplicate to work on
        dup = Duplicator().run(imp)
        
        # SPLIT CHANNELS (CRITICAL STABILITY STEP)
        # Processing single channels prevents composite-mode crashes
        channels = ChannelSplitter.split(dup)
        dup.close()  # Free memory
        
        logd(u"  Split into {} channels".format(len(channels)))
        
        # Map method name to ZProjector constant
        method_map = {
            "Max Intensity": ZProjector.MAX_METHOD,
            "Average Intensity": ZProjector.AVG_METHOD,
            "Sum Slices": ZProjector.SUM_METHOD,
            "Standard Deviation": ZProjector.SD_METHOD,
            "Median": ZProjector.MEDIAN_METHOD,
            "Min Intensity": ZProjector.MIN_METHOD
        }
        method_id = method_map.get(projection_method, ZProjector.MAX_METHOD)
        
        # Project each channel individually
        projected_channels = []
        for i, c_imp in enumerate(channels):
            zp = ZProjector(c_imp)
            zp.setMethod(method_id)
            zp.setStartSlice(1)
            zp.setStopSlice(c_imp.getNSlices())
            zp.doProjection()
            projected_channels.append(zp.getProjection())
            logd(u"    Channel {} projected".format(i + 1))
        
        # MERGE CHANNELS back to Composite
        # This restores the multi-channel structure
        merged_proj = RGBStackMerge.mergeChannels(projected_channels, False)
        
        # Cleanup split channels to free RAM
        for c_imp in channels:
            c_imp.close()
        System.gc()
        
        logd(u"  Channels merged, {} channels in result".format(merged_proj.getNChannels()))
        
        # Apply original LUTs if available
        if source_luts and merged_proj.getNChannels() > 1:
            # Convert to CompositeImage to apply LUTs
            proj_comp = CompositeImage(merged_proj, CompositeImage.COMPOSITE)
            
            # Apply each LUT
            for i, lut in enumerate(source_luts):
                if i < proj_comp.getNChannels():
                    proj_comp.setChannelLut(lut, i + 1)
            
            # Set COMPOSITE mode
            proj_comp.setMode(CompositeImage.COMPOSITE)
            proj_comp.updateAllChannelsAndDraw()
            
            logd(u"  >>> LUTs applied successfully")
            return proj_comp
        else:
            logd(u"  Returning merged projection without LUT transfer")
            return merged_proj
            
    except Exception as e:
        log(u"Robust projection failed: {}".format(e))
        import traceback
        for line in traceback.format_exc().split('\n'):
            logd(u"  {}".format(line))
        return None

def process_projection_batch(output_dir, projection_method, do_show, do_save):
    """
    Process all *_stitched.tif files in output directory to create projections.
    Runs as separate batch after stitching is complete.
    
    Args:
        output_dir: Directory containing *_stitched.tif files
        projection_method: String method name for projection
        do_show: Whether to display projections
        do_save: Whether to save projections
    """
    log(u"")
    log(u"=" * 70)
    log(u"=== STARTING Z-PROJECTION BATCH ===")
    log(u"=" * 70)
    log(u"Method: {}".format(projection_method))
    log(u"")
    
    # Find all *_stitched.tif files
    stitched_files = []
    for f in os.listdir(output_dir):
        if f.endswith("_stitched.tif") or f.endswith("_stitched.tiff"):
            stitched_files.append(os.path.join(output_dir, f))
    
    if not stitched_files:
        log(u"No *_stitched.tif files found in output directory")
        log(u"Skipping projection batch")
        return
    
    log(u"Found {} stitched file(s) to process".format(len(stitched_files)))
    
    proj_count = 0
    for idx, stitched_path in enumerate(stitched_files):
        try:
            fname = os.path.basename(stitched_path)
            base_name = fname.replace("_stitched.tif", "").replace("_stitched.tiff", "")
            
            log(u"")
            log(u"[{}/{}] Processing: {}".format(idx + 1, len(stitched_files), fname))
            
            # Load stitched file
            imp = IJ.openImage(stitched_path)
            if imp is None:
                log(u"  Failed to load image, skipping")
                continue
            
            num_slices = imp.getNSlices()
            if num_slices <= 1:
                log(u"  Only {} slice(s), skipping projection".format(num_slices))
                imp.close()
                continue
            
            log(u"  Loaded: {} slices, {} channels".format(num_slices, imp.getNChannels()))
            
            # Create projection using robust method
            proj_imp = create_robust_projection(imp, projection_method, num_slices)
            
            if proj_imp is None:
                log(u"  Projection creation failed, skipping")
                imp.close()
                continue
            
            # Create filename with z-count and method
            # Format: basename_<num>z_<method>.tif
            method_short = projection_method.replace(" Intensity", "").replace(" Slices", "").replace(" ", "")
            proj_filename = u"{}_{}z_{}.tif".format(base_name, num_slices, method_short)
            proj_imp.setTitle(proj_filename.replace(".tif", ""))
            
            # Auto brightness/contrast adjustment
            # Apply to each channel to handle varying intensity ranges (especially for Min/Sum methods)
            try:
                if proj_imp.isComposite():
                    log(u"  Applying auto brightness/contrast...")
                    for c in range(1, proj_imp.getNChannels() + 1):
                        proj_imp.setC(c)
                        IJ.run(proj_imp, "Enhance Contrast", "saturated=0.35")
                    proj_imp.setC(1)  # Reset to first channel
                    log(u"  Auto B&C applied to all channels")
                else:
                    IJ.run(proj_imp, "Enhance Contrast", "saturated=0.35")
                    log(u"  Auto B&C applied")
            except Exception as e:
                logd(u"  Auto B&C failed: {}".format(e))
            
            # Save if requested
            if do_save:
                proj_out = os.path.join(output_dir, proj_filename)
                try:
                    IJ.saveAs(proj_imp, "Tiff", proj_out)
                    log(u"  Saved: {}".format(proj_filename))
                    proj_count += 1
                except Exception as e:
                    log(u"  Save failed: {}".format(e))
            
            # Show if requested
            if do_show:
                proj_imp.show()
                log(u"  Displayed projection")
            elif not do_save:
                proj_imp.close()
            
            # Close source image
            imp.close()
            
            # Garbage collection
            System.gc()
            
        except Exception as e:
            log(u"  Processing failed: {}".format(e))
            import traceback
            traceback.print_exc()
    
    log(u"")
    log(u"=" * 70)
    log(u"Projection batch complete: {} projection(s) created".format(proj_count))
    log(u"=" * 70)
    log(u"")

# ==============================================================================
# PART 11: MAIN ENTRY POINT (from v31.16h + v34.8 bug fixes)
# ==============================================================================

def show_splash():
    """Display ASCII art splash screen with corrective padding for proportional fonts"""
    splash = u"""
      +---+---+---+
      | C | Z | I  |    CZI-STITCHER v37.5
      +---+---+---+     ======================
      | S | t  | i  |   > Workflow: v31.16h
      +---+---+---+     > UTF-8:    v34.8
      | t  | c | h |    > LUTs:     v36.5
      +---+---+---+     > Paths:    v37.5

      [Target] Zeiss Zen/CZI Analysis
      [Status] Initializing environment...
    """
    log(splash)

def main():
    """Main entry point"""
    IJ.log("\\Clear")
    show_splash()
    
    # Load config
    _config = _load_config()
    
    # Add filesystem loading message for user expectation management
    log(u"")
    log(u"Loading filesystem... This might take a while with sleeping HDDs.")
    log(u"")
    
    _home = os.path.expanduser("~")
    _last_in = _config.get("last_input_dir", "") or _home
    _last_out = _config.get("last_output_dir", "") or _home
    _last_proc = _config.get("last_processing_dir", "") or _last_out
    if not os.path.isdir(_last_in): 
        _last_in = _home
    if not os.path.isdir(_last_out): 
        _last_out = _home
    if not os.path.isdir(_last_proc):
        _last_proc = _last_out
    
    # Parameter dialog loop - allows returning to dialog if illegal settings detected
    while True:
        # Parameter dialog with path fields
        gd = GenericDialog("Specialised CZI Stitcher - Parameters v37.5")
        gd.addMessage("=== Directory Paths ===")
        gd.addStringField("Input Folder (CZI files):", _last_in, 50)
        gd.addToSameRow()
        gd.addMessage("[Browse...]")
        gd.addStringField("Output Folder (Results):", _last_out, 50)
        gd.addToSameRow()
        gd.addMessage("[Browse...]")
        gd.addStringField("Processing Folder (Temp):", _last_proc, 50)
        gd.addToSameRow()
        gd.addMessage("[Browse...]")
        
        gd.addMessage("=== Stitching Parameters ===")
        gd.addChoice("Fusion Method", ["Linear Blending", "Max. Intensity", "Average", "Median"], "Linear Blending")
        gd.addNumericField("Rolling Ball Radius (0 = Off)", 50, 0)
        gd.addNumericField("Regression Threshold", 0.30, 2)
        gd.addNumericField("Max Displacement (px)", 5.0, 1)
        
        gd.addMessage("=== Output Options (at least one must be enabled) ===")
        gd.addCheckbox("Save Stitched Stack", True)
        gd.addCheckbox("Show Stitched Stack", True)
        gd.addCheckbox("Save Z-Projection", False)
        gd.addCheckbox("Show Z-Projection", False)
        gd.addChoice("Z-Projection Method", ["Max Intensity", "Average Intensity", "Sum Slices", "Standard Deviation", "Median", "Min Intensity"], "Max Intensity")
        
        gd.addMessage("=== Processing Options ===")
        gd.addCheckbox("Verbose/Debug Logging", True)
        gd.addCheckbox("Cleanup Temp Files", True)
        gd.addCheckbox("Auto-adjust stitching thresholds from metadata", False)
        gd.addNumericField("Pixel size correction factor (default 10)", 10.0, 1)
        
        gd.addMessage("=== Metadata Correction (Experimental) ===")
        gd.addCheckbox("Enable metadata correction", True)
        gd.addChoice("Microscope", ["default", "zeiss_axio_1", "zeiss_axio_2"], "default")
        gd.addChoice("Thermal state", ["unknown", "cold", "preheated"], "unknown")
        
        gd.showDialog()
        
        if gd.wasCanceled():
            log("User cancelled parameter dialog. Exiting.")
            raise SystemExit("Cancelled by user")
        
        # Get directory paths
        in_path = gd.getNextString().strip()
        out_path = gd.getNextString().strip()
        proc_path = gd.getNextString().strip()
        
        # Validate paths
        if not in_path or not os.path.isdir(in_path):
            log(u"Error: Input folder '{}' does not exist or is invalid.".format(in_path))
            raise SystemExit("Invalid input folder")
        if not out_path or not os.path.isdir(out_path):
            log(u"Error: Output folder '{}' does not exist or is invalid.".format(out_path))
            raise SystemExit("Invalid output folder")
        if not proc_path or not os.path.isdir(proc_path):
            log(u"Error: Processing folder '{}' does not exist or is invalid.".format(proc_path))
            raise SystemExit("Invalid processing folder")
        
        # Save config
        _config["last_input_dir"] = in_path
        _config["last_output_dir"] = out_path
        _config["last_processing_dir"] = proc_path
        _save_config(_config)
        
        input_dir_raw = File(unicode(in_path))
        output_dir_raw = File(unicode(out_path))
        processing_dir_raw = File(unicode(proc_path))
        
        # Get parameters
        fusion_method = gd.getNextChoice()
        rb_radius = int(gd.getNextNumber())
        reg_thresh = float(gd.getNextNumber())
        disp_thresh = float(gd.getNextNumber())
        
        # Output options
        save_stack = (int(gd.getNextBoolean()) == 1)
        show_stack = (int(gd.getNextBoolean()) == 1)
        save_projection = (int(gd.getNextBoolean()) == 1)
        show_projection = (int(gd.getNextBoolean()) == 1)
        projection_method = gd.getNextChoice()
        
        # Processing options
        verbose_mode = (int(gd.getNextBoolean()) == 1)
        do_clean = (int(gd.getNextBoolean()) == 1)
        auto_adjust = (int(gd.getNextBoolean()) == 1)
        corr_factor = float(gd.getNextNumber())
        
        # Metadata correction options
        enable_correction = (int(gd.getNextBoolean()) == 1)
        microscope_id = gd.getNextChoice()
        thermal_state = gd.getNextChoice()
        
        # Load correction matrix
        correction_matrix = _load_correction_matrix(_config, microscope_id)
        correction_matrix['enabled'] = enable_correction
        correction_matrix['thermal_state'] = thermal_state
        
        # Set global VERBOSE flag
        global VERBOSE
        VERBOSE = verbose_mode
        
        # Validate output options
        do_projection = save_projection or show_projection
        has_any_output = save_stack or show_stack or save_projection or show_projection
        
        # Show popup and return to parameters if illegal settings detected
        if not has_any_output:
            from ij.gui import MessageDialog
            MessageDialog(None, "Illegal Settings", 
                         "At least one output option must be enabled:\n" +
                         "- Save Stitched Stack\n" +
                         "- Show Stitched Stack\n" +
                         "- Save Z-Projection\n" +
                         "- Show Z-Projection\n\n" +
                         "Please select at least one option.").show()
            log(u"Error: No output options selected. Returning to parameters.")
            continue  # Return to parameter dialog
        
        # CRITICAL: If projection is requested, save_stack MUST be enabled
        if do_projection and not save_stack:
            from ij.gui import MessageDialog
            MessageDialog(None, "Illegal Settings", 
                         "To create projections, 'Save Stitched Stack' must be enabled.\n\n" +
                         "Projections are created from saved *_stitched.tif files\n" +
                         "after stitching completes.\n\n" +
                         "Please enable 'Save Stitched Stack' to proceed.").show()
            log(u"Error: Save Stitched Stack required for projections. Returning to parameters.")
            continue  # Return to parameter dialog
        
        # If we reach here, settings are valid - break out of loop
        break
    
    thread_count_slider = compute_threads()
    
    # Process files
    s_dir = get_safe_path(input_dir_raw)
    t_dir = get_safe_path(output_dir_raw)
    temp_root = get_safe_path(processing_dir_raw)
    
    files = sorted([os.path.join(s_dir, f) for f in os.listdir(s_dir) if f.lower().endswith(".czi")])
    
    if not files:
        log(u"No CZI files found in {}".format(s_dir))
        return
    
    # Sort files by size (largest first) for better progress visibility
    files = sort_files_by_size(files)
    
    # Estimate batch processing time
    file_info, est_time_sec = estimate_batch_time(files)
    
    t_lim = int(compute_threads())
    
    try:
        log(u"Input: {}".format(unicode(s_dir)))
        log(u"Output: {}".format(unicode(t_dir)))
        log(u"Processing/Temp: {}".format(unicode(temp_root)))
        log(u"Threads: {}".format(t_lim))
    except:
        log("Input: {}".format(s_dir))
        log("Output: {}".format(t_dir))
        log("Processing/Temp: {}".format(temp_root))
        log("Threads: {}".format(t_lim))
    
    log(u"")
    log(u"Parameters:")
    log(u"  Fusion: {}".format(fusion_method))
    log(u"  Rolling Ball Radius: {}".format(rb_radius))
    log(u"  Regression Threshold: {}".format(reg_thresh))
    log(u"  Max Displacement: {}".format(disp_thresh))
    log(u"  Auto-adjust: {}".format(auto_adjust))
    log(u"  Correction Factor: {}".format(corr_factor))
    log(u"  Save Stack: {} | Show Stack: {}".format(save_stack, show_stack))
    log(u"  Z-Projection: {}".format("Enabled ({})".format(projection_method) if do_projection else "Disabled"))
    if do_projection:
        log(u"    Save Projection: {} | Show Projection: {}".format(save_projection, show_projection))
    log(u"")
    
    stitcher = UltimateStitcher(s_dir, t_dir, t_lim, temp_root, fusion_method, rb_radius, 
                                 reg_thresh, disp_thresh, show_stack, save_stack, 
                                 do_clean, auto_adjust, corr_factor, correction_matrix)
    
    batch_start_time = time.time()
    files_completed = 0
    
    for idx, f in enumerate(files):
        try:
            file_start = time.time()
            log(u"")
            log(u"=" * 70)
            log(u"Processing file {}/{}: {}".format(idx + 1, len(files), os.path.basename(f)))
            log(u"=" * 70)
            
            stitcher.process_file(f)
            
            file_elapsed = time.time() - file_start
            files_completed += 1
            
            # Calculate remaining time estimate
            avg_time_per_file = (time.time() - batch_start_time) / files_completed
            remaining_files = len(files) - files_completed
            est_remaining_sec = avg_time_per_file * remaining_files
            est_remaining_min = est_remaining_sec / 60.0
            
            # Calculate estimated completion time in 24h format
            completion_timestamp = time.time() + est_remaining_sec
            completion_struct = time.localtime(completion_timestamp)
            completion_str = time.strftime("%H:%M:%S", completion_struct)
            
            log(u"")
            log(u"File completed in {:.1f} seconds".format(file_elapsed))
            log(u"Progress: {}/{} files ({:.1f}%)".format(
                files_completed, len(files), (files_completed * 100.0) / len(files)))
            
            # Special message when 100% complete
            if files_completed >= len(files) and est_time_sec > 0:
                # Calculate deviation from original estimate
                actual_time = time.time() - batch_start_time
                deviation_pct = ((actual_time - est_time_sec) / est_time_sec) * 100.0
                
                if abs(deviation_pct) <= 5.0:
                    log(u"Estimate deviation: {:.1f}% :) made it in time".format(deviation_pct))
                elif deviation_pct > 10.0:
                    log(u"Estimate deviation: +{:.1f}% :| sorry for the delay".format(deviation_pct))
                elif deviation_pct < -10.0:
                    log(u"Estimate deviation: {:.1f}% o.O that was kinda fast".format(deviation_pct))
                else:
                    log(u"Estimate deviation: {:.1f}%".format(deviation_pct))
            else:
                log(u"Estimated time remaining: {:.1f} minutes".format(est_remaining_min))
                log(u"Estimated completion time: {} (24h format)".format(completion_str))
            
        except Exception as e:
            log(u"Processing file {} failed: {}".format(f, e))
            import traceback
            traceback.print_exc()
    
    batch_elapsed = time.time() - batch_start_time
    batch_elapsed_min = batch_elapsed / 60.0
    
    log(u"")
    log(u"=" * 70)
    log(u"Stitching Batch Done.")
    log(u"Files processed: {}/{}".format(files_completed, len(files)))
    log(u"Total time: {:.1f} minutes ({:.1f} seconds)".format(batch_elapsed_min, batch_elapsed))
    log(u"Average per file: {:.1f} seconds".format(batch_elapsed / files_completed if files_completed > 0 else 0))
    log(u"=" * 70)
    
    # Update performance scale factor based on actual performance
    if est_time_sec > 0 and files_completed > 0:
        old_scale = _config.get("performance_scale", 1.0)
        actual_time = batch_elapsed
        deviation_pct = ((actual_time - est_time_sec) / est_time_sec) * 100.0
        
        # Check for major deviation (2x or more off)
        if abs(deviation_pct) > 100.0:
            # Set directly to match last performance
            new_scale = old_scale * (actual_time / est_time_sec)
            _config["performance_scale"] = new_scale
            log(u"")
            log(u"o_O man I was way off - setting scale to match last performance")
            log(u"Performance scale factor: {:.2f} -> {:.2f}".format(old_scale, new_scale))
        else:
            # Normal learning with exponential moving average (70% old, 30% new)
            new_scale = old_scale * (actual_time / est_time_sec)
            final_scale = 0.7 * old_scale + 0.3 * new_scale
            _config["performance_scale"] = final_scale
            log(u"")
            log(u"Updated performance scale factor: {:.2f} -> {:.2f} (learning enabled)".format(
                old_scale, final_scale))
        
        _save_config(_config)
    
    # Run projection batch if requested
    if do_projection:
        log(u"")
        log(u"Stitching complete. Starting projection batch...")
        process_projection_batch(t_dir, projection_method, show_projection, save_projection)
    
    if PLAY_JINGLE_ON_DONE:
        play_clear_jingle()

# Run main
if __name__ in [None, "__main__", "__builtin__"]:
    main()
