# BATCH Z-PROJECTION v1.2
# Standalone tool for batch Z-projection with layer selection
# INDEPENDENT from main.jy - this is a separate pipeline tool
#
# PURPOSE: Process multiple TIFF stacks with flexible Z-layer selection
# FEATURES:
#   - Multiple projection methods (Max, Average, Sum, SD, Median, Min)
#   - Three layer selection modes:
#     1. Use all layers (fastest)
#     2. Discard top/bottom layers (manual trimming)
#     3. Threshold-based selection (noise filtering)
#   - Advanced noise detection for Apotome/SIM data:
#     * Valley-Emphasis Otsu (BEST for class imbalance)
#     * Weighted Otsu (for rare signal)
#     * Triangle thresholding on focus scores
#     * Coefficient of Variation (CV)
#   - Automatic rejection of fusion artifacts (mean=0 slices)
#   - Hardening constraints (sigma check, percentile padding, SNR gate)
#   - Batch processing with progress tracking
#   - Preserves channel colors (LUTs)
#
# BASED ON: Established patterns from main.jy v37.5
# AVOIDS: All documented pitfalls from TECHDOC/PITFALLS.md
#
# v1.2 CHANGES:
# - Added Valley-Emphasis Otsu for extreme class imbalance (90% baseline + 10% signal)
# - Added hardening constraints: sigma check, percentile padding, SNR gate
# - Valley-Emphasis forces threshold into valley between baseline and signal
# - SNR < 1.5 triggers warning for manual review
# - Prevents threshold from settling on flat, even baseline
#
# v1.1 CHANGES:
# - Added Otsu's method for Apotome structured illumination data
# - Added Triangle thresholding on focus scores (mean × std_dev)
# - Added Coefficient of Variation (CV) method
# - Automatic rejection of slices with mean=0 (fusion artifacts)
# - Deprecated naive mean+sigma method (fails for Apotome)

import os, time, codecs, json, sys, re, tempfile
from java.lang import Runtime, System, Thread
from java.util.concurrent import Executors, Callable, Future
from java.awt import Color
from ij import IJ, ImagePlus, WindowManager, CompositeImage
from ij.plugin import ZProjector, ChannelSplitter, RGBStackMerge, Duplicator
from ij.process import ImageStatistics
from ij.gui import GenericDialog
from java.io import File

# ==============================================================================
# VERSION AND CONFIGURATION
# ==============================================================================
VERSION = "v1.2"
MICRO = u"\u00b5"

# Debug flags
VERBOSE = True
DEBUG = True

# Config file for remembering last used directories
_CONFIG_PATH = os.path.join(os.path.expanduser("~"), ".batch_z_projection_config.json")

# ==============================================================================
# PART 1: UTILITY FUNCTIONS (from main.jy - proven patterns)
# ==============================================================================

def ensure_unicode(o):
    """Convert any object to unicode safely"""
    if o is None:
        return None
    if isinstance(o, unicode):
        return o
    
    try:
        result = unicode(bytearray(o.getBytes("UTF-8")), 'utf-8', 'replace')
        return result
    except:
        pass
    
    try:
        result = unicode(o, 'utf-8', 'replace')
        return result
    except:
        pass
    
    try:
        result = unicode(str(o), 'utf-8', 'replace')
        return result
    except:
        pass
    
    try:
        return u"%s" % o
    except:
        return u""

def safe_unicode(o):
    """Safe unicode conversion with fallback"""
    try:
        return ensure_unicode(o)
    except:
        try:
            return unicode(o)
        except:
            try:
                return u"%s" % o
            except:
                return u"<unrepresentable>"

def log(msg):
    """Thread-safe logging with unicode support"""
    try:
        IJ.log(u"[Z-Proj] {}".format(safe_unicode(msg)))
    except UnicodeEncodeError:
        try:
            IJ.log("[Z-Proj] <message contains unsupported characters>")
        except:
            pass
    except:
        try:
            IJ.log(str(msg))
        except:
            pass

def logv(msg):
    """Verbose logging"""
    if VERBOSE:
        log(u"[VERBOSE] {}".format(msg))

def logd(msg):
    """Debug logging"""
    if DEBUG:
        log(u"[DEBUG] {}".format(msg))

def log_memory():
    """Log current memory usage"""
    try:
        runtime = Runtime.getRuntime()
        total_mb = runtime.totalMemory() / (1024.0 * 1024.0)
        free_mb = runtime.freeMemory() / (1024.0 * 1024.0)
        used_mb = total_mb - free_mb
        max_mb = runtime.maxMemory() / (1024.0 * 1024.0)
        log(u"[MEMORY] Used: {:.1f}MB / Total: {:.1f}MB / Max: {:.1f}MB".format(used_mb, total_mb, max_mb))
        return (used_mb, total_mb, max_mb, free_mb)
    except Exception as e:
        logd(u"Memory logging failed: {}".format(e))
        return (0, 0, 0, 0)

def calculate_optimal_threads(file_size_mb, target_ram_usage_percent=0.8):
    """
    Calculate optimal number of threads based on available RAM
    
    Args:
        file_size_mb: Estimated size per file in MB
        target_ram_usage_percent: Target percentage of free RAM to use (default 0.8 = 80%)
    
    Returns: number of threads (minimum 1, maximum CPU cores)
    """
    try:
        runtime = Runtime.getRuntime()
        max_mb = runtime.maxMemory() / (1024.0 * 1024.0)
        used_mb = (runtime.totalMemory() - runtime.freeMemory()) / (1024.0 * 1024.0)
        free_mb = max_mb - used_mb
        
        # Calculate how much RAM we can allocate (80% of free)
        available_for_threads = free_mb * target_ram_usage_percent
        
        # Estimate threads based on file size (conservative: assume 2x file size per thread)
        memory_per_thread = max(file_size_mb * 2.0, 500.0)  # Minimum 500MB per thread
        threads_by_memory = int(available_for_threads / memory_per_thread)
        
        # Limit by CPU cores
        cpu_cores = runtime.availableProcessors()
        max_threads = max(cpu_cores - 1, 1) if cpu_cores > 1 else 1
        
        # Final thread count
        optimal_threads = max(1, min(threads_by_memory, max_threads))
        
        logd(u"  Thread calculation: free={:.1f}MB, available={:.1f}MB, file_size={:.1f}MB".format(
            free_mb, available_for_threads, file_size_mb))
        logd(u"  CPU cores={}, memory_threads={}, optimal_threads={}".format(
            cpu_cores, threads_by_memory, optimal_threads))
        
        return optimal_threads
        
    except Exception as e:
        logd(u"  Thread calculation failed: {}, defaulting to 1 thread".format(e))
        return 1

def _load_config():
    """Load last used directories from config file"""
    logd(u"Loading config from: {}".format(_CONFIG_PATH))
    try:
        if os.path.exists(_CONFIG_PATH):
            with codecs.open(_CONFIG_PATH, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
                logd(u"Config loaded: {}".format(cfg))
                return cfg
        else:
            logd(u"Config file does not exist, using defaults")
    except Exception as e:
        logd(u"Config load failed: {}".format(e))
    return {}

def _save_config(cfg):
    """Save directories to config file"""
    logd(u"Saving config: {}".format(cfg))
    try:
        with codecs.open(_CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
            logd(u"Config saved successfully")
    except Exception as e:
        logd(u"Config save failed: {}".format(e))

# ==============================================================================
# PART 2: DISCOVERY PHASE (Parallel Z-Profile Calculation)
# ==============================================================================

class DiscoveryTask(Callable):
    """
    Callable task for parallel Z-profile discovery
    
    Processes one file to calculate Z-profile and determine slice range,
    then writes results to temp file for later projection phase.
    """
    def __init__(self, tif_path, layer_mode, discard_top, discard_bottom, 
                 threshold_method, user_threshold, sigma, channel_index, temp_dir):
        self.tif_path = tif_path
        self.layer_mode = layer_mode
        self.discard_top = discard_top
        self.discard_bottom = discard_bottom
        self.threshold_method = threshold_method
        self.user_threshold = user_threshold
        self.sigma = sigma
        self.channel_index = channel_index
        self.temp_dir = temp_dir
        self.fname = os.path.basename(tif_path)
    
    def call(self):
        """Execute discovery for this file"""
        result = {
            'file': self.tif_path,
            'fname': self.fname,
            'success': False,
            'error': None,
            'num_slices': 0,
            'num_channels': 0,
            'slice_range': None,
            'skip': False,
            'skip_reason': None
        }
        
        try:
            # Load image (read-only for discovery)
            imp = IJ.openImage(self.tif_path)
            if imp is None:
                result['error'] = "Failed to load image"
                return result
            
            result['num_slices'] = imp.getNSlices()
            result['num_channels'] = imp.getNChannels()
            
            # Check if projection is needed
            if result['num_slices'] <= 1:
                result['skip'] = True
                result['skip_reason'] = "Only {} slice(s)".format(result['num_slices'])
                imp.close()
                return result
            
            # Determine slice range based on mode
            if self.layer_mode == "all":
                result['slice_range'] = select_all_layers(imp)
                result['success'] = True
                
            elif self.layer_mode == "discard":
                slice_range = select_discard_layers(imp, self.discard_top, self.discard_bottom)
                if slice_range is None:
                    result['error'] = "Invalid discard parameters"
                else:
                    result['slice_range'] = slice_range
                    result['success'] = True
                    
            elif self.layer_mode == "threshold":
                slice_range = select_layers_by_threshold(
                    imp, self.threshold_method, self.user_threshold, 
                    self.sigma, self.channel_index)
                if slice_range is None:
                    result['skip'] = True
                    result['skip_reason'] = "No slices meet threshold"
                else:
                    result['slice_range'] = slice_range
                    result['success'] = True
            
            # Close image to free memory
            imp.close()
            System.gc()
            
            # Write result to temp file
            if result['success'] or result['skip']:
                temp_file = os.path.join(self.temp_dir, "{}.json".format(
                    self.fname.replace('.tif', '').replace('.tiff', '')))
                with codecs.open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                result['temp_file'] = temp_file
            
            return result
            
        except Exception as e:
            result['error'] = str(e)
            return result

def run_discovery_phase(tif_files, layer_mode, discard_top, discard_bottom,
                        threshold_method, user_threshold, sigma, channel_index,
                        num_threads):
    """
    Run discovery phase in parallel to calculate Z-profiles and slice ranges
    
    Args:
        tif_files: List of TIFF file paths
        layer_mode: "all", "discard", or "threshold"
        discard_top: Number of top slices to discard
        discard_bottom: Number of bottom slices to discard
        threshold_method: Threshold detection method
        user_threshold: User-provided threshold value
        sigma: Sigma multiplier
        channel_index: Channel to analyze
        num_threads: Number of parallel threads to use
    
    Returns: (discovery_results[], temp_dir)
    """
    log(u"")
    log(u"=" * 70)
    log(u"=== DISCOVERY PHASE: Z-Profile Analysis ===")
    log(u"=" * 70)
    log(u"  Files: {}".format(len(tif_files)))
    log(u"  Threads: {}".format(num_threads))
    log(u"  Mode: {}".format(layer_mode))
    log(u"")
    
    # Create temporary directory for results
    temp_dir = tempfile.mkdtemp(prefix="batch_z_proj_")
    logd(u"  Temp directory: {}".format(temp_dir))
    
    # Create thread pool
    executor = Executors.newFixedThreadPool(num_threads)
    
    # Submit all tasks
    futures = []
    for tif_path in tif_files:
        task = DiscoveryTask(tif_path, layer_mode, discard_top, discard_bottom,
                            threshold_method, user_threshold, sigma, channel_index,
                            temp_dir)
        future = executor.submit(task)
        futures.append((tif_path, future))
    
    # Collect results as they complete
    discovery_results = []
    completed = 0
    
    for tif_path, future in futures:
        try:
            result = future.get()  # Wait for completion
            discovery_results.append(result)
            completed += 1
            
            # Log progress
            fname = os.path.basename(tif_path)
            if result.get('success'):
                log(u"  [{}/{}] >>> {} - Discovered: slices {}".format(
                    completed, len(tif_files), fname, result.get('slice_range')))
            elif result.get('skip'):
                log(u"  [{}/{}] SKIP {} - {}".format(
                    completed, len(tif_files), fname, result.get('skip_reason')))
            elif result.get('error'):
                log(u"  [{}/{}] !!! {} - ERROR: {}".format(
                    completed, len(tif_files), fname, result.get('error')))
            
        except Exception as e:
            log(u"  !!! Discovery task failed for {}: {}".format(os.path.basename(tif_path), e))
            discovery_results.append({
                'file': tif_path,
                'fname': os.path.basename(tif_path),
                'success': False,
                'error': str(e)
            })
            completed += 1
    
    # Shutdown executor
    executor.shutdown()
    
    log(u"")
    log(u"=== DISCOVERY COMPLETE ===")
    log(u"  Successful: {}".format(sum(1 for r in discovery_results if r.get('success'))))
    log(u"  Skipped: {}".format(sum(1 for r in discovery_results if r.get('skip'))))
    log(u"  Errors: {}".format(sum(1 for r in discovery_results if r.get('error'))))
    log(u"")
    
    # Force garbage collection after discovery
    System.gc()
    log_memory()
    
    return (discovery_results, temp_dir)

# ==============================================================================
# PART 3: LAYER SELECTION METHODS
# ==============================================================================

def select_all_layers(imp):
    """
    Mode 1: Use all layers (fastest)
    
    Returns: (start_slice, stop_slice)
    """
    return (1, imp.getNSlices())

def select_discard_layers(imp, discard_top, discard_bottom):
    """
    Mode 2: Discard x top and y bottom layers
    
    Args:
        imp: ImagePlus stack
        discard_top: Number of top slices to discard
        discard_bottom: Number of bottom slices to discard
    
    Returns: (start_slice, stop_slice) or None if invalid
    """
    total_slices = imp.getNSlices()
    
    # Validate
    if discard_top + discard_bottom >= total_slices:
        log(u"!!! ERROR: Cannot discard {} top + {} bottom from {} total slices".format(
            discard_top, discard_bottom, total_slices))
        return None
    
    start = 1 + discard_top
    stop = total_slices - discard_bottom
    
    log(u"  Discarding {} top and {} bottom slices".format(discard_top, discard_bottom))
    log(u"  Using slices {} to {} (total: {})".format(start, stop, stop - start + 1))
    
    return (start, stop)

def calculate_z_profile(imp, channel_index=1):
    """
    Calculate mean and standard deviation for each Z-slice
    
    This creates a profile of intensity across the Z-stack,
    which is used by advanced thresholding methods.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: tuple of (means[], std_devs[], valid_indices[])
             valid_indices excludes slices with mean=0 (fusion artifacts)
    """
    total_slices = imp.getNSlices()
    means = []
    std_devs = []
    valid_indices = []
    
    # Set to correct channel
    if imp.getNChannels() > 1:
        imp.setC(channel_index)
    
    for z in range(1, total_slices + 1):
        imp.setZ(z)
        stats = imp.getStatistics(ImageStatistics.MEAN + ImageStatistics.STD_DEV)
        
        # Reject slices with mean=0 (fusion artifacts)
        if stats.mean > 0.0:
            means.append(stats.mean)
            std_devs.append(stats.stdDev)
            valid_indices.append(z)
        else:
            logd(u"    Slice {}: mean=0.0 [FUSION ARTIFACT - REJECTED]".format(z))
    
    return (means, std_devs, valid_indices)

def otsu_threshold_1d(values, weighted=False, valley_emphasis=False):
    """
    Apply Otsu's method to 1D array (Z-profile)
    
    Finds threshold that maximizes inter-class variance between
    two populations (out-of-focus vs in-focus slices).
    
    Args:
        values: List of intensity values (e.g., mean per slice)
        weighted: If True, uses weighted Otsu to favor rare in-focus slices
        valley_emphasis: If True, penalizes thresholds on high-density peaks
                        (forces threshold into valley between baseline and signal)
    
    Returns: threshold value (float)
    """
    if not values or len(values) < 2:
        return 0.0
    
    # Sort values to find optimal threshold
    sorted_vals = sorted(values)
    min_val = sorted_vals[0]
    max_val = sorted_vals[-1]
    
    # Create histogram with 256 bins
    num_bins = min(256, len(values))
    bin_width = (max_val - min_val) / float(num_bins) if max_val > min_val else 1.0
    
    # Build histogram
    histogram = [0] * num_bins
    for v in values:
        bin_idx = int((v - min_val) / bin_width)
        if bin_idx >= num_bins:
            bin_idx = num_bins - 1
        histogram[bin_idx] += 1
    
    # Calculate total weight and mean
    total = sum(histogram)
    sum_total = sum(i * histogram[i] for i in range(num_bins))
    
    # Find threshold that maximizes inter-class variance (or weighted/valley-emphasis variance)
    best_threshold = 0
    best_variance = 0.0
    
    weight_background = 0
    sum_background = 0.0
    
    for t in range(num_bins):
        weight_background += histogram[t]
        if weight_background == 0:
            continue
        
        weight_foreground = total - weight_background
        if weight_foreground == 0:
            break
        
        sum_background += t * histogram[t]
        sum_foreground = sum_total - sum_background
        
        mean_background = sum_background / float(weight_background)
        mean_foreground = sum_foreground / float(weight_foreground)
        
        # Inter-class variance
        variance = weight_background * weight_foreground * (mean_background - mean_foreground) ** 2
        
        # Weighted Otsu: multiply by foreground weight to favor rare in-focus slices
        if weighted:
            # Give more importance to the smaller class (typically in-focus slices)
            # This helps when in-focus is only 10-20% of stack
            weight_ratio = float(weight_foreground) / float(total)
            variance = variance * (1.0 + weight_ratio)
        
        # Valley-Emphasis: penalize thresholds on high-density peaks
        # Forces threshold into "valley" between even baseline and signal
        if valley_emphasis:
            # p_t = probability (frequency) at threshold
            p_t = float(histogram[t]) / float(total)
            # Multiply by (1 - p_t) to favor low-density regions
            variance = variance * (1.0 - p_t)
        
        if variance > best_variance:
            best_variance = variance
            best_threshold = t
    
    # Convert bin index back to actual value
    threshold = min_val + (best_threshold * bin_width)
    return float(threshold)

def triangle_threshold_1d(values):
    """
    Apply Triangle thresholding to 1D array
    
    Designed for distributions with one clear peak and a long tail.
    Finds the point of maximum distance from a line drawn between
    the peak and the end of the tail.
    
    Args:
        values: List of intensity values
    
    Returns: threshold value (float)
    """
    if not values or len(values) < 2:
        return 0.0
    
    sorted_vals = sorted(values)
    min_val = sorted_vals[0]
    max_val = sorted_vals[-1]
    
    # Create histogram
    num_bins = min(256, len(values))
    bin_width = (max_val - min_val) / float(num_bins) if max_val > min_val else 1.0
    
    histogram = [0] * num_bins
    for v in values:
        bin_idx = int((v - min_val) / bin_width)
        if bin_idx >= num_bins:
            bin_idx = num_bins - 1
        histogram[bin_idx] += 1
    
    # Find peak (maximum in histogram)
    peak_idx = 0
    peak_val = histogram[0]
    for i in range(1, num_bins):
        if histogram[i] > peak_val:
            peak_val = histogram[i]
            peak_idx = i
    
    # Determine tail direction (left or right of peak)
    # Assume tail is on the right (out-of-focus slices have lower values)
    tail_idx = num_bins - 1
    
    # If peak is on right, tail is on left
    if peak_idx > num_bins // 2:
        tail_idx = 0
    
    # Calculate distances from line between peak and tail
    max_distance = 0.0
    threshold_idx = peak_idx
    
    # Line from (peak_idx, peak_val) to (tail_idx, histogram[tail_idx])
    dx = float(tail_idx - peak_idx)
    dy = float(histogram[tail_idx] - peak_val)
    
    if abs(dx) < 1e-6:  # Vertical line
        threshold_idx = peak_idx
    else:
        # For each point, calculate perpendicular distance to line
        for i in range(min(peak_idx, tail_idx), max(peak_idx, tail_idx) + 1):
            # Point is (i, histogram[i])
            # Distance from point to line ax + by + c = 0
            # Line: (y - peak_val) = (dy/dx) * (x - peak_idx)
            # Rearranged: dy*x - dx*y + (dx*peak_val - dy*peak_idx) = 0
            
            numerator = abs(dy * i - dx * histogram[i] + (dx * peak_val - dy * peak_idx))
            denominator = (dx * dx + dy * dy) ** 0.5
            
            if denominator > 1e-6:
                distance = numerator / denominator
                if distance > max_distance:
                    max_distance = distance
                    threshold_idx = i
    
    # Convert bin index to actual value
    threshold = min_val + (threshold_idx * bin_width)
    return float(threshold)

def detect_noise_threshold_fast(imp, channel_index=1):
    """
    Fast noise detection using histogram minimum value
    
    This is faster than calculating mean because it only needs
    to scan pixel values, not sum them.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: threshold value (float)
    """
    try:
        # Set to correct channel if multi-channel
        if imp.getNChannels() > 1:
            imp.setC(channel_index)
        
        # Get statistics from middle slice (representative)
        mid_slice = imp.getNSlices() // 2
        imp.setZ(mid_slice)
        
        stats = imp.getStatistics(ImageStatistics.MIN_MAX)
        
        # Use minimum value as baseline
        threshold = stats.min
        
        logd(u"  Fast noise detection: min={:.2f}".format(threshold))
        return float(threshold)
        
    except Exception as e:
        logd(u"  Fast noise detection failed: {}".format(e))
        return 0.0

def detect_noise_threshold_mean(imp, channel_index=1, sigma_multiplier=3.0):
    """
    DEPRECATED: Naive mean + sigma approach fails for Apotome data
    
    This method is kept for compatibility but is NOT recommended
    for structured illumination (Apotome) data where signal
    magnitudes vary greatly.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
        sigma_multiplier: How many standard deviations above mean (default 3.0)
    
    Returns: threshold value (float)
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  Mean noise detection failed: no valid slices")
            return 0.0
        
        # Calculate global mean and std dev across all slices
        global_mean = sum(means) / float(len(means))
        variance = sum((m - global_mean) ** 2 for m in means) / float(len(means))
        global_std = variance ** 0.5
        
        # Calculate threshold: mean + N*sigma
        threshold = global_mean + (sigma_multiplier * global_std)
        
        logd(u"  [DEPRECATED] Mean noise detection: mean={:.2f}, std={:.2f}, threshold={:.2f}".format(
            global_mean, global_std, threshold))
        logd(u"  WARNING: This method fails for Apotome data - use Otsu or Triangle instead")
        return float(threshold)
        
    except Exception as e:
        logd(u"  Mean noise detection failed: {}".format(e))
        return 0.0

def detect_noise_threshold_otsu(imp, channel_index=1, weighted=False, valley_emphasis=False, apply_constraints=True):
    """
    Otsu's method on Z-profile (RECOMMENDED for Apotome)
    
    Finds threshold that maximizes inter-class variance between
    out-of-focus and in-focus slice populations. This is
    scale-invariant and parameter-free.
    
    Perfect for Apotome where in-focus slices have significantly
    higher intensity due to structured illumination.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
        weighted: If True, uses weighted Otsu to favor rare in-focus slices
        valley_emphasis: If True, forces threshold into valley (best for class imbalance)
        apply_constraints: If True, applies hardening rules (sigma check, percentile padding)
    
    Returns: threshold value (float)
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  Otsu thresholding failed: no valid slices")
            return 0.0
        
        # Calculate baseline statistics (for hardening constraints)
        sorted_means = sorted(means)
        baseline_mean = sum(sorted_means[:len(sorted_means)//2]) / float(len(sorted_means)//2)
        
        # Calculate baseline std dev
        baseline_variance = sum((m - baseline_mean) ** 2 for m in sorted_means[:len(sorted_means)//2]) / float(len(sorted_means)//2)
        baseline_std = baseline_variance ** 0.5
        
        # Apply Otsu's method to the Z-profile
        threshold = otsu_threshold_1d(means, weighted=weighted, valley_emphasis=valley_emphasis)
        
        # Method name for logging
        method_parts = []
        if valley_emphasis:
            method_parts.append("Valley-Emphasis")
        if weighted:
            method_parts.append("Weighted")
        method_parts.append("Otsu")
        method_name = " ".join(method_parts)
        
        logd(u"  {} thresholding on Z-profile: threshold={:.2f}".format(method_name, threshold))
        logd(u"  Z-profile range: [{:.2f}, {:.2f}]".format(min(means), max(means)))
        logd(u"  Baseline: mean={:.2f}, std={:.2f}".format(baseline_mean, baseline_std))
        
        if weighted:
            logd(u"  Using weighted mode to favor rare in-focus slices")
        if valley_emphasis:
            logd(u"  Using valley-emphasis to avoid high-density baseline")
        
        # Apply hardening constraints
        if apply_constraints:
            original_threshold = threshold
            
            # Constraint 1: Sigma Check
            # Threshold must be at least baseline_mean + 2*sigma
            min_threshold_sigma = baseline_mean + (2.0 * baseline_std)
            if threshold < min_threshold_sigma:
                logd(u"  [CONSTRAINT] Sigma check: {:.2f} < {:.2f}, raising threshold".format(
                    threshold, min_threshold_sigma))
                threshold = min_threshold_sigma
            
            # Constraint 2: Percentile Padding
            # Add 10% of dynamic range as safety buffer
            dynamic_range = max(means) - min(means)
            safety_buffer = 0.1 * dynamic_range
            min_threshold_percentile = min(means) + safety_buffer
            if threshold < min_threshold_percentile:
                logd(u"  [CONSTRAINT] Percentile padding: {:.2f} < {:.2f}, raising threshold".format(
                    threshold, min_threshold_percentile))
                threshold = max(threshold, min_threshold_percentile)
            
            # Constraint 3: SNR Gate
            # Check if Peak/Baseline ratio >= 1.5
            peak_signal = max(means)
            snr = peak_signal / baseline_mean if baseline_mean > 0 else 0.0
            logd(u"  Signal-to-Noise Ratio (SNR): {:.2f}".format(snr))
            if snr < 1.5:
                log(u"  !!! WARNING: Low SNR ({:.2f} < 1.5) - Signal may not be well-isolated".format(snr))
                log(u"  !!! Consider manual review of this file")
            
            if threshold != original_threshold:
                logd(u"  Hardened threshold: {:.2f} -> {:.2f}".format(original_threshold, threshold))
        
        return float(threshold)
        
    except Exception as e:
        logd(u"  Otsu thresholding failed: {}".format(e))
        return 0.0

def detect_noise_threshold_triangle(imp, channel_index=1):
    """
    Triangle thresholding on focus scores (RECOMMENDED for Apotome)
    
    Uses Focus Score = mean × std_dev for each slice.
    This combines both observations: in-focus slices have higher
    brightness AND more variance due to structured detail.
    
    Triangle method is designed for distributions with one peak
    (in-focus) and a long tail (out-of-focus background).
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: threshold value (float) applied to mean values
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  Triangle thresholding failed: no valid slices")
            return 0.0
        
        # Calculate focus scores: S_i = mean_i × std_dev_i
        focus_scores = [m * s for m, s in zip(means, std_devs)]
        
        # Apply Triangle thresholding to focus scores
        threshold_score = triangle_threshold_1d(focus_scores)
        
        logd(u"  Triangle thresholding on focus scores: threshold_score={:.2f}".format(threshold_score))
        logd(u"  Focus score range: [{:.2f}, {:.2f}]".format(min(focus_scores), max(focus_scores)))
        
        # Map threshold back to mean values
        # Find slices where focus_score >= threshold_score
        # Use the minimum mean among those slices as the threshold
        valid_means = [means[i] for i in range(len(focus_scores)) if focus_scores[i] >= threshold_score]
        
        if valid_means:
            threshold = min(valid_means)
            logd(u"  Mapped to mean threshold: {:.2f}".format(threshold))
            return float(threshold)
        else:
            # Fallback: use median of means
            threshold = sorted(means)[len(means) // 2]
            logd(u"  Fallback to median mean: {:.2f}".format(threshold))
            return float(threshold)
        
    except Exception as e:
        logd(u"  Triangle thresholding failed: {}".format(e))
        return 0.0

def detect_noise_threshold_cv(imp, channel_index=1):
    """
    Coefficient of Variation (CV) method
    
    CV = std_dev / mean for each slice.
    In-focus slices have higher CV due to structured detail.
    
    Threshold is set at median CV of the stack, then slices
    with CV above this threshold are considered in-focus.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: threshold value (float) applied to mean values
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  CV thresholding failed: no valid slices")
            return 0.0
        
        # Calculate CV for each slice: CV = std_dev / mean
        cvs = []
        for m, s in zip(means, std_devs):
            if m > 0:
                cvs.append(s / m)
            else:
                cvs.append(0.0)
        
        # Find median CV
        sorted_cvs = sorted(cvs)
        median_cv = sorted_cvs[len(sorted_cvs) // 2]
        
        logd(u"  CV method: median_cv={:.4f}".format(median_cv))
        logd(u"  CV range: [{:.4f}, {:.4f}]".format(min(cvs), max(cvs)))
        
        # Find slices with CV above median
        # Use minimum mean among those slices as threshold
        valid_means = [means[i] for i in range(len(cvs)) if cvs[i] >= median_cv]
        
        if valid_means:
            threshold = min(valid_means)
            logd(u"  Mapped to mean threshold: {:.2f}".format(threshold))
            return float(threshold)
        else:
            # Fallback: use median of means
            threshold = sorted(means)[len(means) // 2]
            logd(u"  Fallback to median mean: {:.2f}".format(threshold))
            return float(threshold)
        
    except Exception as e:
        logd(u"  CV thresholding failed: {}".format(e))
        return 0.0

def detect_noise_threshold_sample(imp, channel_index=1, sample_size=0.1):
    """
    Fast noise detection using center region sampling
    
    Only analyzes center region of image (typically less noisy)
    Much faster than full image statistics
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
        sample_size: Fraction of image to sample (0.1 = 10% of pixels)
    
    Returns: threshold value (float)
    """
    try:
        # Set to correct channel if multi-channel
        if imp.getNChannels() > 1:
            imp.setC(channel_index)
        
        # Get processor from middle slice
        mid_slice = imp.getNSlices() // 2
        imp.setZ(mid_slice)
        ip = imp.getProcessor()
        
        width = ip.getWidth()
        height = ip.getHeight()
        
        # Calculate center region
        sample_frac = max(0.05, min(0.5, sample_size))  # Clamp to 5-50%
        sample_width = int(width * sample_frac)
        sample_height = int(height * sample_frac)
        x_start = (width - sample_width) // 2
        y_start = (height - sample_height) // 2
        
        # Sample pixels from center region
        pixel_sum = 0.0
        pixel_count = 0
        
        for y in range(y_start, y_start + sample_height):
            for x in range(x_start, x_start + sample_width):
                pixel_sum += ip.getPixelValue(x, y)
                pixel_count += 1
        
        # Calculate mean of sample
        sample_mean = pixel_sum / pixel_count if pixel_count > 0 else 0.0
        
        # Use sample mean as threshold (conservative)
        threshold = sample_mean
        
        logd(u"  Sample noise detection: sampled {}x{} region, mean={:.2f}".format(
            sample_width, sample_height, threshold))
        return float(threshold)
        
    except Exception as e:
        logd(u"  Sample noise detection failed: {}".format(e))
        return 0.0

def select_layers_by_threshold(imp, threshold_method="valley_otsu", user_threshold=None, 
                                 sigma=3.0, channel_index=1):
    """
    Mode 3: Select layers based on threshold with automatic rejection of artifacts
    
    IMPORTANT: Automatically rejects slices with mean=0 (fusion artifacts)
    
    Args:
        imp: ImagePlus stack
        threshold_method: "valley_otsu", "weighted_otsu", "otsu", "triangle", "cv", "fast", "mean", "sample", or "user"
        user_threshold: User-provided threshold value (if method="user")
        sigma: Sigma multiplier for mean method (default 3.0) - DEPRECATED
        channel_index: Which channel to analyze (1-based)
    
    Returns: (start_slice, stop_slice) or None if no layers meet threshold
    """
    total_slices = imp.getNSlices()
    
    log(u"")
    log(u"=== THRESHOLD-BASED LAYER SELECTION ===")
    log(u"  Total slices: {}".format(total_slices))
    log(u"  Method: {}".format(threshold_method))
    
    # Determine threshold
    if threshold_method == "user" and user_threshold is not None:
        threshold = float(user_threshold)
        log(u"  Using user threshold: {:.2f}".format(threshold))
    elif threshold_method == "valley_otsu":
        threshold = detect_noise_threshold_otsu(imp, channel_index, weighted=False, valley_emphasis=True, apply_constraints=True)
        log(u"  Calculated Valley-Emphasis Otsu threshold: {:.2f}".format(threshold))
    elif threshold_method == "weighted_otsu":
        threshold = detect_noise_threshold_otsu(imp, channel_index, weighted=True, valley_emphasis=False, apply_constraints=True)
        log(u"  Calculated Weighted Otsu threshold: {:.2f}".format(threshold))
    elif threshold_method == "otsu":
        threshold = detect_noise_threshold_otsu(imp, channel_index, weighted=False, valley_emphasis=False, apply_constraints=True)
        log(u"  Calculated Otsu threshold: {:.2f}".format(threshold))
    elif threshold_method == "triangle":
        threshold = detect_noise_threshold_triangle(imp, channel_index)
        log(u"  Calculated Triangle threshold: {:.2f}".format(threshold))
    elif threshold_method == "cv":
        threshold = detect_noise_threshold_cv(imp, channel_index)
        log(u"  Calculated CV threshold: {:.2f}".format(threshold))
    elif threshold_method == "mean":
        threshold = detect_noise_threshold_mean(imp, channel_index, sigma)
        log(u"  Calculated mean+{}*sigma threshold: {:.2f} [DEPRECATED]".format(sigma, threshold))
    elif threshold_method == "sample":
        threshold = detect_noise_threshold_sample(imp, channel_index, 0.1)
        log(u"  Calculated sample threshold: {:.2f}".format(threshold))
    else:  # "fast" is default
        threshold = detect_noise_threshold_fast(imp, channel_index)
        log(u"  Calculated fast threshold: {:.2f}".format(threshold))
    
    # Set to correct channel
    if imp.getNChannels() > 1:
        imp.setC(channel_index)
    
    # Scan all slices and find those above threshold
    # IMPORTANT: Reject slices with mean=0 (fusion artifacts)
    valid_slices = []
    
    for z in range(1, total_slices + 1):
        imp.setZ(z)
        stats = imp.getStatistics(ImageStatistics.MEAN)
        
        # First check: reject mean=0 (fusion artifacts)
        if stats.mean <= 0.0:
            if DEBUG:
                logd(u"    Slice {}: mean={:.2f} [FUSION ARTIFACT - REJECTED]".format(z, stats.mean))
            continue
        
        # Second check: compare to threshold
        if stats.mean > threshold:
            valid_slices.append(z)
            if DEBUG:
                logd(u"    Slice {}: mean={:.2f} > threshold={:.2f} [KEEP]".format(
                    z, stats.mean, threshold))
        else:
            if DEBUG:
                logd(u"    Slice {}: mean={:.2f} <= threshold={:.2f} [DISCARD]".format(
                    z, stats.mean, threshold))
    
    if not valid_slices:
        log(u"!!! ERROR: No slices meet threshold criteria")
        return None
    
    # Find contiguous range (assume slices are sequential)
    start = min(valid_slices)
    stop = max(valid_slices)
    
    log(u"")
    log(u"  Selected slices: {} to {} (total: {})".format(start, stop, stop - start + 1))
    log(u"  Discarded: {} top, {} bottom".format(start - 1, total_slices - stop))
    log(u"")
    
    return (start, stop)

# ==============================================================================
# PART 3: PROJECTION FUNCTIONS (from main.jy - proven patterns)
# ==============================================================================

def create_robust_projection(imp, projection_method, start_slice, stop_slice):
    """
    Create z-projection using proven channel-splitting method.
    Based on working pipeline from main.jy v37.5
    
    Args:
        imp: Source ImagePlus (must be multi-slice stack)
        projection_method: String method name
        start_slice: First slice to include (1-based)
        stop_slice: Last slice to include (1-based)
    
    Returns:
        ImagePlus with projection, or None if failed
    """
    try:
        logd(u"  Creating robust projection using channel-splitting method...")
        logd(u"  Slice range: {} to {}".format(start_slice, stop_slice))
        
        # Store original LUTs for color transfer
        source_luts = None
        if imp.isComposite():
            source_luts = imp.getLuts()
            logd(u"  Retrieved {} LUTs from source".format(len(source_luts) if source_luts else 0))
        
        # Create safe duplicate to work on
        dup = Duplicator().run(imp)
        
        # SPLIT CHANNELS (CRITICAL STABILITY STEP)
        # Processing single channels prevents composite-mode crashes
        channels = ChannelSplitter.split(dup)
        dup.close()  # Free memory
        
        logd(u"  Split into {} channels".format(len(channels)))
        
        # Map method name to ZProjector constant
        method_map = {
            "Max Intensity": ZProjector.MAX_METHOD,
            "Average Intensity": ZProjector.AVG_METHOD,
            "Sum Slices": ZProjector.SUM_METHOD,
            "Standard Deviation": ZProjector.SD_METHOD,
            "Median": ZProjector.MEDIAN_METHOD,
            "Min Intensity": ZProjector.MIN_METHOD
        }
        method_id = method_map.get(projection_method, ZProjector.MAX_METHOD)
        
        # Project each channel individually
        projected_channels = []
        for i, c_imp in enumerate(channels):
            zp = ZProjector(c_imp)
            zp.setMethod(method_id)
            zp.setStartSlice(start_slice)
            zp.setStopSlice(stop_slice)
            zp.doProjection()
            projected_channels.append(zp.getProjection())
            logd(u"    Channel {} projected".format(i + 1))
        
        # MERGE CHANNELS back to Composite
        merged_proj = RGBStackMerge.mergeChannels(projected_channels, False)
        
        # Cleanup split channels to free RAM
        for c_imp in channels:
            c_imp.close()
        System.gc()
        
        logd(u"  Channels merged, {} channels in result".format(merged_proj.getNChannels()))
        
        # Apply original LUTs if available
        if source_luts and merged_proj.getNChannels() > 1:
            # Convert to CompositeImage to apply LUTs
            proj_comp = CompositeImage(merged_proj, CompositeImage.COMPOSITE)
            
            # Apply each LUT
            for i, lut in enumerate(source_luts):
                if i < proj_comp.getNChannels():
                    proj_comp.setChannelLut(lut, i + 1)
            
            # Set COMPOSITE mode
            proj_comp.setMode(CompositeImage.COMPOSITE)
            proj_comp.updateAllChannelsAndDraw()
            
            logd(u"  >>> LUTs applied successfully")
            return proj_comp
        else:
            logd(u"  Returning merged projection without LUT transfer")
            return merged_proj
            
    except Exception as e:
        log(u"!!! Robust projection failed: {}".format(e))
        import traceback
        for line in traceback.format_exc().split('\n'):
            logd(u"  {}".format(line))
        return None

# ==============================================================================
# PART 4: BATCH PROCESSING
# ==============================================================================

def process_batch(input_dir, output_dir, projection_method, layer_mode, 
                  discard_top, discard_bottom, threshold_method, user_threshold,
                  sigma, channel_index, do_show, do_save, file_filter):
    """
    Process all TIFF stacks in input directory
    
    Args:
        input_dir: Directory containing TIFF stacks
        output_dir: Where to save projections
        projection_method: Projection method name
        layer_mode: "all", "discard", or "threshold"
        discard_top: Number of top slices to discard (for discard mode)
        discard_bottom: Number of bottom slices to discard (for discard mode)
        threshold_method: "fast", "mean", "sample", or "user" (for threshold mode)
        user_threshold: User-provided threshold value
        sigma: Sigma multiplier for mean method
        channel_index: Which channel to analyze for threshold (1-based)
        do_show: Whether to display projections
        do_save: Whether to save projections
        file_filter: Filter string for filenames (e.g., "*stitched" or "*projection")
    """
    log(u"")
    log(u"=" * 70)
    log(u"=== STARTING BATCH Z-PROJECTION ===")
    log(u"=" * 70)
    log(u"Input: {}".format(input_dir))
    log(u"Output: {}".format(output_dir))
    log(u"Method: {}".format(projection_method))
    log(u"Layer Mode: {}".format(layer_mode))
    log(u"File Filter: {}".format(file_filter if file_filter else "*.tif (all)"))
    log(u"")
    
    # Find all TIFF files matching the filter
    tif_files = []
    for f in os.listdir(input_dir):
        if not (f.lower().endswith(".tif") or f.lower().endswith(".tiff")):
            continue
        
        # Apply filter if specified
        if file_filter:
            # Remove asterisk if present and convert to lowercase for comparison
            filter_pattern = file_filter.strip().lstrip('*').lower()
            f_lower = f.lower()
            
            # Check if filename contains the filter pattern (before the extension)
            f_base = f_lower.replace('.tif', '').replace('.tiff', '')
            if filter_pattern not in f_base:
                continue
        
        tif_files.append(os.path.join(input_dir, f))
    
    if not tif_files:
        if file_filter:
            log(u"!!! No TIFF files found matching filter: {}".format(file_filter))
        else:
            log(u"!!! No TIFF files found in input directory")
        return
    
    log(u"Found {} TIFF file(s) to process".format(len(tif_files)))
    log_memory()
    
    proj_count = 0
    skip_count = 0
    error_count = 0
    
    for idx, tif_path in enumerate(tif_files):
        try:
            fname = os.path.basename(tif_path)
            base_name = fname.replace(".tif", "").replace(".tiff", "")
            
            log(u"")
            log(u"[{}/{}] Processing: {}".format(idx + 1, len(tif_files), fname))
            
            # Load image
            imp = IJ.openImage(tif_path)
            if imp is None:
                log(u"  !!! Failed to load image, skipping")
                error_count += 1
                continue
            
            num_slices = imp.getNSlices()
            num_channels = imp.getNChannels()
            
            log(u"  Loaded: {} slices, {} channels".format(num_slices, num_channels))
            
            if num_slices <= 1:
                log(u"  Only {} slice(s), skipping projection".format(num_slices))
                imp.close()
                skip_count += 1
                continue
            
            # Determine slice range based on mode
            slice_range = None
            
            if layer_mode == "all":
                slice_range = select_all_layers(imp)
                log(u"  Mode: Using all {} slices".format(num_slices))
                
            elif layer_mode == "discard":
                slice_range = select_discard_layers(imp, discard_top, discard_bottom)
                if slice_range is None:
                    log(u"  !!! Invalid discard parameters, skipping")
                    imp.close()
                    error_count += 1
                    continue
                    
            elif layer_mode == "threshold":
                slice_range = select_layers_by_threshold(
                    imp, threshold_method, user_threshold, sigma, channel_index)
                if slice_range is None:
                    log(u"  !!! No slices meet threshold, skipping")
                    imp.close()
                    skip_count += 1
                    continue
            
            start_slice, stop_slice = slice_range
            num_used_slices = stop_slice - start_slice + 1
            
            # Create projection
            proj_imp = create_robust_projection(imp, projection_method, start_slice, stop_slice)
            
            if proj_imp is None:
                log(u"  !!! Projection creation failed, skipping")
                imp.close()
                error_count += 1
                continue
            
            # Create filename with detailed operation modifier
            # Format: basename_<method>_<operation>.tif
            # Examples: 
            #   - sample_stitched_max_all_32.tif (all 32 slices, max projection)
            #   - sample_stitched_avg_z6to22.tif (slices 6-22, average projection)
            #   - sample_stitched_sum_discard2-3.tif (discarded 2 top, 3 bottom, sum projection)
            
            # Method abbreviation
            method_abbrev = {
                "Max Intensity": "max",
                "Average Intensity": "avg",
                "Sum Slices": "sum",
                "Standard Deviation": "sd",
                "Median": "med",
                "Min Intensity": "min"
            }.get(projection_method, "max")
            
            # Operation descriptor
            if num_used_slices == num_slices:
                # Used all slices
                operation = u"all_{}".format(num_slices)
            elif layer_mode == "discard":
                # Discard mode - record what was discarded
                operation = u"z{}to{}_discard{}-{}".format(
                    start_slice, stop_slice, discard_top, discard_bottom)
            elif layer_mode == "threshold":
                # Threshold mode - record slice range
                operation = u"z{}to{}_thr".format(start_slice, stop_slice)
            else:
                # Generic slice range
                operation = u"z{}to{}".format(start_slice, stop_slice)
            
            proj_filename = u"{}_{}_{}_{}.tif".format(base_name, method_abbrev, operation, num_used_slices)
            
            proj_imp.setTitle(proj_filename.replace(".tif", ""))
            
            # Auto brightness/contrast adjustment
            try:
                if proj_imp.isComposite():
                    log(u"  Applying auto brightness/contrast...")
                    for c in range(1, proj_imp.getNChannels() + 1):
                        proj_imp.setC(c)
                        IJ.run(proj_imp, "Enhance Contrast", "saturated=0.35")
                    proj_imp.setC(1)  # Reset to first channel
                    log(u"  >>> Auto B&C applied to all channels")
                else:
                    IJ.run(proj_imp, "Enhance Contrast", "saturated=0.35")
                    log(u"  >>> Auto B&C applied")
            except Exception as e:
                logd(u"  Auto B&C failed: {}".format(e))
            
            # Save if requested
            if do_save:
                proj_out = os.path.join(output_dir, proj_filename)
                try:
                    IJ.saveAs(proj_imp, "Tiff", proj_out)
                    log(u"  >>> Saved: {}".format(proj_filename))
                    proj_count += 1
                except Exception as e:
                    log(u"  !!! Save failed: {}".format(e))
                    error_count += 1
            
            # Show if requested
            if do_show:
                proj_imp.show()
                log(u"  >>> Displayed projection")
            elif not do_save:
                proj_imp.close()
            
            # Close source image
            imp.close()
            
            # Garbage collection
            System.gc()
            
        except Exception as e:
            log(u"  !!! Processing failed: {}".format(e))
            import traceback
            traceback.print_exc()
            error_count += 1
    
    log(u"")
    log(u"=" * 70)
    log(u"=== BATCH COMPLETE ===")
    log(u"  Processed: {}".format(proj_count))
    log(u"  Skipped: {}".format(skip_count))
    log(u"  Errors: {}".format(error_count))
    log(u"=" * 70)
    log(u"")
    log_memory()

# ==============================================================================
# PART 5: MAIN ENTRY POINT
# ==============================================================================

def show_splash():
    """Display ASCII art splash screen"""
    splash = u"""
      +---+---+---+
      |   Z   |   |    BATCH Z-PROJECTION v1.2
      +---+---+---+     ========================
      | P | r | o |    > Standalone Tool
      +---+---+---+     > Layer Selection
      | j | e | c |    > Valley-Emphasis Otsu
      +---+---+---+     > Batch Processing

      [Standalone] Independent from main.jy
      [Based on] CZI-Stitcher v37.5 patterns
      [New in v1.2] Valley-Emphasis for class imbalance
      [Status] Initializing...
    """
    log(splash)

def main():
    """Main entry point"""
    IJ.log("\\Clear")
    show_splash()
    
    # Load config
    _config = _load_config()
    
    _home = os.path.expanduser("~")
    _last_in = _config.get("last_input_dir", "") or _home
    _last_out = _config.get("last_output_dir", "") or _home
    
    if not os.path.isdir(_last_in): 
        _last_in = _home
    if not os.path.isdir(_last_out): 
        _last_out = _home
    
    # Parameter dialog
    gd = GenericDialog("Batch Z-Projection - Parameters v1.2")
    
    gd.addMessage("=== Directory Paths ===")
    gd.addStringField("Input Folder (TIFF stacks):", _last_in, 50)
    gd.addStringField("Output Folder (Projections):", _last_out, 50)
    
    gd.addMessage("=== File Filter ===")
    gd.addStringField("Filter files containing (leave empty for all):", "stitched", 30)
    gd.addMessage("  Examples: 'stitched', 'projection', 'sample01'")
    gd.addMessage("  Use '*stitched' or just 'stitched' (both work)")
    gd.addMessage("  Leave empty to process ALL .tif files")
    
    gd.addMessage("=== Projection Method ===")
    gd.addChoice("Method", ["Max Intensity", "Average Intensity", "Sum Slices", 
                            "Standard Deviation", "Median", "Min Intensity"], 
                 "Max Intensity")
    
    gd.addMessage("=== Layer Selection Mode ===")
    gd.addChoice("Mode", ["Use all layers", "Discard top/bottom", "Threshold-based"], 
                 "Use all layers")
    
    gd.addMessage("--- Discard Mode Options ---")
    gd.addNumericField("Discard top N slices:", 0, 0)
    gd.addNumericField("Discard bottom N slices:", 0, 0)
    
    gd.addMessage("--- Threshold Mode Options ---")
    gd.addMessage("  BEST for Apotome with class imbalance: Valley-Emphasis Otsu")
    gd.addChoice("Noise detection method", ["Valley-Emphasis Otsu (BEST for Apotome)", 
                                             "Weighted Otsu (for rare signal)",
                                             "Otsu (standard)",
                                             "Triangle (focus scores)",
                                             "CV (coefficient of variation)",
                                             "Fast (histogram min)", 
                                             "Mean + sigma (DEPRECATED)", 
                                             "Sample center (fast)",
                                             "User-defined threshold"],
                 "Valley-Emphasis Otsu (BEST for Apotome)")
    gd.addMessage("  Valley-Emphasis: Handles 90% baseline + 10% signal")
    gd.addMessage("  Includes hardening constraints (sigma check, SNR gate)")
    gd.addMessage("  Note: Mean+sigma fails for Apotome data")
    gd.addNumericField("User threshold (if user-defined):", 0.0, 2)
    gd.addNumericField("Sigma multiplier (for mean method):", 3.0, 1)
    gd.addNumericField("Analyze channel (1-based):", 1, 0)
    
    gd.addMessage("=== Output Options ===")
    gd.addCheckbox("Save Projections", True)
    gd.addCheckbox("Show Projections", False)
    
    gd.showDialog()
    
    if gd.wasCanceled():
        log("User cancelled. Exiting.")
        return
    
    # Get parameters
    in_path = gd.getNextString().strip()
    out_path = gd.getNextString().strip()
    file_filter = gd.getNextString().strip()
    
    # Validate paths
    if not in_path or not os.path.isdir(in_path):
        log(u"!!! Error: Input folder '{}' does not exist or is invalid.".format(in_path))
        return
    if not out_path or not os.path.isdir(out_path):
        log(u"!!! Error: Output folder '{}' does not exist or is invalid.".format(out_path))
        return
    
    # Save config
    _config["last_input_dir"] = in_path
    _config["last_output_dir"] = out_path
    _save_config(_config)
    
    projection_method = gd.getNextChoice()
    layer_mode_choice = gd.getNextChoice()
    
    # Map choice to internal mode name
    if layer_mode_choice == "Use all layers":
        layer_mode = "all"
    elif layer_mode_choice == "Discard top/bottom":
        layer_mode = "discard"
    else:
        layer_mode = "threshold"
    
    discard_top = int(gd.getNextNumber())
    discard_bottom = int(gd.getNextNumber())
    
    threshold_method_choice = gd.getNextChoice()
    # Map choice to internal method name
    if "Valley-Emphasis" in threshold_method_choice:
        threshold_method = "valley_otsu"
    elif "Weighted Otsu" in threshold_method_choice:
        threshold_method = "weighted_otsu"
    elif "Otsu" in threshold_method_choice:
        threshold_method = "otsu"
    elif "Triangle" in threshold_method_choice:
        threshold_method = "triangle"
    elif "CV" in threshold_method_choice or "coefficient" in threshold_method_choice:
        threshold_method = "cv"
    elif "Fast" in threshold_method_choice:
        threshold_method = "fast"
    elif "Mean" in threshold_method_choice:
        threshold_method = "mean"
    elif "Sample" in threshold_method_choice:
        threshold_method = "sample"
    else:
        threshold_method = "user"
    
    user_threshold = float(gd.getNextNumber())
    sigma = float(gd.getNextNumber())
    channel_index = int(gd.getNextNumber())
    
    do_save = (int(gd.getNextBoolean()) == 1)
    do_show = (int(gd.getNextBoolean()) == 1)
    
    # Validate output options
    if not do_save and not do_show:
        log(u"!!! Error: At least one output option must be enabled")
        return
    
    # Log parameters
    log(u"")
    log(u"Parameters:")
    log(u"  File Filter: {}".format(file_filter if file_filter else "None (all .tif files)"))
    log(u"  Projection Method: {}".format(projection_method))
    log(u"  Layer Mode: {}".format(layer_mode))
    
    if layer_mode == "discard":
        log(u"  Discard: {} top, {} bottom".format(discard_top, discard_bottom))
    elif layer_mode == "threshold":
        log(u"  Threshold Method: {}".format(threshold_method))
        if threshold_method == "user":
            log(u"  User Threshold: {:.2f}".format(user_threshold))
        elif threshold_method == "mean":
            log(u"  Sigma Multiplier: {:.1f}".format(sigma))
        log(u"  Analyze Channel: {}".format(channel_index))
    
    log(u"  Save: {} | Show: {}".format(do_save, do_show))
    log(u"")
    
    # Process batch
    batch_start = time.time()
    
    process_batch(in_path, out_path, projection_method, layer_mode,
                  discard_top, discard_bottom, threshold_method, user_threshold,
                  sigma, channel_index, do_show, do_save, file_filter)
    
    batch_elapsed = time.time() - batch_start
    log(u"")
    log(u"Total processing time: {:.1f} seconds ({:.1f} minutes)".format(
        batch_elapsed, batch_elapsed / 60.0))
    log(u"")
    log(u">>> Batch Z-Projection Complete!")

# Run main
if __name__ in [None, "__main__", "__builtin__"]:
    main()
