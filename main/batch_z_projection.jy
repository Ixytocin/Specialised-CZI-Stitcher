# BATCH Z-PROJECTION v1.5
# Standalone tool for batch Z-projection with layer selection
# INDEPENDENT from main.jy - this is a separate pipeline tool
#
# PURPOSE: Process multiple TIFF stacks with flexible Z-layer selection
# FEATURES:
#   - Multiple projection methods (Max, Average, Sum, SD, Median, Min)
#   - Three layer selection modes:
#     1. Use all layers (fastest)
#     2. Discard top/bottom layers (manual trimming)
#     3. Threshold-based selection (noise filtering)
#   - Advanced noise detection for Apotome/SIM data:
#     * Valley-Emphasis Otsu (BEST for class imbalance) - VEO
#     * Weighted Otsu (for rare signal) - WO
#     * Standard Otsu - O
#     * Triangle thresholding on focus scores - TT
#     * Coefficient of Variation (CV) - CV
#     * Fast, Sample center, Mean+sigma, User-defined - F, S, M, U
#   - Detection method acronyms in output filenames for traceability
#   - Threaded discovery phase (dynamic thread allocation based on available RAM)
#   - Phased processing (Discovery → Projection → Display)
#   - Automatic rejection of fusion artifacts (mean=0 slices)
#   - Hardening constraints (sigma check, percentile padding, SNR gate)
#   - Smart file exclusion (checks method + mode + detection method)
#   - Batch processing with progress tracking
#   - Preserves channel colors (LUTs)
#   - Improved brightness/contrast (fixed for channel 1, less bright)
#   - Full unicode support for international filenames
#
# FILENAME FORMAT:
#   {base}_{method}_{operation}_{num_slices}.tif
#   Examples:
#     - sample_stitched_max_all_32.tif          (all layers, max projection)
#     - brain_avg_z6to22_VEO_17.tif             (Valley-Emphasis Otsu, avg projection)
#     - tissue_max_z1to28_TT_28.tif             (Triangle thresholding, max projection)
#     - cells_sum_z5to20_CV_16.tif              (Coefficient of Variation, sum projection)
#     - sample_sd_z10to25_discard2-3_14.tif     (manual discard, SD projection)
#
# BASED ON: Established patterns from main.jy v37.5
# AVOIDS: All documented pitfalls from TECHDOC/PITFALLS.md
#
# v1.5 CHANGES:
# - Fixed unicode encoding errors for German characters (äüßö) throughout
# - Enhanced safe_unicode() to handle Exception objects with unicode in args
# - Removed str(e) calls that caused ASCII codec errors
# - Now properly handles filenames like "Färbung2025-07" in error messages
#
# v1.4 CHANGES:
# - Added detection method acronyms to filenames (VEO, TT, CV, WO, O, F, S, M, U)
# - Updated smart exclusion to check detection method in threshold mode
# - Filenames now include method signage for full traceability
# - Fixed unicode handling throughout (äüßö support)
# - Simplified UI with single consolidated dropdown
#
# v1.3 CHANGES:
# - Added threaded discovery phase with dynamic thread allocation (up to 80% free RAM)
# - Phased processing: Discovery (parallel) → Projection → Display (deferred)
# - Excludes already-projected files (_max_, _avg_, etc. suffixes)
# - Fixed brightness/contrast application for channel 1 on large files (added 100ms delay)
# - Reduced brightness: saturated=0.10 instead of 0.35 (less bright colors)
# - Memory cleanup after each phase
# - Temp files written during discovery, cleaned up after completion
#
# v1.2 CHANGES:
# - Added Valley-Emphasis Otsu for extreme class imbalance (90% baseline + 10% signal)
# - Added hardening constraints: sigma check, percentile padding, SNR gate
# - Valley-Emphasis forces threshold into valley between baseline and signal
# - SNR < 1.5 triggers warning for manual review
# - Prevents threshold from settling on flat, even baseline
#
# v1.1 CHANGES:
# - Added Otsu's method for Apotome structured illumination data
# - Added Triangle thresholding on focus scores (mean × std_dev)
# - Added Coefficient of Variation (CV) method
# - Automatic rejection of slices with mean=0 (fusion artifacts)
# - Deprecated naive mean+sigma method (fails for Apotome)

import os, time, codecs, json, sys, re, tempfile
from java.lang import Runtime, System, Thread
from java.util.concurrent import Executors, Callable, Future
from java.awt import Color
from ij import IJ, ImagePlus, WindowManager, CompositeImage
from ij.plugin import ZProjector, ChannelSplitter, RGBStackMerge, Duplicator
from ij.process import ImageStatistics
from ij.gui import GenericDialog
from java.io import File

# ==============================================================================
# VERSION AND CONFIGURATION
# ==============================================================================
VERSION = "v1.5"
MICRO = u"\u00b5"

# Debug flags
VERBOSE = True
DEBUG = True

# Config file for remembering last used directories
_CONFIG_PATH = os.path.join(os.path.expanduser("~"), ".batch_z_projection_config.json")

# ==============================================================================
# PART 1: UTILITY FUNCTIONS (from main.jy - proven patterns)
# ==============================================================================

def ensure_unicode(o):
    """Convert any object to unicode safely"""
    if o is None:
        return None
    if isinstance(o, unicode):
        return o
    
    try:
        result = unicode(bytearray(o.getBytes("UTF-8")), 'utf-8', 'replace')
        return result
    except:
        pass
    
    try:
        result = unicode(o, 'utf-8', 'replace')
        return result
    except:
        pass
    
    try:
        result = unicode(str(o), 'utf-8', 'replace')
        return result
    except:
        pass
    
    try:
        return u"%s" % o
    except:
        return u""

def safe_unicode(o):
    """Safe unicode conversion with fallback"""
    # Special handling for exceptions - they may contain unicode filenames
    if isinstance(o, Exception):
        try:
            # Try to get the args which may contain unicode
            if hasattr(o, 'args') and o.args:
                return u" ".join([safe_unicode(arg) for arg in o.args])
            else:
                return u"{}".format(type(o).__name__)
        except:
            pass
    
    try:
        return ensure_unicode(o)
    except:
        try:
            return unicode(o)
        except:
            try:
                return u"%s" % o
            except:
                return u"<unrepresentable>"

def log(msg):
    """Thread-safe logging with unicode support"""
    try:
        IJ.log(u"[Z-Proj] {}".format(safe_unicode(msg)))
    except UnicodeEncodeError:
        try:
            IJ.log("[Z-Proj] <message contains unsupported characters>")
        except:
            pass
    except:
        try:
            IJ.log(str(msg))
        except:
            pass

def logv(msg):
    """Verbose logging"""
    if VERBOSE:
        log(u"[VERBOSE] {}".format(msg))

def logd(msg):
    """Debug logging"""
    if DEBUG:
        log(u"[DEBUG] {}".format(msg))

def format_elapsed_time(seconds):
    """
    Format elapsed time in minutes, seconds, milliseconds
    
    Args:
        seconds: Elapsed time in seconds (float)
    
    Returns: Formatted string like "5m 23s 456ms" or "45s 123ms"
    """
    total_ms = int(seconds * 1000)
    
    minutes = total_ms // 60000
    remaining_ms = total_ms % 60000
    
    secs = remaining_ms // 1000
    ms = remaining_ms % 1000
    
    if minutes > 0:
        return u"{}m {}s {}ms".format(minutes, secs, ms)
    elif secs > 0:
        return u"{}s {}ms".format(secs, ms)
    else:
        return u"{}ms".format(ms)

def log_memory():
    """Log current memory usage"""
    try:
        runtime = Runtime.getRuntime()
        total_mb = runtime.totalMemory() / (1024.0 * 1024.0)
        free_mb = runtime.freeMemory() / (1024.0 * 1024.0)
        used_mb = total_mb - free_mb
        max_mb = runtime.maxMemory() / (1024.0 * 1024.0)
        log(u"[MEMORY] Used: {:.1f}MB / Total: {:.1f}MB / Max: {:.1f}MB".format(used_mb, total_mb, max_mb))
        return (used_mb, total_mb, max_mb, free_mb)
    except Exception as e:
        logd(u"Memory logging failed: {}".format(e))
        return (0, 0, 0, 0)

def calculate_optimal_threads(file_size_mb, target_ram_usage_percent=0.8):
    """
    Calculate optimal number of threads based on available RAM
    
    Args:
        file_size_mb: Estimated size per file in MB
        target_ram_usage_percent: Target percentage of free RAM to use (default 0.8 = 80%)
    
    Returns: number of threads (minimum 1, maximum CPU cores)
    """
    try:
        runtime = Runtime.getRuntime()
        max_mb = runtime.maxMemory() / (1024.0 * 1024.0)
        used_mb = (runtime.totalMemory() - runtime.freeMemory()) / (1024.0 * 1024.0)
        free_mb = max_mb - used_mb
        
        # Calculate how much RAM we can allocate (80% of free)
        available_for_threads = free_mb * target_ram_usage_percent
        
        # Estimate threads based on file size (conservative: assume 2x file size per thread)
        memory_per_thread = max(file_size_mb * 2.0, 500.0)  # Minimum 500MB per thread
        threads_by_memory = int(available_for_threads / memory_per_thread)
        
        # Limit by CPU cores
        cpu_cores = runtime.availableProcessors()
        max_threads = max(cpu_cores - 1, 1) if cpu_cores > 1 else 1
        
        # Final thread count
        optimal_threads = max(1, min(threads_by_memory, max_threads))
        
        logd(u"  Thread calculation: free={:.1f}MB, available={:.1f}MB, file_size={:.1f}MB".format(
            free_mb, available_for_threads, file_size_mb))
        logd(u"  CPU cores={}, memory_threads={}, optimal_threads={}".format(
            cpu_cores, threads_by_memory, optimal_threads))
        
        return optimal_threads
        
    except Exception as e:
        logd(u"  Thread calculation failed: {}, defaulting to 1 thread".format(e))
        return 1

def _load_config():
    """Load last used directories from config file"""
    logd(u"Loading config from: {}".format(_CONFIG_PATH))
    try:
        if os.path.exists(_CONFIG_PATH):
            with codecs.open(_CONFIG_PATH, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
                logd(u"Config loaded: {}".format(cfg))
                return cfg
        else:
            logd(u"Config file does not exist, using defaults")
    except Exception as e:
        logd(u"Config load failed: {}".format(e))
    return {}

def _save_config(cfg):
    """Save directories to config file"""
    logd(u"Saving config: {}".format(cfg))
    try:
        with codecs.open(_CONFIG_PATH, 'w', encoding='utf-8') as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
            logd(u"Config saved successfully")
    except Exception as e:
        logd(u"Config save failed: {}".format(e))

# ==============================================================================
# PART 2: DISCOVERY PHASE (Parallel Z-Profile Calculation)
# ==============================================================================

class DiscoveryTask(Callable):
    """
    Callable task for parallel Z-profile discovery
    
    Processes one file to calculate Z-profile and determine slice range,
    then writes results to temp file for later projection phase.
    """
    def __init__(self, tif_path, layer_mode, discard_top, discard_bottom, 
                 threshold_method, user_threshold, sigma, channel_index, temp_dir):
        self.tif_path = tif_path
        self.layer_mode = layer_mode
        self.discard_top = discard_top
        self.discard_bottom = discard_bottom
        self.threshold_method = threshold_method
        self.user_threshold = user_threshold
        self.sigma = sigma
        self.channel_index = channel_index
        self.temp_dir = temp_dir
        self.fname = safe_unicode(os.path.basename(tif_path))
    
    def call(self):
        """Execute discovery for this file"""
        result = {
            'file': self.tif_path,
            'fname': self.fname,
            'success': False,
            'error': None,
            'num_slices': 0,
            'num_channels': 0,
            'slice_range': None,
            'skip': False,
            'skip_reason': None
        }
        
        try:
            # Load image (read-only for discovery)
            imp = IJ.openImage(self.tif_path)
            if imp is None:
                result['error'] = safe_unicode("Failed to load image")
                return result
            
            result['num_slices'] = imp.getNSlices()
            result['num_channels'] = imp.getNChannels()
            
            # Check if projection is needed
            if result['num_slices'] <= 1:
                result['skip'] = True
                result['skip_reason'] = safe_unicode("Only {} slice(s)".format(result['num_slices']))
                imp.close()
                return result
            
            # Determine slice range based on mode
            if self.layer_mode == "all":
                result['slice_range'] = select_all_layers(imp)
                result['success'] = True
                
            elif self.layer_mode == "discard":
                slice_range = select_discard_layers(imp, self.discard_top, self.discard_bottom)
                if slice_range is None:
                    result['error'] = safe_unicode("Invalid discard parameters")
                else:
                    result['slice_range'] = slice_range
                    result['success'] = True
                    
            elif self.layer_mode == "threshold":
                slice_range = select_layers_by_threshold(
                    imp, self.threshold_method, self.user_threshold, 
                    self.sigma, self.channel_index)
                if slice_range is None:
                    result['skip'] = True
                    result['skip_reason'] = safe_unicode("No slices meet threshold")
                else:
                    result['slice_range'] = slice_range
                    result['success'] = True
            
            # Close image to free memory
            imp.close()
            System.gc()
            
            # Write result to temp file
            if result['success'] or result['skip']:
                temp_file = os.path.join(self.temp_dir, "{}.json".format(
                    safe_unicode(self.fname).replace('.tif', '').replace('.tiff', '')))
                with codecs.open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                result['temp_file'] = temp_file
            
            return result
            
        except Exception as e:
            result['error'] = safe_unicode(e)
            return result

def run_discovery_phase(tif_files, layer_mode, discard_top, discard_bottom,
                        threshold_method, user_threshold, sigma, channel_index,
                        num_threads):
    """
    Run discovery phase in parallel to calculate Z-profiles and slice ranges
    
    Args:
        tif_files: List of TIFF file paths
        layer_mode: "all", "discard", or "threshold"
        discard_top: Number of top slices to discard
        discard_bottom: Number of bottom slices to discard
        threshold_method: Threshold detection method
        user_threshold: User-provided threshold value
        sigma: Sigma multiplier
        channel_index: Channel to analyze
        num_threads: Number of parallel threads to use
    
    Returns: (discovery_results[], temp_dir)
    """
    log(u"")
    log(u"=" * 70)
    log(u"=== DISCOVERY PHASE: Z-Profile Analysis ===")
    log(u"=" * 70)
    log(u"  Files: {}".format(len(tif_files)))
    log(u"  Threads: {}".format(num_threads))
    log(u"  Mode: {}".format(layer_mode))
    log(u"")
    
    # Create temporary directory for results
    temp_dir = tempfile.mkdtemp(prefix="batch_z_proj_")
    logd(u"  Temp directory: {}".format(temp_dir))
    
    # Create thread pool
    executor = Executors.newFixedThreadPool(num_threads)
    
    # Submit all tasks
    futures = []
    for tif_path in tif_files:
        task = DiscoveryTask(tif_path, layer_mode, discard_top, discard_bottom,
                            threshold_method, user_threshold, sigma, channel_index,
                            temp_dir)
        future = executor.submit(task)
        futures.append((tif_path, future))
    
    # Collect results as they complete
    discovery_results = []
    completed = 0
    
    for tif_path, future in futures:
        try:
            result = future.get()  # Wait for completion
            discovery_results.append(result)
            completed += 1
            
            # Log progress with proper unicode handling
            fname = safe_unicode(os.path.basename(tif_path))
            if result.get('success'):
                log(u"  [{}/{}] >>> {} - Discovered: slices {}".format(
                    completed, len(tif_files), fname, result.get('slice_range')))
            elif result.get('skip'):
                log(u"  [{}/{}] SKIP {} - {}".format(
                    completed, len(tif_files), fname, safe_unicode(result.get('skip_reason'))))
            elif result.get('error'):
                log(u"  [{}/{}] !!! {} - ERROR: {}".format(
                    completed, len(tif_files), fname, safe_unicode(result.get('error'))))
            
        except Exception as e:
            log(u"  !!! Discovery task failed for {}: {}".format(safe_unicode(os.path.basename(tif_path)), safe_unicode(e)))
            discovery_results.append({
                'file': tif_path,
                'fname': safe_unicode(os.path.basename(tif_path)),
                'success': False,
                'error': safe_unicode(e)
            })
            completed += 1
    
    # Shutdown executor
    executor.shutdown()
    
    log(u"")
    log(u"=== DISCOVERY COMPLETE ===")
    log(u"  Successful: {}".format(sum(1 for r in discovery_results if r.get('success'))))
    log(u"  Skipped: {}".format(sum(1 for r in discovery_results if r.get('skip'))))
    log(u"  Errors: {}".format(sum(1 for r in discovery_results if r.get('error'))))
    log(u"")
    
    # Force garbage collection after discovery
    System.gc()
    log_memory()
    
    return (discovery_results, temp_dir)

# ==============================================================================
# PART 3: LAYER SELECTION METHODS
# ==============================================================================

def select_all_layers(imp):
    """
    Mode 1: Use all layers (fastest)
    
    Returns: (start_slice, stop_slice)
    """
    return (1, imp.getNSlices())

def select_discard_layers(imp, discard_top, discard_bottom):
    """
    Mode 2: Discard x top and y bottom layers
    
    Args:
        imp: ImagePlus stack
        discard_top: Number of top slices to discard
        discard_bottom: Number of bottom slices to discard
    
    Returns: (start_slice, stop_slice) or None if invalid
    """
    total_slices = imp.getNSlices()
    
    # Validate
    if discard_top + discard_bottom >= total_slices:
        log(u"!!! ERROR: Cannot discard {} top + {} bottom from {} total slices".format(
            discard_top, discard_bottom, total_slices))
        return None
    
    start = 1 + discard_top
    stop = total_slices - discard_bottom
    
    log(u"  Discarding {} top and {} bottom slices".format(discard_top, discard_bottom))
    log(u"  Using slices {} to {} (total: {})".format(start, stop, stop - start + 1))
    
    return (start, stop)

def calculate_z_profile(imp, channel_index=1):
    """
    Calculate mean and standard deviation for each Z-slice
    
    This creates a profile of intensity across the Z-stack,
    which is used by advanced thresholding methods.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: tuple of (means[], std_devs[], valid_indices[])
             valid_indices excludes slices with mean=0 (fusion artifacts)
    """
    total_slices = imp.getNSlices()
    means = []
    std_devs = []
    valid_indices = []
    
    # Set to correct channel
    if imp.getNChannels() > 1:
        imp.setC(channel_index)
    
    for z in range(1, total_slices + 1):
        imp.setZ(z)
        stats = imp.getStatistics(ImageStatistics.MEAN + ImageStatistics.STD_DEV)
        
        # Reject slices with mean=0 (fusion artifacts)
        if stats.mean > 0.0:
            means.append(stats.mean)
            std_devs.append(stats.stdDev)
            valid_indices.append(z)
        else:
            logd(u"    Slice {}: mean=0.0 [FUSION ARTIFACT - REJECTED]".format(z))
    
    return (means, std_devs, valid_indices)

def otsu_threshold_1d(values, weighted=False, valley_emphasis=False):
    """
    Apply Otsu's method to 1D array (Z-profile)
    
    Finds threshold that maximizes inter-class variance between
    two populations (out-of-focus vs in-focus slices).
    
    Args:
        values: List of intensity values (e.g., mean per slice)
        weighted: If True, uses weighted Otsu to favor rare in-focus slices
        valley_emphasis: If True, penalizes thresholds on high-density peaks
                        (forces threshold into valley between baseline and signal)
    
    Returns: threshold value (float)
    """
    if not values or len(values) < 2:
        return 0.0
    
    # Sort values to find optimal threshold
    sorted_vals = sorted(values)
    min_val = sorted_vals[0]
    max_val = sorted_vals[-1]
    
    # Create histogram with 256 bins
    num_bins = min(256, len(values))
    bin_width = (max_val - min_val) / float(num_bins) if max_val > min_val else 1.0
    
    # Build histogram
    histogram = [0] * num_bins
    for v in values:
        bin_idx = int((v - min_val) / bin_width)
        if bin_idx >= num_bins:
            bin_idx = num_bins - 1
        histogram[bin_idx] += 1
    
    # Calculate total weight and mean
    total = sum(histogram)
    sum_total = sum(i * histogram[i] for i in range(num_bins))
    
    # Find threshold that maximizes inter-class variance (or weighted/valley-emphasis variance)
    best_threshold = 0
    best_variance = 0.0
    
    weight_background = 0
    sum_background = 0.0
    
    for t in range(num_bins):
        weight_background += histogram[t]
        if weight_background == 0:
            continue
        
        weight_foreground = total - weight_background
        if weight_foreground == 0:
            break
        
        sum_background += t * histogram[t]
        sum_foreground = sum_total - sum_background
        
        mean_background = sum_background / float(weight_background)
        mean_foreground = sum_foreground / float(weight_foreground)
        
        # Inter-class variance
        variance = weight_background * weight_foreground * (mean_background - mean_foreground) ** 2
        
        # Weighted Otsu: multiply by foreground weight to favor rare in-focus slices
        if weighted:
            # Give more importance to the smaller class (typically in-focus slices)
            # This helps when in-focus is only 10-20% of stack
            weight_ratio = float(weight_foreground) / float(total)
            variance = variance * (1.0 + weight_ratio)
        
        # Valley-Emphasis: penalize thresholds on high-density peaks
        # Forces threshold into "valley" between even baseline and signal
        if valley_emphasis:
            # p_t = probability (frequency) at threshold
            p_t = float(histogram[t]) / float(total)
            # Multiply by (1 - p_t) to favor low-density regions
            variance = variance * (1.0 - p_t)
        
        if variance > best_variance:
            best_variance = variance
            best_threshold = t
    
    # Convert bin index back to actual value
    threshold = min_val + (best_threshold * bin_width)
    return float(threshold)

def triangle_threshold_1d(values):
    """
    Apply Triangle thresholding to 1D array
    
    Designed for distributions with one clear peak and a long tail.
    Finds the point of maximum distance from a line drawn between
    the peak and the end of the tail.
    
    Args:
        values: List of intensity values
    
    Returns: threshold value (float)
    """
    if not values or len(values) < 2:
        return 0.0
    
    sorted_vals = sorted(values)
    min_val = sorted_vals[0]
    max_val = sorted_vals[-1]
    
    # Create histogram
    num_bins = min(256, len(values))
    bin_width = (max_val - min_val) / float(num_bins) if max_val > min_val else 1.0
    
    histogram = [0] * num_bins
    for v in values:
        bin_idx = int((v - min_val) / bin_width)
        if bin_idx >= num_bins:
            bin_idx = num_bins - 1
        histogram[bin_idx] += 1
    
    # Find peak (maximum in histogram)
    peak_idx = 0
    peak_val = histogram[0]
    for i in range(1, num_bins):
        if histogram[i] > peak_val:
            peak_val = histogram[i]
            peak_idx = i
    
    # Determine tail direction (left or right of peak)
    # Assume tail is on the right (out-of-focus slices have lower values)
    tail_idx = num_bins - 1
    
    # If peak is on right, tail is on left
    if peak_idx > num_bins // 2:
        tail_idx = 0
    
    # Calculate distances from line between peak and tail
    max_distance = 0.0
    threshold_idx = peak_idx
    
    # Line from (peak_idx, peak_val) to (tail_idx, histogram[tail_idx])
    dx = float(tail_idx - peak_idx)
    dy = float(histogram[tail_idx] - peak_val)
    
    if abs(dx) < 1e-6:  # Vertical line
        threshold_idx = peak_idx
    else:
        # For each point, calculate perpendicular distance to line
        for i in range(min(peak_idx, tail_idx), max(peak_idx, tail_idx) + 1):
            # Point is (i, histogram[i])
            # Distance from point to line ax + by + c = 0
            # Line: (y - peak_val) = (dy/dx) * (x - peak_idx)
            # Rearranged: dy*x - dx*y + (dx*peak_val - dy*peak_idx) = 0
            
            numerator = abs(dy * i - dx * histogram[i] + (dx * peak_val - dy * peak_idx))
            denominator = (dx * dx + dy * dy) ** 0.5
            
            if denominator > 1e-6:
                distance = numerator / denominator
                if distance > max_distance:
                    max_distance = distance
                    threshold_idx = i
    
    # Convert bin index to actual value
    threshold = min_val + (threshold_idx * bin_width)
    return float(threshold)

def detect_noise_threshold_fast(imp, channel_index=1):
    """
    Fast noise detection using histogram minimum value
    
    This is faster than calculating mean because it only needs
    to scan pixel values, not sum them.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: threshold value (float)
    """
    try:
        # Set to correct channel if multi-channel
        if imp.getNChannels() > 1:
            imp.setC(channel_index)
        
        # Get statistics from middle slice (representative)
        mid_slice = imp.getNSlices() // 2
        imp.setZ(mid_slice)
        
        stats = imp.getStatistics(ImageStatistics.MIN_MAX)
        
        # Use minimum value as baseline
        threshold = stats.min
        
        logd(u"  Fast noise detection: min={:.2f}".format(threshold))
        return float(threshold)
        
    except Exception as e:
        logd(u"  Fast noise detection failed: {}".format(e))
        return 0.0

def detect_noise_threshold_mean(imp, channel_index=1, sigma_multiplier=3.0):
    """
    DEPRECATED: Naive mean + sigma approach fails for Apotome data
    
    This method is kept for compatibility but is NOT recommended
    for structured illumination (Apotome) data where signal
    magnitudes vary greatly.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
        sigma_multiplier: How many standard deviations above mean (default 3.0)
    
    Returns: threshold value (float)
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  Mean noise detection failed: no valid slices")
            return 0.0
        
        # Calculate global mean and std dev across all slices
        global_mean = sum(means) / float(len(means))
        variance = sum((m - global_mean) ** 2 for m in means) / float(len(means))
        global_std = variance ** 0.5
        
        # Calculate threshold: mean + N*sigma
        threshold = global_mean + (sigma_multiplier * global_std)
        
        logd(u"  [DEPRECATED] Mean noise detection: mean={:.2f}, std={:.2f}, threshold={:.2f}".format(
            global_mean, global_std, threshold))
        logd(u"  WARNING: This method fails for Apotome data - use Otsu or Triangle instead")
        return float(threshold)
        
    except Exception as e:
        logd(u"  Mean noise detection failed: {}".format(e))
        return 0.0

def detect_noise_threshold_otsu(imp, channel_index=1, weighted=False, valley_emphasis=False, apply_constraints=True):
    """
    Otsu's method on Z-profile (RECOMMENDED for Apotome)
    
    Finds threshold that maximizes inter-class variance between
    out-of-focus and in-focus slice populations. This is
    scale-invariant and parameter-free.
    
    Perfect for Apotome where in-focus slices have significantly
    higher intensity due to structured illumination.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
        weighted: If True, uses weighted Otsu to favor rare in-focus slices
        valley_emphasis: If True, forces threshold into valley (best for class imbalance)
        apply_constraints: If True, applies hardening rules (sigma check, percentile padding)
    
    Returns: threshold value (float)
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  Otsu thresholding failed: no valid slices")
            return 0.0
        
        # Calculate baseline statistics (for hardening constraints)
        sorted_means = sorted(means)
        baseline_mean = sum(sorted_means[:len(sorted_means)//2]) / float(len(sorted_means)//2)
        
        # Calculate baseline std dev
        baseline_variance = sum((m - baseline_mean) ** 2 for m in sorted_means[:len(sorted_means)//2]) / float(len(sorted_means)//2)
        baseline_std = baseline_variance ** 0.5
        
        # Apply Otsu's method to the Z-profile
        threshold = otsu_threshold_1d(means, weighted=weighted, valley_emphasis=valley_emphasis)
        
        # Method name for logging
        method_parts = []
        if valley_emphasis:
            method_parts.append("Valley-Emphasis")
        if weighted:
            method_parts.append("Weighted")
        method_parts.append("Otsu")
        method_name = " ".join(method_parts)
        
        logd(u"  {} thresholding on Z-profile: threshold={:.2f}".format(method_name, threshold))
        logd(u"  Z-profile range: [{:.2f}, {:.2f}]".format(min(means), max(means)))
        logd(u"  Baseline: mean={:.2f}, std={:.2f}".format(baseline_mean, baseline_std))
        
        if weighted:
            logd(u"  Using weighted mode to favor rare in-focus slices")
        if valley_emphasis:
            logd(u"  Using valley-emphasis to avoid high-density baseline")
        
        # Apply hardening constraints
        if apply_constraints:
            original_threshold = threshold
            
            # Constraint 1: Sigma Check
            # Threshold must be at least baseline_mean + 2*sigma
            min_threshold_sigma = baseline_mean + (2.0 * baseline_std)
            if threshold < min_threshold_sigma:
                logd(u"  [CONSTRAINT] Sigma check: {:.2f} < {:.2f}, raising threshold".format(
                    threshold, min_threshold_sigma))
                threshold = min_threshold_sigma
            
            # Constraint 2: Percentile Padding
            # Add 10% of dynamic range as safety buffer
            dynamic_range = max(means) - min(means)
            safety_buffer = 0.1 * dynamic_range
            min_threshold_percentile = min(means) + safety_buffer
            if threshold < min_threshold_percentile:
                logd(u"  [CONSTRAINT] Percentile padding: {:.2f} < {:.2f}, raising threshold".format(
                    threshold, min_threshold_percentile))
                threshold = max(threshold, min_threshold_percentile)
            
            # Constraint 3: SNR Gate
            # Check if Peak/Baseline ratio >= 1.5
            peak_signal = max(means)
            snr = peak_signal / baseline_mean if baseline_mean > 0 else 0.0
            logd(u"  Signal-to-Noise Ratio (SNR): {:.2f}".format(snr))
            if snr < 1.5:
                log(u"  !!! WARNING: Low SNR ({:.2f} < 1.5) - Signal may not be well-isolated".format(snr))
                log(u"  !!! Consider manual review of this file")
            
            if threshold != original_threshold:
                logd(u"  Hardened threshold: {:.2f} -> {:.2f}".format(original_threshold, threshold))
        
        return float(threshold)
        
    except Exception as e:
        logd(u"  Otsu thresholding failed: {}".format(e))
        return 0.0

def detect_noise_threshold_triangle(imp, channel_index=1):
    """
    Triangle thresholding on focus scores (RECOMMENDED for Apotome)
    
    Uses Focus Score = mean × std_dev for each slice.
    This combines both observations: in-focus slices have higher
    brightness AND more variance due to structured detail.
    
    Triangle method is designed for distributions with one peak
    (in-focus) and a long tail (out-of-focus background).
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: threshold value (float) applied to mean values
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  Triangle thresholding failed: no valid slices")
            return 0.0
        
        # Calculate focus scores: S_i = mean_i × std_dev_i
        focus_scores = [m * s for m, s in zip(means, std_devs)]
        
        # Apply Triangle thresholding to focus scores
        threshold_score = triangle_threshold_1d(focus_scores)
        
        logd(u"  Triangle thresholding on focus scores: threshold_score={:.2f}".format(threshold_score))
        logd(u"  Focus score range: [{:.2f}, {:.2f}]".format(min(focus_scores), max(focus_scores)))
        
        # Map threshold back to mean values
        # Find slices where focus_score >= threshold_score
        # Use the minimum mean among those slices as the threshold
        valid_means = [means[i] for i in range(len(focus_scores)) if focus_scores[i] >= threshold_score]
        
        if valid_means:
            threshold = min(valid_means)
            logd(u"  Mapped to mean threshold: {:.2f}".format(threshold))
            return float(threshold)
        else:
            # Fallback: use median of means
            threshold = sorted(means)[len(means) // 2]
            logd(u"  Fallback to median mean: {:.2f}".format(threshold))
            return float(threshold)
        
    except Exception as e:
        logd(u"  Triangle thresholding failed: {}".format(e))
        return 0.0

def detect_noise_threshold_cv(imp, channel_index=1):
    """
    Coefficient of Variation (CV) method
    
    CV = std_dev / mean for each slice.
    In-focus slices have higher CV due to structured detail.
    
    Threshold is set at median CV of the stack, then slices
    with CV above this threshold are considered in-focus.
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
    
    Returns: threshold value (float) applied to mean values
    """
    try:
        # Calculate Z-profile
        means, std_devs, valid_indices = calculate_z_profile(imp, channel_index)
        
        if not means:
            logd(u"  CV thresholding failed: no valid slices")
            return 0.0
        
        # Calculate CV for each slice: CV = std_dev / mean
        cvs = []
        for m, s in zip(means, std_devs):
            if m > 0:
                cvs.append(s / m)
            else:
                cvs.append(0.0)
        
        # Find median CV
        sorted_cvs = sorted(cvs)
        median_cv = sorted_cvs[len(sorted_cvs) // 2]
        
        logd(u"  CV method: median_cv={:.4f}".format(median_cv))
        logd(u"  CV range: [{:.4f}, {:.4f}]".format(min(cvs), max(cvs)))
        
        # Find slices with CV above median
        # Use minimum mean among those slices as threshold
        valid_means = [means[i] for i in range(len(cvs)) if cvs[i] >= median_cv]
        
        if valid_means:
            threshold = min(valid_means)
            logd(u"  Mapped to mean threshold: {:.2f}".format(threshold))
            return float(threshold)
        else:
            # Fallback: use median of means
            threshold = sorted(means)[len(means) // 2]
            logd(u"  Fallback to median mean: {:.2f}".format(threshold))
            return float(threshold)
        
    except Exception as e:
        logd(u"  CV thresholding failed: {}".format(e))
        return 0.0

def detect_noise_threshold_sample(imp, channel_index=1, sample_size=0.1):
    """
    Fast noise detection using center region sampling
    
    Only analyzes center region of image (typically less noisy)
    Much faster than full image statistics
    
    Args:
        imp: ImagePlus stack
        channel_index: Which channel to analyze (1-based)
        sample_size: Fraction of image to sample (0.1 = 10% of pixels)
    
    Returns: threshold value (float)
    """
    try:
        # Set to correct channel if multi-channel
        if imp.getNChannels() > 1:
            imp.setC(channel_index)
        
        # Get processor from middle slice
        mid_slice = imp.getNSlices() // 2
        imp.setZ(mid_slice)
        ip = imp.getProcessor()
        
        width = ip.getWidth()
        height = ip.getHeight()
        
        # Calculate center region
        sample_frac = max(0.05, min(0.5, sample_size))  # Clamp to 5-50%
        sample_width = int(width * sample_frac)
        sample_height = int(height * sample_frac)
        x_start = (width - sample_width) // 2
        y_start = (height - sample_height) // 2
        
        # Sample pixels from center region
        pixel_sum = 0.0
        pixel_count = 0
        
        for y in range(y_start, y_start + sample_height):
            for x in range(x_start, x_start + sample_width):
                pixel_sum += ip.getPixelValue(x, y)
                pixel_count += 1
        
        # Calculate mean of sample
        sample_mean = pixel_sum / pixel_count if pixel_count > 0 else 0.0
        
        # Use sample mean as threshold (conservative)
        threshold = sample_mean
        
        logd(u"  Sample noise detection: sampled {}x{} region, mean={:.2f}".format(
            sample_width, sample_height, threshold))
        return float(threshold)
        
    except Exception as e:
        logd(u"  Sample noise detection failed: {}".format(e))
        return 0.0

def select_layers_by_threshold(imp, threshold_method="valley_otsu", user_threshold=None, 
                                 sigma=3.0, channel_index=1):
    """
    Mode 3: Select layers based on threshold with automatic rejection of artifacts
    
    IMPORTANT: Automatically rejects slices with mean=0 (fusion artifacts)
    
    Args:
        imp: ImagePlus stack
        threshold_method: "valley_otsu", "weighted_otsu", "otsu", "triangle", "cv", "fast", "mean", "sample", or "user"
        user_threshold: User-provided threshold value (if method="user")
        sigma: Sigma multiplier for mean method (default 3.0) - DEPRECATED
        channel_index: Which channel to analyze (1-based)
    
    Returns: (start_slice, stop_slice) or None if no layers meet threshold
    """
    total_slices = imp.getNSlices()
    
    log(u"")
    log(u"=== THRESHOLD-BASED LAYER SELECTION ===")
    log(u"  Total slices: {}".format(total_slices))
    log(u"  Method: {}".format(threshold_method))
    
    # Determine threshold
    if threshold_method == "user" and user_threshold is not None:
        threshold = float(user_threshold)
        log(u"  Using user threshold: {:.2f}".format(threshold))
    elif threshold_method == "valley_otsu":
        threshold = detect_noise_threshold_otsu(imp, channel_index, weighted=False, valley_emphasis=True, apply_constraints=True)
        log(u"  Calculated Valley-Emphasis Otsu threshold: {:.2f}".format(threshold))
    elif threshold_method == "weighted_otsu":
        threshold = detect_noise_threshold_otsu(imp, channel_index, weighted=True, valley_emphasis=False, apply_constraints=True)
        log(u"  Calculated Weighted Otsu threshold: {:.2f}".format(threshold))
    elif threshold_method == "otsu":
        threshold = detect_noise_threshold_otsu(imp, channel_index, weighted=False, valley_emphasis=False, apply_constraints=True)
        log(u"  Calculated Otsu threshold: {:.2f}".format(threshold))
    elif threshold_method == "triangle":
        threshold = detect_noise_threshold_triangle(imp, channel_index)
        log(u"  Calculated Triangle threshold: {:.2f}".format(threshold))
    elif threshold_method == "cv":
        threshold = detect_noise_threshold_cv(imp, channel_index)
        log(u"  Calculated CV threshold: {:.2f}".format(threshold))
    elif threshold_method == "mean":
        threshold = detect_noise_threshold_mean(imp, channel_index, sigma)
        log(u"  Calculated mean+{}*sigma threshold: {:.2f} [DEPRECATED]".format(sigma, threshold))
    elif threshold_method == "sample":
        threshold = detect_noise_threshold_sample(imp, channel_index, 0.1)
        log(u"  Calculated sample threshold: {:.2f}".format(threshold))
    else:  # "fast" is default
        threshold = detect_noise_threshold_fast(imp, channel_index)
        log(u"  Calculated fast threshold: {:.2f}".format(threshold))
    
    # Set to correct channel
    if imp.getNChannels() > 1:
        imp.setC(channel_index)
    
    # Scan all slices and find those above threshold
    # IMPORTANT: Reject slices with mean=0 (fusion artifacts)
    valid_slices = []
    
    for z in range(1, total_slices + 1):
        imp.setZ(z)
        stats = imp.getStatistics(ImageStatistics.MEAN)
        
        # First check: reject mean=0 (fusion artifacts)
        if stats.mean <= 0.0:
            if DEBUG:
                logd(u"    Slice {}: mean={:.2f} [FUSION ARTIFACT - REJECTED]".format(z, stats.mean))
            continue
        
        # Second check: compare to threshold
        if stats.mean > threshold:
            valid_slices.append(z)
            if DEBUG:
                logd(u"    Slice {}: mean={:.2f} > threshold={:.2f} [KEEP]".format(
                    z, stats.mean, threshold))
        else:
            if DEBUG:
                logd(u"    Slice {}: mean={:.2f} <= threshold={:.2f} [DISCARD]".format(
                    z, stats.mean, threshold))
    
    if not valid_slices:
        log(u"!!! ERROR: No slices meet threshold criteria")
        return None
    
    # Find contiguous range (assume slices are sequential)
    start = min(valid_slices)
    stop = max(valid_slices)
    
    log(u"")
    log(u"  Selected slices: {} to {} (total: {})".format(start, stop, stop - start + 1))
    log(u"  Discarded: {} top, {} bottom".format(start - 1, total_slices - stop))
    log(u"")
    
    return (start, stop)

# ==============================================================================
# PART 3: PROJECTION FUNCTIONS (from main.jy - proven patterns)
# ==============================================================================

def create_robust_projection(imp, projection_method, start_slice, stop_slice):
    """
    Create z-projection using proven channel-splitting method.
    Based on working pipeline from main.jy v37.5
    
    Args:
        imp: Source ImagePlus (must be multi-slice stack)
        projection_method: String method name
        start_slice: First slice to include (1-based)
        stop_slice: Last slice to include (1-based)
    
    Returns:
        ImagePlus with projection, or None if failed
    """
    try:
        logd(u"  Creating robust projection using channel-splitting method...")
        logd(u"  Slice range: {} to {}".format(start_slice, stop_slice))
        
        # Store original LUTs for color transfer
        source_luts = None
        if imp.isComposite():
            source_luts = imp.getLuts()
            logd(u"  Retrieved {} LUTs from source".format(len(source_luts) if source_luts else 0))
        
        # Create safe duplicate to work on
        dup = Duplicator().run(imp)
        
        # SPLIT CHANNELS (CRITICAL STABILITY STEP)
        # Processing single channels prevents composite-mode crashes
        channels = ChannelSplitter.split(dup)
        dup.close()  # Free memory
        
        logd(u"  Split into {} channels".format(len(channels)))
        
        # Map method name to ZProjector constant
        method_map = {
            "Max Intensity": ZProjector.MAX_METHOD,
            "Average Intensity": ZProjector.AVG_METHOD,
            "Sum Slices": ZProjector.SUM_METHOD,
            "Standard Deviation": ZProjector.SD_METHOD,
            "Median": ZProjector.MEDIAN_METHOD,
            "Min Intensity": ZProjector.MIN_METHOD
        }
        method_id = method_map.get(projection_method, ZProjector.MAX_METHOD)
        
        # Project each channel individually
        projected_channels = []
        for i, c_imp in enumerate(channels):
            zp = ZProjector(c_imp)
            zp.setMethod(method_id)
            zp.setStartSlice(start_slice)
            zp.setStopSlice(stop_slice)
            zp.doProjection()
            projected_channels.append(zp.getProjection())
            logd(u"    Channel {} projected".format(i + 1))
        
        # MERGE CHANNELS back to Composite
        merged_proj = RGBStackMerge.mergeChannels(projected_channels, False)
        
        # Cleanup split channels to free RAM
        for c_imp in channels:
            c_imp.close()
        System.gc()
        
        logd(u"  Channels merged, {} channels in result".format(merged_proj.getNChannels()))
        
        # Apply original LUTs if available
        if source_luts and merged_proj.getNChannels() > 1:
            # Convert to CompositeImage to apply LUTs
            proj_comp = CompositeImage(merged_proj, CompositeImage.COMPOSITE)
            
            # Apply each LUT
            for i, lut in enumerate(source_luts):
                if i < proj_comp.getNChannels():
                    proj_comp.setChannelLut(lut, i + 1)
            
            # Set COMPOSITE mode
            proj_comp.setMode(CompositeImage.COMPOSITE)
            proj_comp.updateAllChannelsAndDraw()
            
            logd(u"  >>> LUTs applied successfully")
            return proj_comp
        else:
            logd(u"  Returning merged projection without LUT transfer")
            return merged_proj
            
    except Exception as e:
        log(u"!!! Robust projection failed: {}".format(e))
        import traceback
        for line in traceback.format_exc().split('\n'):
            logd(u"  {}".format(line))
        return None

# ==============================================================================
# PART 4: BATCH PROCESSING
# ==============================================================================

def is_already_projected(filename, current_method, current_layer_mode, current_threshold_method=None):
    """
    Check if filename appears to be already-projected with SAME method AND layer selection
    
    ONLY excludes if BOTH the projection method AND layer selection mode match.
    For threshold mode, also checks detection method acronym (VEO, TT, CV, etc.)
    
    This allows:
    - Different methods: sample_max_all_32.tif can be re-projected as avg
    - Different layer selection: sample_max_all_32.tif can be re-projected with z6to22
    - Different detection: sample_max_z6to22_VEO_17.tif can be re-projected with TT
    
    Layer selection indicators:
    - all : Use all layers (e.g., max_all_32)
    - discard : Discard top/bottom (e.g., z1to28_discard2-2)
    - z with acronym : Threshold-based (e.g., z6to22_VEO, z1to28_TT)
    
    Detection method acronyms (threshold mode):
    - VEO : Valley-Emphasis Otsu
    - WO : Weighted Otsu
    - O : Standard Otsu
    - TT : Triangle Thresholding
    - CV : Coefficient of Variation
    - F : Fast (histogram min)
    - M : Mean+sigma
    - S : Sample center
    - U : User-defined
    
    Examples:
    - sample_max_all_32.tif + (Max, all) -> EXCLUDE (same method+mode)
    - sample_max_all_32.tif + (Avg, all) -> ALLOW (different method)
    - sample_max_all_32.tif + (Max, discard) -> ALLOW (different layer mode)
    - sample_max_z6to22_VEO_17.tif + (Max, threshold, VEO) -> EXCLUDE (same all)
    - sample_max_z6to22_VEO_17.tif + (Max, threshold, TT) -> ALLOW (different detection)
    
    Args:
        filename: Filename to check (just the name, not full path)
        current_method: Current projection method (e.g., "Max Intensity")
        current_layer_mode: Current layer mode ("all", "discard", "threshold")
        current_threshold_method: Current detection method (e.g., "valley_otsu", "triangle")
    
    Returns: True if file appears to be already projected with SAME method+mode+detection
    """
    # Map current method to abbreviation
    method_map = {
        "Max Intensity": "_max_",
        "Average Intensity": "_avg_",
        "Sum Slices": "_sum_",
        "Standard Deviation": "_sd_",
        "Median": "_med_",
        "Min Intensity": "_min_"
    }
    
    current_abbrev = method_map.get(current_method, "").lower()
    if not current_abbrev:
        return False  # Unknown method, don't exclude
    
    # Remove extension to get base name
    fname_lower = filename.lower()
    if fname_lower.endswith('.tif'):
        base = fname_lower[:-4]
    elif fname_lower.endswith('.tiff'):
        base = fname_lower[:-5]
    else:
        base = fname_lower
    
    # Check if the CURRENT method abbreviation is in the LAST portion of filename
    # We look at the last 50 characters to focus on suffix
    suffix_check = base[-50:] if len(base) > 50 else base
    
    if current_abbrev in suffix_check:
        # Find position of method in suffix
        method_pos = suffix_check.rfind(current_abbrev)
        
        # Get everything after the method
        after_method = suffix_check[method_pos + len(current_abbrev):]
        
        # Check for operation indicators matching current layer mode
        mode_match = False
        
        if current_layer_mode == "all":
            # Looking for _all_ pattern (now just "all" without trailing underscore)
            if 'all' in after_method and any(c.isdigit() for c in after_method):
                # Make sure it's not part of "discard_all" or similar
                if 'discard' not in after_method:
                    mode_match = True
        elif current_layer_mode == "discard":
            # Looking for _discard pattern
            if 'discard' in after_method and any(c.isdigit() for c in after_method):
                mode_match = True
        elif current_layer_mode == "threshold":
            # Looking for z pattern with detection method acronym
            if 'z' in after_method and any(c.isdigit() for c in after_method):
                # Make sure it's not _all_ (which also has digits)
                if 'all' not in after_method and 'discard' not in after_method:
                    # Check detection method acronym if provided
                    if current_threshold_method:
                        method_acronym_map = {
                            "valley_otsu": "veo",
                            "weighted_otsu": "wo",
                            "otsu": "_o_",  # Use _o_ to avoid matching "to" in z6to22
                            "triangle": "tt",
                            "cv": "cv",
                            "fast": "_f_",
                            "mean": "_m_",
                            "sample": "_s_",
                            "user": "_u_"
                        }
                        current_acronym = method_acronym_map.get(current_threshold_method, "").lower()
                        if current_acronym:
                            # Check if the specific detection method acronym is present
                            if current_acronym in after_method:
                                mode_match = True
                        else:
                            # Unknown detection method, match any threshold pattern
                            mode_match = True
                    else:
                        # No specific detection method provided, match any threshold pattern
                        mode_match = True
        
        if mode_match:
            return True
    
    return False

def process_batch(input_dir, output_dir, projection_method, layer_mode, 
                  discard_top, discard_bottom, threshold_method, user_threshold,
                  sigma, channel_index, do_show, do_save, file_filter):
    """
    Process all TIFF stacks in input directory using phased approach
    
    PHASE 1: Discovery - Parallel Z-profile calculation (threaded based on available RAM)
    PHASE 2: Projection - Create projections from discovered slice ranges
    PHASE 3: Display - Show images if requested (after all projections complete)
    
    Args:
        input_dir: Directory containing TIFF stacks
        output_dir: Where to save projections
        projection_method: Projection method name
        layer_mode: "all", "discard", or "threshold"
        discard_top: Number of top slices to discard (for discard mode)
        discard_bottom: Number of bottom slices to discard (for discard mode)
        threshold_method: Threshold detection method
        user_threshold: User-provided threshold value
        sigma: Sigma multiplier for mean method
        channel_index: Which channel to analyze for threshold (1-based)
        do_show: Whether to display projections
        do_save: Whether to save projections
        file_filter: Filter string for filenames (e.g., "*stitched" or "*projection")
    """
    log(u"")
    log(u"=" * 70)
    log(u"=== STARTING BATCH Z-PROJECTION (PHASED) ===")
    log(u"=" * 70)
    log(u"Input: {}".format(input_dir))
    log(u"Output: {}".format(output_dir))
    log(u"Method: {}".format(projection_method))
    log(u"Layer Mode: {}".format(layer_mode))
    log(u"File Filter: {}".format(file_filter if file_filter else "*.tif (all)"))
    log(u"")
    
    # Start timing
    batch_start_time = time.time()
    
    # Find all TIFF files matching the filter
    tif_files = []
    excluded_count = 0
    
    for f in os.listdir(input_dir):
        if not (f.lower().endswith(".tif") or f.lower().endswith(".tiff")):
            continue
        
        # EXCLUDE already-projected files with SAME method AND layer selection
        if is_already_projected(f, projection_method, layer_mode, threshold_method):
            log(u"  EXCLUDED (already projected with same method+mode): {}".format(safe_unicode(f)))
            excluded_count += 1
            continue
        
        # Apply filter if specified
        if file_filter:
            filter_pattern = file_filter.strip().lstrip('*').lower()
            f_lower = f.lower()
            f_base = f_lower.replace('.tif', '').replace('.tiff', '')
            if filter_pattern not in f_base:
                continue
        
        tif_files.append(os.path.join(input_dir, f))
    
    if excluded_count > 0:
        log(u"")
        log(u">>> Excluded {} already-projected file(s) (suffix pattern matched)".format(excluded_count))
        log(u"")
    
    if not tif_files:
        if file_filter:
            log(u"!!! No TIFF files found matching filter: {}".format(file_filter))
        else:
            log(u"!!! No TIFF files found in input directory")
        return
    
    log(u"Found {} TIFF file(s) to process".format(len(tif_files)))
    log_memory()
    
    # Estimate file size for thread calculation (use first file as reference)
    try:
        first_file_size_mb = os.path.getsize(tif_files[0]) / (1024.0 * 1024.0)
        log(u"Estimated file size: {:.1f}MB".format(first_file_size_mb))
    except:
        first_file_size_mb = 1000.0  # Default 1GB estimate
    
    # Calculate optimal threads
    num_threads = calculate_optimal_threads(first_file_size_mb, target_ram_usage_percent=0.8)
    log(u"Using {} thread(s) for discovery phase".format(num_threads))
    log(u"")
    
    # PHASE 1: DISCOVERY (Parallel Z-profile calculation for threshold methods)
    discovery_results = None
    temp_dir = None
    discovery_time = 0.0
    
    if layer_mode == "threshold" and num_threads > 1:
        discovery_start = time.time()
        discovery_results, temp_dir = run_discovery_phase(
            tif_files, layer_mode, discard_top, discard_bottom,
            threshold_method, user_threshold, sigma, channel_index,
            num_threads)
        discovery_time = time.time() - discovery_start
        log(u"Discovery phase completed in: {}".format(format_elapsed_time(discovery_time)))
    
    # PHASE 2: PROJECTION (Create projections)
    projection_start = time.time()
    log(u"")
    log(u"=" * 70)
    log(u"=== PROJECTION PHASE: Creating Z-Projections ===")
    log(u"=" * 70)
    log(u"")
    
    proj_count = 0
    skip_count = 0
    error_count = 0
    saved_files = []  # Track saved files for display phase
    
    for idx, tif_path in enumerate(tif_files):
        try:
            fname = safe_unicode(os.path.basename(tif_path))
            base_name = fname.replace(u".tif", u"").replace(u".tiff", u"")
            
            log(u"")
            log(u"[{}/{}] Projecting: {}".format(idx + 1, len(tif_files), fname))
            
            # Check if discovery was done for this file
            if discovery_results:
                result = next((r for r in discovery_results if r['file'] == tif_path), None)
                if result:
                    if result.get('skip'):
                        log(u"  SKIP - {}".format(safe_unicode(result.get('skip_reason'))))
                        skip_count += 1
                        continue
                    if result.get('error'):
                        log(u"  !!! ERROR - {}".format(safe_unicode(result.get('error'))))
                        error_count += 1
                        continue
                    if not result.get('success'):
                        log(u"  !!! No valid discovery result, skipping")
                        error_count += 1
                        continue
            
            # Load image
            imp = IJ.openImage(tif_path)
            if imp is None:
                log(u"  !!! Failed to load image, skipping")
                error_count += 1
                continue
            
            num_slices = imp.getNSlices()
            num_channels = imp.getNChannels()
            
            log(u"  Loaded: {} slices, {} channels".format(num_slices, num_channels))
            
            if num_slices <= 1:
                log(u"  Only {} slice(s), skipping projection".format(num_slices))
                imp.close()
                skip_count += 1
                continue
            
            # Determine slice range
            slice_range = None
            
            if discovery_results and layer_mode == "threshold":
                # Use discovered range
                result = next((r for r in discovery_results if r['file'] == tif_path), None)
                if result and result.get('slice_range'):
                    slice_range = tuple(result['slice_range'])
                    log(u"  Using discovered range: slices {} to {}".format(slice_range[0], slice_range[1]))
            else:
                # Calculate range now (for "all" or "discard" modes, or if discovery failed)
                if layer_mode == "all":
                    slice_range = select_all_layers(imp)
                    log(u"  Mode: Using all {} slices".format(num_slices))
                elif layer_mode == "discard":
                    slice_range = select_discard_layers(imp, discard_top, discard_bottom)
                    if slice_range is None:
                        log(u"  !!! Invalid discard parameters, skipping")
                        imp.close()
                        error_count += 1
                        continue
                elif layer_mode == "threshold":
                    slice_range = select_layers_by_threshold(
                        imp, threshold_method, user_threshold, sigma, channel_index)
                    if slice_range is None:
                        log(u"  !!! No slices meet threshold, skipping")
                        imp.close()
                        skip_count += 1
                        continue
            
            if not slice_range:
                log(u"  !!! Could not determine slice range, skipping")
                imp.close()
                error_count += 1
                continue
            
            start_slice, stop_slice = slice_range
            num_used_slices = stop_slice - start_slice + 1
            
            # Create projection
            proj_imp = create_robust_projection(imp, projection_method, start_slice, stop_slice)
            
            if proj_imp is None:
                log(u"  !!! Projection creation failed, skipping")
                imp.close()
                error_count += 1
                continue
            
            # Create filename with detailed operation modifier
            method_abbrev = {
                "Max Intensity": "max",
                "Average Intensity": "avg",
                "Sum Slices": "sum",
                "Standard Deviation": "sd",
                "Median": "med",
                "Min Intensity": "min"
            }.get(projection_method, "max")
            
            # Operation descriptor with detection method signage
            if num_used_slices == num_slices:
                operation = u"all"
            elif layer_mode == "discard":
                operation = u"z{}to{}_discard{}-{}".format(
                    start_slice, stop_slice, discard_top, discard_bottom)
            elif layer_mode == "threshold":
                # Add detection method acronym to filename
                method_acronym = {
                    "valley_otsu": "VEO",      # Valley-Emphasis Otsu
                    "weighted_otsu": "WO",     # Weighted Otsu
                    "otsu": "O",               # Standard Otsu
                    "triangle": "TT",          # Triangle Thresholding
                    "cv": "CV",                # Coefficient of Variation
                    "fast": "F",               # Fast (histogram min)
                    "mean": "M",               # Mean+sigma (deprecated)
                    "sample": "S",             # Sample center
                    "user": "U"                # User-defined
                }.get(threshold_method, "THR")
                operation = u"z{}to{}_{}".format(start_slice, stop_slice, method_acronym)
            else:
                operation = u"z{}to{}".format(start_slice, stop_slice)
            
            proj_filename = u"{}_{}_{}_{}.tif".format(base_name, method_abbrev, operation, num_used_slices)
            proj_imp.setTitle(proj_filename.replace(".tif", ""))
            
            # Auto brightness/contrast adjustment (IMPROVED FOR CHANNEL 1 AND LARGE FILES)
            try:
                if proj_imp.isComposite():
                    log(u"  Applying auto brightness/contrast per channel...")
                    comp_imp = proj_imp
                    
                    # Process each channel individually with proper timing
                    for c in range(1, comp_imp.getNChannels() + 1):
                        comp_imp.setC(c)
                        
                        # Give ImageJ time to update, especially important for channel 1 and large files
                        Thread.sleep(100)  # 100ms delay for ImageJ to catch up
                        
                        # Use more conservative saturation for less bright output (0.10 instead of 0.35)
                        IJ.run(comp_imp, "Enhance Contrast", "saturated=0.10")
                        
                        logd(u"    Channel {}: B&C applied (saturated=0.10)".format(c))
                    
                    # Reset to first channel
                    comp_imp.setC(1)
                    Thread.sleep(50)
                    
                    log(u"  >>> Auto B&C applied to all {} channels (saturated=0.10)".format(comp_imp.getNChannels()))
                else:
                    # Single channel - also use conservative saturation
                    IJ.run(proj_imp, "Enhance Contrast", "saturated=0.10")
                    log(u"  >>> Auto B&C applied (saturated=0.10)")
            except Exception as e:
                logd(u"  Auto B&C failed: {}".format(e))
            
            # Save if requested
            if do_save:
                proj_out = os.path.join(output_dir, proj_filename)
                try:
                    IJ.saveAs(proj_imp, "Tiff", proj_out)
                    log(u"  >>> Saved: {}".format(safe_unicode(proj_filename)))
                    proj_count += 1
                    saved_files.append(proj_out)
                except Exception as e:
                    log(u"  !!! Save failed: {}".format(safe_unicode(e)))
                    error_count += 1
            
            # Don't show yet - save for phase 3
            if not do_show:
                proj_imp.close()
            else:
                saved_files.append((proj_imp, proj_filename))
            
            # Close source image
            imp.close()
            
            # Garbage collection after each file
            System.gc()
            
        except Exception as e:
            log(u"  !!! Processing failed: {}".format(safe_unicode(e)))
            import traceback
            traceback.print_exc()
            error_count += 1
    
    log(u"")
    log(u"=" * 70)
    log(u"=== PROJECTION PHASE COMPLETE ===")
    
    projection_time = time.time() - projection_start
    
    log(u"  Processed: {}".format(proj_count))
    log(u"  Skipped: {}".format(skip_count))
    log(u"  Errors: {}".format(error_count))
    log(u"  Projection Time: {}".format(format_elapsed_time(projection_time)))
    log(u"=" * 70)
    log(u"")
    
    # Clean memory after projection phase
    System.gc()
    log_memory()
    
    # PHASE 3: DISPLAY (Open files only if requested)
    display_time = 0.0
    
    if do_show and saved_files:
        display_start = time.time()
        
        log(u"")
        log(u"=" * 70)
        log(u"=== DISPLAY PHASE: Opening Projections ===")
        log(u"=" * 70)
        log(u"")
        
        for item in saved_files:
            try:
                if isinstance(item, tuple):
                    # Already have ImagePlus object
                    proj_imp, proj_filename = item
                    proj_imp.show()
                    log(u"  >>> Displayed: {}".format(safe_unicode(proj_filename)))
                else:
                    # Need to open file
                    proj_path = item
                    proj_filename = safe_unicode(os.path.basename(proj_path))
                    proj_imp = IJ.openImage(proj_path)
                    if proj_imp:
                        proj_imp.show()
                        log(u"  >>> Opened: {}".format(proj_filename))
                    else:
                        log(u"  !!! Failed to open: {}".format(proj_filename))
            except Exception as e:
                log(u"  !!! Display failed: {}".format(safe_unicode(e)))
        
        display_time = time.time() - display_start
        
        log(u"")
        log(u"=== DISPLAY COMPLETE ===")
        log(u"  Display Time: {}".format(format_elapsed_time(display_time)))
        log(u"")
    
    # Cleanup temp directory if discovery was used
    if temp_dir and os.path.exists(temp_dir):
        try:
            import shutil
            shutil.rmtree(temp_dir)
            logd(u"Cleaned up temp directory: {}".format(temp_dir))
        except Exception as e:
            logd(u"Failed to cleanup temp directory: {}".format(e))
    
    log(u"")
    log(u"=" * 70)
    log(u"=== BATCH COMPLETE ===")
    
    # Calculate elapsed time
    batch_end_time = time.time()
    batch_elapsed = batch_end_time - batch_start_time
    
    log(u"  Files Found: {}".format(len(tif_files) + excluded_count))
    log(u"  Already-Projected (Excluded): {}".format(excluded_count))
    log(u"  Processed: {}".format(proj_count))
    log(u"  Skipped: {}".format(skip_count))
    log(u"  Errors: {}".format(error_count))
    log(u"")
    log(u"  --- Timing ---")
    if discovery_time > 0:
        log(u"  Discovery Phase: {}".format(format_elapsed_time(discovery_time)))
    log(u"  Projection Phase: {}".format(format_elapsed_time(projection_time)))
    if display_time > 0:
        log(u"  Display Phase: {}".format(format_elapsed_time(display_time)))
    log(u"  Total Time: {}".format(format_elapsed_time(batch_elapsed)))
    log(u"=" * 70)
    log(u"")
    log_memory()
# ==============================================================================
# PART 5: MAIN ENTRY POINT
# ==============================================================================

def show_splash():
    """Display ASCII art splash screen"""
    splash = u"""
      +---+---+---+
      |   Z   |   |    BATCH Z-PROJECTION v1.3
      +---+---+---+     ========================
      | P | r | o |    > Standalone Tool
      +---+---+---+     > Threaded Discovery
      | j | e | c |    > Valley-Emphasis Otsu
      +---+---+---+     > Phased Processing

      [Standalone] Independent from main.jy
      [Based on] CZI-Stitcher v37.5 patterns
      [New in v1.3] Threaded discovery + improved UI
      [Status] Initializing...
    """
    log(splash)

def main():
    """Main entry point"""
    IJ.log("\\Clear")
    show_splash()
    
    # Load config
    _config = _load_config()
    
    _home = os.path.expanduser("~")
    _last_in = _config.get("last_input_dir", "") or _home
    _last_out = _config.get("last_output_dir", "") or _home
    
    if not os.path.isdir(_last_in): 
        _last_in = _home
    if not os.path.isdir(_last_out): 
        _last_out = _home
    
    # Parameter dialog
    gd = GenericDialog("Batch Z-Projection - Parameters v1.3")
    
    gd.addMessage("=== Directory Paths ===")
    gd.addStringField("Input Folder (TIFF stacks):", _last_in, 50)
    gd.addStringField("Output Folder (Projections):", _last_out, 50)
    
    gd.addMessage("=== File Filter ===")
    gd.addStringField("Filter files containing (leave empty for all):", "stitched", 30)
    gd.addMessage("  Examples: 'stitched', 'projection', 'sample01'")
    gd.addMessage("  Use '*stitched' or just 'stitched' (both work)")
    gd.addMessage("  Leave empty to process ALL .tif files")
    
    gd.addMessage("=== Projection Method ===")
    gd.addChoice("Method", ["Max Intensity", "Average Intensity", "Sum Slices", 
                            "Standard Deviation", "Median", "Min Intensity"], 
                 "Max Intensity")
    
    gd.addMessage("=== Layer Selection Mode ===")
    gd.addChoice("Mode", [
        "Use all layers",
        "Discard top/bottom",
        "Valley-Emphasis Otsu (BEST for Apotome)", 
        "Weighted Otsu (for rare signal)",
        "Otsu (standard)",
        "Triangle (focus scores)",
        "CV (coefficient of variation)",
        "Fast (histogram min)", 
        "Mean + sigma (DEPRECATED)", 
        "Sample center (fast)",
        "User-defined threshold"
    ], "Use all layers")
    gd.addMessage("  All: Fastest, uses every slice")
    gd.addMessage("  Discard: Manual trimming (remove top/bottom slices)")
    gd.addMessage("  Detection methods: Automatic threshold-based selection")
    gd.addMessage("  Valley-Emphasis: BEST for Apotome with 90% baseline + 10% signal")
    
    gd.addMessage("--- Mode Parameters ---")
    gd.addNumericField("Discard top N slices (discard mode):", 0, 0)
    gd.addNumericField("Discard bottom N slices (discard mode):", 0, 0)
    gd.addNumericField("User threshold (user-defined mode):", 0.0, 2)
    gd.addNumericField("Sigma multiplier (mean+sigma mode):", 3.0, 1)
    gd.addNumericField("Analyze channel (detection modes, 1-based):", 1, 0)
    
    gd.addMessage("=== Output Options ===")
    gd.addChoice("Output", ["Save only", "Save and Show", "Show only (testing)"], "Save only")
    gd.addMessage("  'Save only': Best for batch processing")
    gd.addMessage("  'Save and Show': Opens files after all projections complete")
    gd.addMessage("  'Show only': For testing (projections NOT saved)")
    
    gd.showDialog()
    
    if gd.wasCanceled():
        log("User cancelled. Exiting.")
        return
    
    # Get parameters
    in_path = gd.getNextString().strip()
    out_path = gd.getNextString().strip()
    file_filter = gd.getNextString().strip()
    
    # Validate paths
    if not in_path or not os.path.isdir(in_path):
        log(u"!!! Error: Input folder '{}' does not exist or is invalid.".format(in_path))
        return
    if not out_path or not os.path.isdir(out_path):
        log(u"!!! Error: Output folder '{}' does not exist or is invalid.".format(out_path))
        return
    
    # Save config
    _config["last_input_dir"] = in_path
    _config["last_output_dir"] = out_path
    _save_config(_config)
    
    projection_method = gd.getNextChoice()
    mode_choice = gd.getNextChoice()
    
    # Map choice to internal mode name and threshold method
    if mode_choice == "Use all layers":
        layer_mode = "all"
        threshold_method = "valley_otsu"  # Default, won't be used
    elif mode_choice == "Discard top/bottom":
        layer_mode = "discard"
        threshold_method = "valley_otsu"  # Default, won't be used
    else:
        # It's a threshold method
        layer_mode = "threshold"
        
        # Map choice to internal threshold method name
        if "Valley-Emphasis" in mode_choice:
            threshold_method = "valley_otsu"
        elif "Weighted Otsu" in mode_choice:
            threshold_method = "weighted_otsu"
        elif "Otsu" in mode_choice:
            threshold_method = "otsu"
        elif "Triangle" in mode_choice:
            threshold_method = "triangle"
        elif "CV" in mode_choice or "coefficient" in mode_choice:
            threshold_method = "cv"
        elif "Fast" in mode_choice:
            threshold_method = "fast"
        elif "Mean" in mode_choice:
            threshold_method = "mean"
        elif "Sample" in mode_choice:
            threshold_method = "sample"
        else:  # User-defined
            threshold_method = "user"
    
    discard_top = int(gd.getNextNumber())
    discard_bottom = int(gd.getNextNumber())
    user_threshold = float(gd.getNextNumber())
    sigma = float(gd.getNextNumber())
    channel_index = int(gd.getNextNumber())
    
    # Get output options from dropdown
    output_choice = gd.getNextChoice()
    if "Save only" in output_choice:
        do_save = True
        do_show = False
    elif "Save and Show" in output_choice:
        do_save = True
        do_show = True
    else:  # Show only
        do_save = False
        do_show = True
    
    # Log parameters
    log(u"")
    log(u"Parameters:")
    log(u"  File Filter: {}".format(file_filter if file_filter else "None (all .tif files)"))
    log(u"  Projection Method: {}".format(projection_method))
    log(u"  Layer Mode: {}".format(layer_mode))
    
    if layer_mode == "discard":
        log(u"  Discard: {} top, {} bottom".format(discard_top, discard_bottom))
    elif layer_mode == "threshold":
        log(u"  Threshold Method: {}".format(threshold_method))
        if threshold_method == "user":
            log(u"  User Threshold: {:.2f}".format(user_threshold))
        elif threshold_method == "mean":
            log(u"  Sigma Multiplier: {:.1f}".format(sigma))
        log(u"  Analyze Channel: {}".format(channel_index))
    
    log(u"  Save: {} | Show: {}".format(do_save, do_show))
    log(u"")
    
    # Process batch
    batch_start = time.time()
    
    process_batch(in_path, out_path, projection_method, layer_mode,
                  discard_top, discard_bottom, threshold_method, user_threshold,
                  sigma, channel_index, do_show, do_save, file_filter)
    
    batch_elapsed = time.time() - batch_start
    log(u"")
    log(u"Total processing time: {:.1f} seconds ({:.1f} minutes)".format(
        batch_elapsed, batch_elapsed / 60.0))
    log(u"")
    log(u">>> Batch Z-Projection Complete!")

# Run main
if __name__ in [None, "__main__", "__builtin__"]:
    main()
