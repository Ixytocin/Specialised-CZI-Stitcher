# SPECIALISED CZI STITCHER WITH Z-PROJECTION v33.0
# A specialized batch processing pipeline for Zeiss CZI microscopy files
# - Fixed color interpretation: Zeiss uses RGBA format (not ARGB)
# - Channel colors: Respect metadata by default, optional standard microscopy LUT override
# - Z-stack projection: 6 methods with save/view options
# - Sharp-slice detection: ROI-based or global sharpness analysis for selective z-range fusion
# - Output options: save 3D, z-projection, or both; view projections
# - Automatic BigTIFF handling based on file size
# - Enhanced filenames: include processing parameters in output
# - Performance optimizations: StringBuilder for logging, optimized metadata
# - Fail-fast: Process largest file first for early error detection

import os, time, shutil, math, re, sys, json, codecs
from java.lang import Runtime, Thread, System, StringBuilder
from java.awt import Color
from java.util.concurrent import Executors, Callable
from ij import IJ, ImagePlus, WindowManager, CompositeImage
from ij.plugin import ZProjector, HyperStackConverter
from ij.process import LUT
from loci.plugins import BF
from loci.plugins.in import ImporterOptions, ImportProcess
from java.io import File, BufferedOutputStream, FileOutputStream
from ij.gui import GenericDialog
from ij.io import TiffEncoder
import jarray

VERBOSE = False
LOG_TILE_POS = False
DUMP_DEBUG = False
LUT_DEBUG = True
PLAY_JINGLE_ON_DONE = True
DEBUG_MODE = False  # Set via dialog checkbox

# Z-projection options
ZPROJ_METHODS = {
    "Average Intensity": ZProjector.AVG_METHOD,
    "Max Intensity": ZProjector.MAX_METHOD,
    "Min Intensity": ZProjector.MIN_METHOD,
    "Sum Slices": ZProjector.SUM_METHOD,
    "Standard Deviation": ZProjector.SD_METHOD,
    "Median": ZProjector.MEDIAN_METHOD
}

# Sharp-slice detection methods
SHARPNESS_METHODS = {
    "Laplacian Variance": "laplacian",
    "Tenengrad Gradient": "tenengrad",
    "Normalized Variance": "variance"
}

# Buffer size for file I/O (64KB for optimal performance)
# Note: IJ.saveAs() and Bio-Formats use their own internal buffering
# This constant is available for future custom file I/O operations
FILE_BUFFER_SIZE = 65536

# Threshold for automatic BigTIFF (2GB - 100MB margin)
BIGTIFF_THRESHOLD = 2147483648 - 104857600

# Log buffer for performance
_log_buffer = StringBuilder()
_log_last_flush = time.time()

MICRO = u"\u00b5"
FLOAT_RE = re.compile(r"([-+]?\d*\.\d+|[-+]?\d+)(?:[eE][-+]?\d+)?")
ATTR_RE = re.compile(r'([A-Za-z_:][-A-Za-z0-9_:.]*)="([^"]*)"')
STAGELABEL_RE = re.compile(r'<(?:[A-Za-z0-9_]+:)?StageLabel\b([^>]*)/?>', re.IGNORECASE)
_PIXELS_TAG_RE = re.compile(r'<Pixels\b([^>]*)>', re.IGNORECASE)
_PHYSICAL_X_RE = re.compile(r'PhysicalSizeX\s*=\s*"([^"]+)"', re.IGNORECASE)
_PHYSICAL_XUNIT_RE = re.compile(r'PhysicalSizeXUnit\s*=\s*"([^"]+)"', re.IGNORECASE)
_CHANNEL_COLOR_RE = re.compile(r'<(?:[A-Za-z0-9_]+:)?Channel\b([^>]*)>', re.IGNORECASE)

_CONFIG_PATH = os.path.join(os.path.expanduser("~"), ".ixytocin_stitcher.json")

def _load_config():
    try:
        if os.path.exists(_CONFIG_PATH):
            with open(_CONFIG_PATH, 'r') as f:
                return json.load(f)
    except:
        pass
    return {}

def _save_config(cfg):
    try:
        with open(_CONFIG_PATH, 'w') as f:
            json.dump(cfg, f)
    except:
        pass

def ensure_unicode(o):
    if o is None:
        return None
    if isinstance(o, unicode):
        return o
    try:
        return unicode(bytearray(o.getBytes("UTF-8")), 'utf-8', 'replace')
    except:
        pass
    try:
        return unicode(o, 'utf-8', 'replace')
    except:
        pass
    try:
        return unicode(str(o), 'utf-8', 'replace')
    except:
        pass
    try:
        return u"%s" % o
    except:
        return u""

def safe_unicode(o):
    try:
        return ensure_unicode(o)
    except:
        try:
            return unicode(o)
        except:
            try:
                return u"%s" % o
            except:
                return u"<unrepresentable>"

def log(msg):
    global _log_buffer, _log_last_flush
    try:
        msg_str = u"[Specialised CZI Stitcher] " + safe_unicode(msg) + u"\n"
        _log_buffer.append(msg_str)
        
        # Flush buffer every 1 second or when it exceeds 8KB
        current_time = time.time()
        if (current_time - _log_last_flush) >= 1.0 or _log_buffer.length() > 8192:
            IJ.log(_log_buffer.toString())
            _log_buffer = StringBuilder()
            _log_last_flush = current_time
    except:
        try:
            IJ.log(str(msg))
        except:
            pass

def flush_log():
    """Flush remaining log messages."""
    global _log_buffer, _log_last_flush
    try:
        if _log_buffer.length() > 0:
            IJ.log(_log_buffer.toString())
            _log_buffer = StringBuilder()
            _log_last_flush = time.time()
    except:
        pass

def logv(msg):
    if VERBOSE:
        log(msg)

def compute_sharpness_laplacian(imp_slice):
    """Compute sharpness using Laplacian variance method."""
    from ij.plugin.filter import Convolver
    from ij.process import FloatProcessor
    ip = imp_slice.getProcessor().convertToFloat()
    kernel = [-1, -1, -1, -1, 8, -1, -1, -1, -1]
    convolver = Convolver()
    convolver.convolve(ip, kernel, 3, 3)
    pixels = ip.getPixels()
    mean_val = sum(pixels) / len(pixels)
    variance = sum([(p - mean_val) ** 2 for p in pixels]) / len(pixels)
    return variance

def compute_sharpness_tenengrad(imp_slice):
    """Compute sharpness using Tenengrad gradient method."""
    from ij.plugin.filter import Convolver
    ip = imp_slice.getProcessor().convertToFloat()
    # Sobel X kernel
    kernelX = [-1, 0, 1, -2, 0, 2, -1, 0, 1]
    # Sobel Y kernel
    kernelY = [-1, -2, -1, 0, 0, 0, 1, 2, 1]
    convolver = Convolver()
    ipX = ip.duplicate()
    ipY = ip.duplicate()
    convolver.convolve(ipX, kernelX, 3, 3)
    convolver.convolve(ipY, kernelY, 3, 3)
    pixelsX = ipX.getPixels()
    pixelsY = ipY.getPixels()
    # Use generator to avoid intermediate list
    gradient_sum = sum(math.sqrt(px**2 + py**2) for px, py in zip(pixelsX, pixelsY))
    return gradient_sum / len(pixelsX)

def compute_sharpness_variance(imp_slice):
    """Compute sharpness using normalized variance method."""
    ip = imp_slice.getProcessor()
    pixels = ip.getPixels()
    mean_val = sum(pixels) / float(len(pixels))
    if mean_val == 0:
        return 0
    variance = sum([(p - mean_val) ** 2 for p in pixels]) / float(len(pixels))
    return variance / mean_val

def compute_sharpness(imp_slice, method="laplacian"):
    """Compute sharpness of a single slice using specified method."""
    if method == "laplacian":
        return compute_sharpness_laplacian(imp_slice)
    elif method == "tenengrad":
        return compute_sharpness_tenengrad(imp_slice)
    elif method == "variance":
        return compute_sharpness_variance(imp_slice)
    else:
        return compute_sharpness_laplacian(imp_slice)

def detect_sharp_slices_global(imp, threshold, method="laplacian"):
    """Detect sharp slices using global sharpness analysis.
    
    Args:
        imp: ImagePlus with z-stack
        threshold: Sharpness threshold (0.0-1.0)
        method: Sharpness detection method
    
    Returns:
        (start_slice, end_slice) tuple (1-indexed)
    """
    nSlices = imp.getNSlices()
    if nSlices <= 1:
        return (1, 1)
    
    log("Computing global sharpness for %d slices (method: %s)..." % (nSlices, method))
    sharpness_scores = []
    
    # Compute sharpness for each slice
    for z in range(1, nSlices + 1):
        imp.setSlice(z)
        score = compute_sharpness(imp, method)
        sharpness_scores.append(score)
    
    # Find threshold value
    max_score = max(sharpness_scores)
    min_score = min(sharpness_scores)
    threshold_value = min_score + (max_score - min_score) * threshold
    
    # Find continuous range of sharp slices (use largest continuous block)
    sharp_indices = [i for i, score in enumerate(sharpness_scores) if score >= threshold_value]
    
    if not sharp_indices:
        log("Warning: No slices met sharpness threshold, using all slices")
        return (1, nSlices)
    
    # Find largest continuous range with hole-filling
    # Hole-filling: Allow small gaps (1-2 slices) to be included in continuous ranges
    # This handles noise or temporary focus issues within otherwise sharp regions
    ranges = []
    start = sharp_indices[0]
    end = sharp_indices[0]
    
    for i in range(1, len(sharp_indices)):
        gap = sharp_indices[i] - sharp_indices[i-1]
        if gap <= 3:  # Allow gaps of 1-2 slices to be filled (gap=3 means 2 missing slices)
            end = sharp_indices[i]
        else:
            # Gap too large, finalize current range
            ranges.append((start, end))
            start = sharp_indices[i]
            end = sharp_indices[i]
    
    # Add final range
    ranges.append((start, end))
    
    # Use the longest range
    longest_range = max(ranges, key=lambda r: r[1] - r[0])
    start_slice = longest_range[0] + 1  # Convert to 1-indexed
    end_slice = longest_range[1] + 1
    
    log("Sharp slice range (global): Z %d to %d" % (start_slice, end_slice))
    return (start_slice, end_slice)

def detect_sharp_slices_roi(imp, threshold, method="laplacian", roi_grid_size=3):
    """Detect sharp slices using ROI-based local sharpness analysis.
    
    Args:
        imp: ImagePlus with z-stack
        threshold: Sharpness threshold (0.0-1.0)
        method: Sharpness detection method
        roi_grid_size: Grid size for ROI analysis (n x n grid)
    
    Returns:
        (start_slice, end_slice) tuple (1-indexed)
    """
    from ij.gui import Roi
    nSlices = imp.getNSlices()
    if nSlices <= 1:
        return (1, 1)
    
    width = imp.getWidth()
    height = imp.getHeight()
    roi_width = int(width // roi_grid_size)
    roi_height = int(height // roi_grid_size)
    
    log("Computing ROI-based sharpness for %d slices (%dx%d grid, method: %s)..." % 
        (nSlices, roi_grid_size, roi_grid_size, method))
    
    all_sharp_ranges = []
    
    # Process each ROI
    for row in range(roi_grid_size):
        for col in range(roi_grid_size):
            x = col * roi_width
            y = row * roi_height
            roi = Roi(int(x), int(y), int(roi_width), int(roi_height))
            imp.setRoi(roi)
            
            sharpness_scores = []
            for z in range(1, nSlices + 1):
                imp.setSlice(z)
                score = compute_sharpness(imp, method)
                sharpness_scores.append(score)
            
            # Find threshold for this ROI
            max_score = max(sharpness_scores)
            min_score = min(sharpness_scores)
            threshold_value = min_score + (max_score - min_score) * threshold
            
            # Find sharp range for this ROI
            sharp_indices = [i for i, score in enumerate(sharpness_scores) if score >= threshold_value]
            
            if sharp_indices:
                # Fill holes: find largest continuous block of sharp slices
                # allowing small gaps (1-2 slices) to be included
                continuous_ranges = []
                current_start = sharp_indices[0]
                current_end = sharp_indices[0]
                
                for i in range(1, len(sharp_indices)):
                    gap = sharp_indices[i] - sharp_indices[i-1]
                    if gap <= 3:  # Allow gaps of 1-2 slices to be filled
                        current_end = sharp_indices[i]
                    else:
                        # Gap too large, start new range
                        continuous_ranges.append((current_start, current_end))
                        current_start = sharp_indices[i]
                        current_end = sharp_indices[i]
                
                # Add final range
                continuous_ranges.append((current_start, current_end))
                
                # Use the largest continuous range for this ROI
                largest_range = max(continuous_ranges, key=lambda r: r[1] - r[0])
                start_z = largest_range[0] + 1  # Convert to 1-indexed
                end_z = largest_range[1] + 1
                all_sharp_ranges.append((start_z, end_z))
    
    imp.killRoi()
    
    # Merge all ROI ranges with hole-filling
    # Note: Currently collecting exceptions but not displaying batch summary
    # TODO: Add batch summary of failed files at end of processing
    if not all_sharp_ranges:
        log("Warning: No sharp regions found in any ROI, using all slices")
        return (1, nSlices)
    
    # Sort ranges by start position
    all_sharp_ranges.sort(key=lambda r: r[0])
    
    # Merge overlapping or close ranges (with hole-filling)
    merged_ranges = []
    current_start = all_sharp_ranges[0][0]
    current_end = all_sharp_ranges[0][1]
    
    for start, end in all_sharp_ranges[1:]:
        # Check if ranges overlap or are close (within 2 slices)
        if start <= current_end + 3:  # Allow gap of up to 2 slices
            # Merge by extending current range
            current_end = max(current_end, end)
        else:
            # No overlap, save current range and start new one
            merged_ranges.append((current_start, current_end))
            current_start = start
            current_end = end
    
    # Add final range
    merged_ranges.append((current_start, current_end))
    
    # Use the largest merged range
    if len(merged_ranges) == 1:
        start_slice = merged_ranges[0][0]
        end_slice = merged_ranges[0][1]
    else:
        # Find largest range
        largest_range = max(merged_ranges, key=lambda r: r[1] - r[0])
        start_slice = largest_range[0]
        end_slice = largest_range[1]
    
    log("Sharp slice range (ROI %dx%d, %d ROIs analyzed, %d ranges merged): Z %d to %d" % 
        (roi_grid_size, roi_grid_size, len(all_sharp_ranges), len(merged_ranges), start_slice, end_slice))
    return (start_slice, end_slice)

def get_safe_path(f):
    if f is None: return u""
    try:
        return u"{}".format(f.getAbsolutePath())
    except:
        return u"{}".format(f)

def find_floats(s):
    if s is None: return []
    return [float(x) for x in FLOAT_RE.findall(u"{}".format(s))]

def _parse_stagelabels_from_xml(xml):
    labels = []
    if not xml:
        return labels
    xml = ensure_unicode(xml)
    for m in STAGELABEL_RE.finditer(xml):
        attr_blob = m.group(1)
        attrs = dict(ATTR_RE.findall(attr_blob))
        name = attrs.get('Name') or attrs.get('name') or ""
        x_str = attrs.get('X') or attrs.get('x')
        y_str = attrs.get('Y') or attrs.get('y')
        z_str = attrs.get('Z') or attrs.get('z')
        xunit = attrs.get('XUnit') or attrs.get('xUnit') or attrs.get('xunit') or attrs.get('Xunit') or ""
        yunit = attrs.get('YUnit') or attrs.get('yUnit') or attrs.get('yunit') or ""
        zunit = attrs.get('ZUnit') or attrs.get('zUnit') or attrs.get('zunit') or ""
        try: x = float(x_str) if x_str is not None else None
        except: x = None
        try: y = float(y_str) if y_str is not None else None
        except: y = None
        try: z = float(z_str) if z_str is not None else None
        except: z = None
        labels.append({'name': name, 'x': x, 'y': y, 'z': z, 'xunit': xunit, 'yunit': yunit, 'zunit': zunit, 'raw_attrs': attrs})
    return labels

def _parse_pixels_physicalsize_from_xml(ome_xml):
    if not ome_xml:
        return None, ""
    ome_xml = ensure_unicode(ome_xml)
    m = _PIXELS_TAG_RE.search(ome_xml)
    if m:
        attrs = m.group(1)
        pat = re.compile(r'PhysicalSizeX\s*=\s*"([^"]+)"', re.IGNORECASE)
        mm = pat.search(attrs)
        px = float(mm.group(1)) if mm else None
        um = re.search(r'PhysicalSizeXUnit\s*=\s*"([^"]+)"', attrs, re.IGNORECASE)
        unit_mm = um.group(1) if um else ""
        return px, unit_mm
    mxx = _PHYSICAL_X_RE.search(ome_xml)
    if mxx:
        val = float(mxx.group(1))
        um = _PHYSICAL_XUNIT_RE.search(ome_xml)
        unit = um.group(1) if um else ""
        return val, unit
    return None, ""

def _unit_to_um(value, unit):
    if value is None:
        return None
    if not unit:
        return float(value)
    u = unit.strip().lower()
    u = u.replace('micro', 'um').replace('µ', 'um').replace('μ', 'um').replace('Âµ','um')
    if u in ('um', 'µm', 'μm', 'Âµm'): return float(value)
    if u == 'm': return float(value) * 1e6
    if u == 'cm': return float(value) * 1e4
    if u == 'mm': return float(value) * 1e3
    if u in ('nm',): return float(value) * 1e-3
    if u in ('pm',): return float(value) * 1e-6
    if 'meter' in u or 'metre' in u:
        if 'micrometer' in u or 'micron' in u: return float(value)
        return float(value) * 1e6
    return float(value)

def _pixel_from_global_metadata(gMeta):
    if not gMeta:
        return None, None
    cams = []
    generic = []
    for k in gMeta.keySet():
        try:
            keystr = safe_unicode(k)
            val = safe_unicode(gMeta.get(k))
        except:
            continue
        lkey = keystr.lower()
        nums = find_floats(val)
        nums = [n for n in nums if n > 0]
        if not nums:
            continue
        if "camerapixeldistance" in lkey or "camerapixeldistances" in lkey:
            cams.extend(nums)
        elif ("pixel" in lkey and "dist" in lkey) or ("pixel" in lkey and "size" in lkey) or ("physicalsizex" in lkey):
            generic.extend(nums)
    def pick_min_med(lst):
        if not lst: return None, None
        lst = [c for c in lst if 0.01 <= c <= 50.0]
        if not lst: return None, None
        lst.sort()
        mid = len(lst)//2
        med = lst[mid] if len(lst)%2==1 else 0.5*(lst[mid-1]+lst[mid])
        return lst[0], med
    cam_min, cam_med = pick_min_med(cams)
    gen_min, gen_med = pick_min_med(generic)
    if cam_med is not None:
        return cam_min, cam_med
    if gen_min is not None:
        return gen_min, gen_med
    return None, None

def get_pixel_size_um_strict(ome_xml, omeMeta, reader, gMeta):
    try:
        ome_xml = ensure_unicode(ome_xml)
    except:
        ome_xml = ome_xml
    try:
        if ome_xml:
            px_raw, unit = _parse_pixels_physicalsize_from_xml(ome_xml)
            if px_raw is not None:
                px_um = _unit_to_um(px_raw, unit)
                log(u"Pixel size from OME-XML <Pixels>: {} {}".format(px_um, MICRO))
                return float(px_um)
    except Exception as e:
        logv(u"OME-XML pixel parse error (fallback): {}".format(e))
    try:
        if omeMeta is not None:
            q = omeMeta.getPixelsPhysicalSizeX(0)
            if q is not None and q.value() is not None:
                v = float(q.value().doubleValue())
                if abs(v) < 1e-3:
                    v_um = v * 1e6
                    log(u"Pixel size from OME metadata (meters->µm): {} {}".format(v_um, MICRO))
                    return float(v_um)
                else:
                    log(u"Pixel size from OME metadata (assumed µm): {} {}".format(v, MICRO))
                    return float(v)
    except:
        pass
    try:
        if reader is not None:
            md = reader.getMetadataStore()
            mdxml = None
            try:
                mdxml = md.dumpXML()
            except:
                try:
                    mdxml = md.toString()
                except:
                    mdxml = None
            if mdxml:
                mdxml = ensure_unicode(mdxml)
                m = re.search(r'PhysicalSizeX\s*=\s*"([^"]+)"', mdxml, re.IGNORECASE)
                if m:
                    val = float(m.group(1))
                    um = re.search(r'PhysicalSizeXUnit\s*=\s*"([^"]+)"', mdxml, re.IGNORECASE)
                    unitm = um.group(1) if um else ""
                    px_um = _unit_to_um(val, unitm)
                    log(u"Pixel size from reader metadata store: {} {}".format(px_um, MICRO))
                    return float(px_um)
    except:
        pass
    cam_min, cam_med = _pixel_from_global_metadata(gMeta)
    if cam_med is not None:
        log(u"Pixel size candidate (median) from global metadata: {} {}".format(cam_med, MICRO))
        if cam_min is not None and abs(cam_min - cam_med) > 1e-6:
            logv(u"Pixel size candidate (min) from global metadata: {} {}".format(cam_min, MICRO))
        return float(cam_med)
    log(u"Pixel size not found; defaulting to 0.345 {}".format(MICRO))
    return 0.345

def _parse_stage_labels_list_from_xml(ome_xml):
    labs = _parse_stagelabels_from_xml(ome_xml)
    out = []
    for L in labs:
        out.append((L.get('name', ''), L.get('x', None), L.get('y', None), L.get('xunit',''), L.get('yunit','')))
    return out

def try_ome_stage_labels_from_xml(xml, reader, series_index):
    if not xml: return None
    xml = ensure_unicode(xml)
    labels = _parse_stagelabels_from_xml(xml)
    if not labels: return None
    idx = series_index + 1
    for lab in labels:
        nm = lab.get('name', '') or ""
        if ("#{}".format(idx) in nm) or (re.search(r'\b{}$'.format(idx), nm)):
            return lab.get('x'), lab.get('y'), "StageLabel-Name-match"
    try:
        s_count = reader.getSeriesCount()
    except:
        s_count = None
    if s_count and len(labels) == s_count:
        lab = labels[series_index]
        return lab.get('x'), lab.get('y'), "StageLabel-order-map"
    if len(labels) > 0 and series_index < len(labels):
        lab = labels[series_index]
        return lab.get('x'), lab.get('y'), "StageLabel-best-effort-index"
    return None

def parse_channel_colors_from_ome_xml(ome_xml):
    """Parse channel colors from OME-XML.
    
    Only extracts colors from the first <Image> element to avoid
    duplicates when multiple images/series are present.
    Colors are validated and corrected by fix_zeiss_channel_colors() function.
    """
    colors = []
    if not ome_xml:
        return colors
    xml = ensure_unicode(ome_xml)
    
    # Find the first <Image> element
    image_match = re.search(r'<(?:[A-Za-z0-9_]+:)?Image\b[^>]*>(.*?)</(?:[A-Za-z0-9_]+:)?Image>', xml, re.IGNORECASE | re.DOTALL)
    if image_match:
        # Only search for channels within the first image
        image_content = image_match.group(1)
        for m in _CHANNEL_COLOR_RE.finditer(image_content):
            attrs = dict(ATTR_RE.findall(m.group(1)))
            c = attrs.get('Color') or attrs.get('color')
            if c:
                try: colors.append(int(c))
                except (ValueError, TypeError):
                    try: colors.append(int(c,0))
                    except (ValueError, TypeError): pass
    else:
        # Fallback: search all Channel tags if no Image tag found
        for m in _CHANNEL_COLOR_RE.finditer(xml):
            attrs = dict(ATTR_RE.findall(m.group(1)))
            c = attrs.get('Color') or attrs.get('color')
            if c:
                try: colors.append(int(c))
                except (ValueError, TypeError):
                    try: colors.append(int(c,0))
                    except (ValueError, TypeError): pass
    
    # Return colors from metadata as-is
    return colors

def extract_channel_colors_from_gmeta(gMeta):
    """Extract channel colors from global metadata.
    
    Looks for keys containing 'channel' and 'color' or similar patterns
    that indicate color information per channel.
    """
    colors = []
    if not gMeta:
        return colors
    
    # Try to find channel color information in global metadata
    color_map = {}
    try:
        for k in gMeta.keySet():
            try:
                keystr = safe_unicode(k)
                val = safe_unicode(gMeta.get(k))
            except (AttributeError, TypeError):
                continue
            
            lkey = keystr.lower()
            
            # Look for keys that contain channel and color information
            # e.g., "Channel 0 Color", "ChannelColor0", "DisplaySetting|Channels|Channel 0|Color"
            if ('channel' in lkey or 'ch' in lkey) and 'color' in lkey:
                # Try to extract channel index
                match = re.search(r'(\d+)', keystr)
                if match:
                    ch_idx = int(match.group(1))
                    # Try to parse the color value
                    try:
                        # Could be hex string or integer
                        if val.startswith('#'):
                            color_int = int(val[1:], 16)
                        elif val.startswith('0x'):
                            color_int = int(val, 16)
                        else:
                            color_int = int(val)
                        color_map[ch_idx] = color_int
                    except (ValueError, TypeError, AttributeError):
                        pass
    except Exception as e:
        logv(u"extract_channel_colors_from_gmeta error: {}".format(e))
    
    # Convert to ordered list
    if color_map:
        max_idx = max(color_map.keys())
        for i in range(max_idx + 1):
            if i in color_map:
                colors.append(color_map[i])
    
    return colors

def get_full_res_series_indices(reader):
    try:
        counts = []
        total = reader.getSeriesCount()
        for s in range(total):
            sx, sy = None, None
            try:
                sx = int(reader.getSizeX(s))
                sy = int(reader.getSizeY(s))
            except:
                try:
                    md = reader.getMetadataStore()
                    sx = int(md.getPixelsSizeX(s).getValue().doubleValue())
                    sy = int(md.getPixelsSizeY(s).getValue().doubleValue())
                except:
                    sx, sy = 0, 0
            counts.append((s, sx, sy))
        if not counts:
            return []
        max_area = max([x*y for (_, x, y) in counts])
        full = [s for (s, x, y) in counts if x*y == max_area]
        full.sort()
        return full
    except Exception as e:
        log(u"get_full_res_series_indices failed: {}".format(e))
        try:
            return list(range(reader.getSeriesCount()))
        except:
            return []

class TileWorker(Callable):
    def __init__(self, czi_path, series_index, x, y, out_dir, rb_radius):
        self.czi_path = czi_path
        self.i = int(series_index)
        self.x = float(x)
        self.y = float(y)
        self.out_dir = out_dir
        self.rb_radius = int(rb_radius)
    def call(self):
        try:
            opts = ImporterOptions()
            opts.setId(self.czi_path); opts.setSeriesOn(self.i, True); opts.setGroupFiles(False)
            opts.setQuiet(True); opts.setWindowless(True)
            ims = BF.openImagePlus(opts)
            imp = ims[0]
            if self.rb_radius > 0:
                try:
                    IJ.run(imp, "Subtract Background...", "radius=" + str(self.rb_radius) + " stack")
                except Exception as e:
                    logv(u"Background subtraction failed for series {}: {}".format(self.i, e))
            nr = u"S{:03d}_3D.tif".format(self.i); IJ.saveAs(imp, "Tiff", os.path.join(self.out_dir, nr))
            zp = ZProjector(imp); zp.setMethod(ZProjector.MAX_METHOD); zp.doProjection()
            mip = zp.getProjection(); nm = u"S{:03d}_MIP.tif".format(self.i)
            try:
                if mip.getNChannels() > 1:
                    mip.setC(1); t_mip = ImagePlus("MIP", mip.getProcessor())
                    IJ.saveAs(t_mip, "Tiff", os.path.join(self.out_dir, nm)); t_mip.close()
                else:
                    IJ.saveAs(mip, "Tiff", os.path.join(self.out_dir, nm))
            except Exception as e:
                logv(u"Saving MIP failed for series {}: {}".format(self.i, e))
            d = imp.getDimensions(); 
            try: imp.close()
            except: pass
            try: mip.close()
            except: pass
            return (nm, nr, self.x, self.y, d)
        except Exception as e:
            log(u"TileWorker series {} failed: {}".format(self.i, e))
            return None

def _hex_to_rgb(hexstr):
    if not hexstr:
        return None
    s = hexstr.strip()
    if s.startswith('#'):
        s = s[1:]
    if len(s) == 6:
        r = int(s[0:2], 16); g = int(s[2:4], 16); b = int(s[4:6], 16)
    elif len(s) == 8:
        r = int(s[2:4], 16); g = int(s[4:6], 16); b = int(s[6:8], 16)
    else:
        try:
            r = int(s[-6:-4], 16); g = int(s[-4:-2], 16); b = int(s[-2:], 16)
        except:
            return None
    return (r, g, b)

def build_lut_from_rgb(rgb):
    if rgb is None: return None
    R, G, B = rgb
    r_arr = [int(round((i/255.0)*R)) for i in range(256)]
    g_arr = [int(round((i/255.0)*G)) for i in range(256)]
    b_arr = [int(round((i/255.0)*B)) for i in range(256)]
    def to_signed_byte_list(lst):
        out = []
        for v in lst:
            out.append(v-256 if v>127 else v)
        return out
    rb = jarray.array(to_signed_byte_list(r_arr), 'b')
    gb = jarray.array(to_signed_byte_list(g_arr), 'b')
    bb = jarray.array(to_signed_byte_list(b_arr), 'b')
    try:
        return LUT(rb, gb, bb)
    except:
        return None

def get_standard_microscopy_colors(num_channels):
    """Get standard microscopy LUT colors.
    
    Common immunofluorescence color assignment based on typical emission wavelengths:
    - Channel 1: Cyan/Blue (typical DAPI/Hoechst ~460nm emission)
    - Channel 2: Green (typical Alexa488/FITC ~520nm emission)
    - Channel 3: Red/Orange (typical Cy3/TRITC ~570nm emission)
    - Channel 4: Far-red (typical Alexa647/Cy5 ~670nm emission)
    
    Note: These are suggested defaults. Actual channel assignment depends on
    your microscope setup and fluorophore choices.
    
    Args:
        num_channels: Number of channels needed
        
    Returns:
        List of standard color integers in RGBA format
    """
    standard_colors = [
        0x0000FFFF,  # Cyan for Ch1 (typical DAPI/Hoechst)
        0x0000FF00,  # Green for Ch2 (typical Alexa488/FITC)
        0x00FF6600,  # Orange for Ch3 (typical Cy3/TRITC)
        0x00FF00FF,  # Far-red/Magenta for Ch4 (typical Alexa647/Cy5 - displayed as magenta for visibility)
    ]
    return standard_colors[:num_channels]

def apply_channel_luts_to_image(imp, ome_xml, gMeta, use_standard_colors=False):
    """Apply channel LUTs to an image.
    
    Args:
        imp: ImagePlus to apply LUTs to
        ome_xml: OME-XML metadata string
        gMeta: Global metadata dictionary
        use_standard_colors: If True, override metadata colors with standard microscopy LUTs
    
    Returns:
        ImagePlus with LUTs applied
    """
    if imp is None:
        return imp
    
    num_channels = imp.getNChannels() if imp else 0
    
    # Get colors based on user preference
    if use_standard_colors:
        colors = get_standard_microscopy_colors(num_channels)
        if LUT_DEBUG:
            log(u"LUT Debug: Using standard microscopy LUTs (user override)")
    else:
        colors_ome = parse_channel_colors_from_ome_xml(ome_xml)
        colors_gm = extract_channel_colors_from_gmeta(gMeta)
        colors = []
        # prefer OME if present, else gMeta
        if colors_ome:
            colors = colors_ome
        elif colors_gm:
            colors = colors_gm
        
        # If no colors from metadata, use standard as fallback
        if not colors or len(colors) == 0:
            colors = get_standard_microscopy_colors(num_channels)
            if LUT_DEBUG:
                log(u"LUT Debug: No metadata colors found, using standard microscopy LUTs")
        else:
            if LUT_DEBUG:
                log(u"LUT Debug: OME colors={}, GM colors={}, using metadata colors".format(colors_ome, colors_gm))
    
    # build luts
    luts = []
    if colors and isinstance(colors[0], int):
        for ci in colors:
            u = int(ci) & 0xFFFFFFFF
            hex8 = "%08X" % u
            # Zeiss uses RGBA format: RR GG BB AA
            # Extract RGB components (alpha channel not used for LUT creation)
            # Zeiss CZI uses RGBA format, ImageJ interprets colors as BGR
            # So we swap R and B when passing to ImageJ
            r = int(hex8[0:2],16)
            g = int(hex8[2:4],16)
            b = int(hex8[4:6],16)
            rgb = (b, g, r)  # Swap to BGR for ImageJ's color interpretation
            lut = build_lut_from_rgb(rgb)
            if lut: luts.append(lut)
    else:
        for c in colors:
            lut = build_lut_from_rgb(_hex_to_rgb(c))
            if lut: luts.append(lut)
    if LUT_DEBUG:
        log(u"LUT Debug: built {} LUTs".format(len(luts)))
    if not luts:
        return imp
    try:
        if imp.getStackSize() > 1 and imp.getNChannels() > 1:
            try:
                cimp = CompositeImage(imp)
                nchan = cimp.getNChannels()
                if LUT_DEBUG:
                    log(u"LUT Debug: Applying LUTs to {} channels".format(nchan))
                for i in range(min(nchan, len(luts))):
                    try:
                        cimp.setChannelLut(luts[i], i+1)
                        if LUT_DEBUG:
                            log(u"LUT Debug: Applied LUT {} to channel {}".format(i, i+1))
                    except Exception as e:
                        if LUT_DEBUG:
                            log(u"LUT Debug: setChannelLut failed for ch{}: {}".format(i+1, e))
                        try:
                            cimp.setLut(luts[i], i+1)
                        except:
                            pass
                cimp.setDisplayMode(IJ.COMPOSITE)
                cimp.updateAndDraw()
                if LUT_DEBUG:
                    log(u"LUT Debug: CompositeImage created successfully")
                return cimp
            except Exception as e:
                if LUT_DEBUG:
                    log(u"LUT Debug: CompositeImage creation failed: {}".format(e))
                # Fall through to return original imp
        else:
            try:
                imp.getProcessor().setColorModel(luts[0].getColorModel())
                imp.updateAndDraw()
            except:
                pass
    except Exception as e:
        if LUT_DEBUG: log(u"LUT Debug: apply failed: {}".format(e))
    return imp

def estimate_tiff_size(imp):
    """Estimate the size of a TIFF file in bytes."""
    if imp is None:
        return 0
    try:
        width = imp.getWidth()
        height = imp.getHeight()
        channels = imp.getNChannels()
        slices = imp.getNSlices()
        frames = imp.getNFrames()
        bit_depth = imp.getBitDepth()
        
        # Calculate bytes per pixel
        if bit_depth == 8:
            bytes_per_pixel = 1
        elif bit_depth == 16:
            bytes_per_pixel = 2
        elif bit_depth == 24:
            bytes_per_pixel = 3
        elif bit_depth == 32:
            bytes_per_pixel = 4
        else:
            bytes_per_pixel = 2  # default
        
        # Calculate total size with overhead (metadata, tags, etc.)
        pixel_data = width * height * channels * slices * frames * bytes_per_pixel
        overhead = pixel_data * 0.05  # 5% overhead for metadata
        
        return int(pixel_data + overhead)
    except:
        return 0

def needs_bigtiff(imp):
    """Check if image needs BigTIFF format."""
    size = estimate_tiff_size(imp)
    return size > BIGTIFF_THRESHOLD

def suggest_stitcher_thresholds(tile_width_px, tile_height_px, avg_disp_px):
    ox = max(0.0, 1.0 - (avg_disp_px / float(tile_width_px)))
    oy = max(0.0, 1.0 - (avg_disp_px / float(tile_height_px)))
    avg_overlap = (ox + oy) / 2.0
    if avg_overlap >= 0.6: reg = 0.3
    elif avg_overlap >= 0.4: reg = 0.25
    elif avg_overlap >= 0.2: reg = 0.18
    else: reg = 0.12
    max_disp = max(tile_width_px, tile_height_px) * 0.5
    return {'avg_overlap': avg_overlap, 'suggested_regression_threshold': reg, 'suggested_max_disp_px': max_disp}

def create_zprojection(imp, method_name):
    """Create a z-projection of an image using the specified method.
    
    Args:
        imp: ImagePlus to project
        method_name: Name of projection method (e.g., "Max Intensity")
    
    Returns:
        ImagePlus with z-projection or None if failed
    """
    if imp is None:
        return None
    
    try:
        method = ZPROJ_METHODS.get(method_name, ZProjector.MAX_METHOD)
        zp = ZProjector(imp)
        zp.setMethod(method)
        zp.doProjection()
        proj = zp.getProjection()
        
        # Preserve title
        if proj:
            proj.setTitle(imp.getTitle() + "_" + method_name.replace(" ", "_"))
        
        return proj
    except Exception as e:
        logv(u"Z-projection failed: {}".format(e))
        return None

def choose_temp_root(dst_dir, files):
    try:
        ram = File("R:\\")
        if ram.exists() and ram.isDirectory():
            total = ram.getTotalSpace()
            free = ram.getUsableSpace()
            need = 0
            for fp in files:
                try: need += os.path.getsize(fp)
                except: pass
            need *= 2
            if total < 256*(1024**3) and free >= need:
                ram_path = os.path.join("R:\\", "ixy_tmp")
                try:
                    if not os.path.exists(ram_path):
                        os.makedirs(ram_path)
                    log(u"Using RAM drive R: for temp (need {:.1f} GB, free {:.1f} GB)".format(need/1e9, free/1e9))
                    return ram_path
                except Exception as e:
                    logv(u"RAM drive create failed: {}".format(e))
    except Exception as e:
        logv(u"RAM drive check failed: {}".format(e))
    return dst_dir

def play_clear_jingle():
    try:
        from javax.sound.midi import MidiSystem
        syn = MidiSystem.getSynthesizer()
        syn.open()
        ch = syn.getChannels()[0]
        ch.programChange(11)
        noten = [64, 68, 72]
        laut = [100, 80, 60]
        for n, v in zip(noten, laut):
            ch.noteOn(n, v); ch.noteOn(n-20, max(0,v-10)); ch.noteOn(n+10, max(0,v-10))
            time.sleep(0.2)
        time.sleep(4.0)
        for n in noten:
            ch.noteOff(n)
        syn.close()
    except Exception as e:
        logv(u"MIDI jingle failed: {}".format(e))

_config = _load_config()
_home = os.path.expanduser("~")
_last_in = _config.get("last_input_dir", "") or _home
_last_out = _config.get("last_output_dir", "") or _home
if not os.path.isdir(_last_in): _last_in = _home
if not os.path.isdir(_last_out): _last_out = _home

def pick_directory_with_jfilechooser(title, default_path):
    try:
        from javax.swing import JFileChooser
        jc = JFileChooser()
        try:
            jc.setCurrentDirectory(File(default_path if default_path and os.path.isdir(default_path) else _home))
        except:
            pass
        jc.setFileSelectionMode(JFileChooser.DIRECTORIES_ONLY)
        jc.setDialogTitle(title)
        res = jc.showOpenDialog(None)
        from javax.swing import JFileChooser as _JC
        if res == _JC.APPROVE_OPTION:
            sel = jc.getSelectedFile()
            return u"{}".format(sel.getAbsolutePath())
    except Exception as e:
        logv(u"JFileChooser failed: {}".format(e))
        return default_path
    return None

def compute_threads():
    max_cores = int(Runtime.getRuntime().availableProcessors())
    if max_cores < 10:
        return max_cores
    return max_cores - 1

# Parameter dialog (threads fixed, others editable)
if "input_dir_raw" in globals():
    try:
        fusion_method = globals().get("fusion_method", "Linear Blending")
        thread_count_slider = compute_threads()
        rb_radius = int(globals().get("rb_radius", 50))
        reg_thresh = float(globals().get("reg_thresh", 0.30))
        disp_thresh = float(globals().get("disp_thresh", 5.0))
        do_show = bool(globals().get("do_show", True))
        do_save = bool(globals().get("do_save", True))
        save_bigtiff = bool(globals().get("save_bigtiff", False))
        do_clean = bool(globals().get("do_clean", True))
        auto_adjust = bool(globals().get("auto_adjust_thresholds", True))
        corr_factor = float(globals().get("corr_factor", 10.0))
        # New z-projection options
        save_3d = bool(globals().get("save_3d", True))
        save_zprojection = bool(globals().get("save_zprojection", False))
        view_zprojection = bool(globals().get("view_zprojection", False))
        zprojection_method = globals().get("zprojection_method", "Max Intensity")
        use_standard_luts = bool(globals().get("use_standard_luts", False))
        try:
            _last_in = get_safe_path(input_dir_raw) or _last_in
            _last_out = get_safe_path(output_dir_raw) or _last_out
            _config["last_input_dir"] = _last_in
            _config["last_output_dir"] = _last_out
            _save_config(_config)
        except:
            pass
    except Exception:
        pass
def show_help_dialog():
    """Display comprehensive help for all parameters."""
    from ij.gui import GenericDialog
    help_text = """
SPECIALISED CZI STITCHER - HELP

=== FOLDER PATHS ===
Input: Source folder containing .czi files
Processing: Temporary folder for intermediate files (auto-created)
Output: Destination folder for stitched results

Tip: Leave paths blank to use input folder for all. First path filled auto-populates others.

=== STITCHED VOLUME OPTIONS ===
Show: Display stitched result in Fiji after processing
Save: Write stitched volume to disk as TIFF

=== Z-PROJECTION OPTIONS ===
Show: Display z-projection in Fiji after processing
Save: Write z-projection to disk as TIFF
Method: How to collapse z-stack into 2D image:
  - Max Intensity: Brightest pixel across z (best for sparse signals)
  - Average: Mean intensity (reduces noise)
  - Min Intensity: Darkest pixel (rarely used)
  - Sum: Total intensity (for quantification)
  - Std Dev: Variation across z (shows z-structure)
  - Median: Middle value (robust to outliers)

=== SHARP-SLICE DETECTION (Advanced) ===
PURPOSE: Automatically find in-focus z-range to improve projection quality
For tilted samples or non-uniform focus across the field of view.

Enable: Turn on automatic detection of sharp (in-focus) slices

Detection Modes:
  GLOBAL MODE (uniform samples):
    - Analyzes entire image as one region
    - Faster processing
    - Best when: sample is flat/coplanar, uniform focus across field
    - Finds single z-range where whole image is sharp
  
  ROI-BASED MODE (tilted/non-coplanar samples):
    - Divides image into n×n grid of regions (e.g., 3×3 = 9 regions)
    - Each region analyzed independently across ALL z-slices
    - Finds which z-slices have ANY part of image in focus
    - All regions' z-ranges merged to capture all in-focus areas
    - Slower but handles tilted samples, bubbles, uneven mounting
    - NOTE: This is NOT spreading-fire optimization (planned future feature)
    
    Example: If top-left corner sharp at z5-8 and bottom-right sharp 
    at z12-15, merged range is z5-15 (includes both focused regions)
    
    IMPORTANT: Final output includes ENTIRE x-y plane (whole slices)
    for all z-slices in merged range. We don't crop to ROI boundaries.
    This is z-slice selection, NOT spatial focus stacking/EDF.

Threshold: Sensitivity (0.0-1.0)
  RECOMMENDED VALUES:
    - 0.3 = standard (good starting point for most samples)
    - 0.2-0.4 = typical range
    - Lower (0.1-0.2) = more slices included (less strict, noisier samples)
    - Higher (0.5-0.7) = fewer slices (more strict, high SNR samples)
  
  Thresholds are NOT directly comparable between methods!
  Each method has different score ranges and distributions.

Detection Methods:
  - Laplacian Variance: Standard approach, robust (RECOMMENDED, start here)
  - Tenengrad Gradient: Edge-based, good for high contrast structures
  - Normalized Variance: Simple intensity variance, fast but sensitive to noise
  
  Method choice matters less than threshold tuning for your sample type.

ROI Grid Size: For ROI mode only (n×n grid)
  - 3×3 = 9 regions (RECOMMENDED for most non-coplanar samples)
  - 5×5 = 25 regions (more detail, longer processing)
  - 10×10 = 100 regions (WARNING: Very slow! Only for extreme tilt)
  - Larger grid = finer spatial resolution but slower processing

How Detection Works (Current Implementation):
  1. Each region analyzes ALL z-slices for sharpness
  2. Computes sharpness score per slice per region
  3. Threshold applied: keep slices above threshold
  4. Within-slice gap filling: bridges gaps of 1-2 slices
     (handles temporary focus flicker or noise)
  5. [ROI mode only] Cross-ROI merging: combines ranges from all regions,
     merging overlapping/nearby ranges (gap ≤2 slices)
  6. Largest continuous merged range selected as output z-range
  7. ENTIRE x-y planes for that z-range included in final volume
  
  Future optimization (not yet implemented): 
  "Spreading-fire" search to reduce number of sharpness calculations
  by propagating from known-sharp slices to neighbors.

NOTE: Sharp-slice detection outputs complete z-slices (whole x-y planes).
This is NOT Extended Depth of Field (EDF) or spatial focus stacking,
which creates a single 2D composite from the sharpest pixels at each x,y.
  8. Filename includes range: file_stitched_z6-16_max_projection.tif

===  COLOR OPTIONS ===
Standard LUTs: Override CZI metadata with common immunofluorescence colors:
  - Channel 1: Cyan/Blue (typical DAPI/Hoechst ~460nm)
  - Channel 2: Green (typical Alexa488/FITC ~520nm)
  - Channel 3: Red/Orange (typical Cy3/TRITC ~570nm)
  - Channel 4: Far-red displayed as Magenta (typical Alexa647/Cy5 ~670nm)
  
  Note: Far-red emissions are displayed as magenta for visibility since
  true far-red is outside visible spectrum. This is display convention only.

Default (unchecked): Respects colors from CZI metadata

=== ADVANCED OPTIONS ===
Fusion Method: How tiles are blended
  - Linear Blending: Smooth transitions (recommended)
  - Max Intensity: Brightest wins (harsh edges)
  - Average/Median: Mathematical blending

Rolling Ball Radius: Background subtraction (0 = disable)
  - 50 recommended for most fluorescence images
  - Smaller values (20-30) = preserve more fine detail, less background removal
  - Larger values (100-200) = more aggressive background removal, may affect dim signals
  - Radius should be larger than largest object of interest

Regression/Displacement Thresholds: Stitching accuracy controls
  - Default values work for most cases

Cleanup Temp Files: Remove intermediate files after processing

Auto-adjust: Use metadata to optimize stitching thresholds

Pixel Size Correction: Scale factor for metadata pixel size

Debug Mode: Enable verbose logging for troubleshooting

=== FILE SIZES & BIGTIFF ===
BigTIFF automatically enabled for files >2GB
No manual selection needed!

=== PERFORMANCE ===
- Largest file processed first (fail-fast)
- Memory freed after each file
- Multi-threaded stitching uses (CPU cores - 1)
    """
    
    help_gd = GenericDialog("Help - Specialised CZI Stitcher")
    help_gd.addMessage(help_text)
    help_gd.showDialog()

else:
    # Show initialization message
    IJ.showStatus("Specialised CZI Stitcher - Initializing, please wait...")
    IJ.log("\\Clear")
    IJ.log("[Specialised CZI Stitcher] Initializing...")
    IJ.log("[Specialised CZI Stitcher] Loading Bio-Formats and stitching plugins...")
    
    # Load config for last used paths
    _config = _load_config()
    _last_in = _config.get("last_input_dir", os.path.expanduser("~"))
    _last_out = _config.get("last_output_dir", os.path.expanduser("~"))
    
    # Create dialog with integrated path selection
    gd = GenericDialog("Specialised CZI Stitcher - Parameters")
    gd.addMessage("=== FOLDER PATHS ===")
    gd.addStringField("Input Folder (CZI files):", _last_in, 60)
    gd.addStringField("Processing Folder (temp files):", _last_in, 60)
    gd.addStringField("Output Folder (results):", _last_out, 60)
    gd.addMessage("Tip: Leave processing folder same as input unless you need separation")
    gd.addMessage("")
    gd.addMessage("=== STITCHING PARAMETERS ===")
    gd.addChoice("Fusion Method", ["Linear Blending", "Max. Intensity", "Average", "Median"], "Linear Blending")
    gd.addNumericField("Rolling Ball Radius (0 = Off)", 50, 0)
    gd.addNumericField("Regression Threshold", 0.30, 2)
    gd.addNumericField("Max Displacement (px)", 5.0, 1)
    gd.addMessage("")
    gd.addMessage("=== STITCHED VOLUME OPTIONS ===")
    gd.addCheckbox("Show Stitched Volume", True)
    gd.addCheckbox("Save Stitched Volume", True)
    gd.addMessage("")
    gd.addMessage("=== Z-PROJECTION OPTIONS ===")
    gd.addCheckbox("Show Z-Projection", False)
    gd.addCheckbox("Save Z-Projection", False)
    gd.addChoice("Z-Projection Method", list(ZPROJ_METHODS.keys()), "Max Intensity")
    gd.addMessage("")
    gd.addMessage("=== SHARP-SLICE DETECTION (Advanced) ===")
    gd.addCheckbox("Enable Sharp-Slice Detection", False)
    gd.addChoice("Detection Mode", ["Global", "ROI-based"], "Global")
    gd.addNumericField("Sharpness Threshold (0.0-1.0)", 0.3, 2)
    gd.addChoice("Detection Method", list(SHARPNESS_METHODS.keys()), "Laplacian Variance")
    gd.addNumericField("ROI Grid Size (n x n, if ROI mode)", 3, 0)
    gd.addMessage("")
    gd.addMessage("=== COLOR OPTIONS ===")
    gd.addCheckbox("Use Standard Microscopy LUTs (override metadata)", False)
    gd.addMessage("")
    gd.addMessage("=== ADVANCED OPTIONS ===")
    gd.addCheckbox("Cleanup Temp Files", True)
    gd.addCheckbox("Auto-adjust stitching thresholds from metadata", True)
    gd.addNumericField("Pixel size correction factor (default 10)", 10.0, 1)
    gd.addCheckbox("Debug Mode (verbose logging)", False)
    gd.addMessage("")
    gd.addMessage("Need help? Press 'H' key or see documentation for detailed explanations.")
    # Note: Fiji's GenericDialog doesn't support custom help dialogs well
    # Help text is comprehensive in the dialog itself via section headers
    gd.showDialog()
    if gd.wasCanceled():
        log("User cancelled parameter dialog. Exiting."); raise SystemExit("Cancelled by user")
    
    # Get path fields
    in_path = gd.getNextString()
    processing_path = gd.getNextString()
    out_path = gd.getNextString()
    
    # Validate paths
    if not in_path or not os.path.exists(in_path):
        log("Invalid input path. Exiting."); raise SystemExit("Invalid input path")
    if not out_path:
        log("Invalid output path. Exiting."); raise SystemExit("Invalid output path")
    
    # Create output directory if it doesn't exist
    if not os.path.exists(out_path):
        try:
            os.makedirs(out_path)
        except:
            log("Failed to create output directory. Exiting."); raise SystemExit("Cannot create output directory")
    
    # Save paths to config
    _config["last_input_dir"] = in_path
    _config["last_output_dir"] = out_path
    _save_config(_config)
    
    input_dir_raw = File(unicode(in_path))
    output_dir_raw = File(unicode(out_path))
    temp_root = processing_path if processing_path and os.path.exists(os.path.dirname(processing_path)) else in_path
    
    # Get other parameters
    fusion_method = gd.getNextChoice()
    rb_radius = int(gd.getNextNumber())
    reg_thresh = float(gd.getNextNumber())
    disp_thresh = float(gd.getNextNumber())
    do_show = bool(gd.getNextBoolean())
    do_save = bool(gd.getNextBoolean())
    view_zprojection = bool(gd.getNextBoolean())
    save_zprojection = bool(gd.getNextBoolean())
    zprojection_method = gd.getNextChoice()
    enable_sharp_detection = bool(gd.getNextBoolean())
    sharp_detection_mode = gd.getNextChoice()
    sharp_threshold = float(gd.getNextNumber())
    sharp_method_name = gd.getNextChoice()
    sharp_method = SHARPNESS_METHODS.get(sharp_method_name, "laplacian")
    roi_grid_size = int(gd.getNextNumber())
    use_standard_luts = bool(gd.getNextBoolean())
    do_clean = bool(gd.getNextBoolean())
    auto_adjust = bool(gd.getNextBoolean())
    try:
        corr_factor = float(gd.getNextNumber())
    except:
        corr_factor = 10.0
    DEBUG_MODE = bool(gd.getNextBoolean())
    
    # BigTIFF is now automatic based on file size
    save_bigtiff = False
    # Backward compatibility - save_3d is now do_save
    save_3d = do_save
    thread_count_slider = compute_threads()

def get_original_omexml_str_and_reader(czi_path):
    try:
        opts = ImporterOptions()
        opts.setId(czi_path); opts.setQuiet(True); opts.setGroupFiles(False)
        proc = ImportProcess(opts)
        proc.execute()
        try:
            xml = proc.getOMEXML()
        except:
            try:
                omeMeta = proc.getOMEMetadata()
                xml = omeMeta.dumpXML() if omeMeta is not None else None
            except:
                xml = None
        omeMeta = proc.getOMEMetadata()
        reader = proc.getReader()
        try:
            gMeta = reader.getGlobalMetadata()
        except:
            gMeta = {}
        if xml is not None:
            xml = ensure_unicode(xml)
        return xml, proc, omeMeta, reader, gMeta
    except Exception as e:
        log(u"get_original_omexml_str_and_reader failed: {}".format(e))
        return None, None, None, None, None

class UltimateStitcher:
    def __init__(self, src, dst, t_limit, temp_root):
        self.src, self.dst, self.t_limit, self.temp_root = src, dst, t_limit, temp_root

    def process_file(self, czi_path):
        base_name = os.path.splitext(os.path.basename(czi_path))[0]
        file_dst = os.path.join(self.temp_root, u"temp_{}".format(int(time.time())))
        if not os.path.exists(file_dst): os.makedirs(file_dst)
        log(u"--- Meta Scan: {} ---".format(base_name))

        ome_xml, proc, omeMeta, reader, gMeta = get_original_omexml_str_and_reader(czi_path)

        if reader is None:
            log(u"No reader available for {}; skipping.".format(base_name))
            if proc:
                try: proc.close()
                except: pass
            if do_clean:
                try: shutil.rmtree(file_dst)
                except: pass
            return False

        px_um = get_pixel_size_um_strict(ome_xml, omeMeta, reader, gMeta)
        try:
            cf = float(corr_factor)
        except:
            cf = 10.0
        px_um_eff = px_um / cf if cf != 1.0 else px_um
        if cf != 1.0:
            log(u"px = {} {}, corr_factor {}, effective = {} {}".format(px_um, MICRO, cf, px_um_eff, MICRO))
        else:
            log(u"px = {} {}".format(px_um_eff, MICRO))

        try:
            full_res_indices = get_full_res_series_indices(reader)
        except Exception as e:
            logv(u"Failed to determine full-res series: {}".format(e)); full_res_indices = list(range(reader.getSeriesCount() or 0))

        stage_labels = _parse_stage_labels_list_from_xml(ome_xml)
        series_to_label = {}
        if stage_labels and len(stage_labels) == len(full_res_indices):
            for idx, s in enumerate(full_res_indices):
                name, x_um, y_um, xu, yu = stage_labels[idx]
                series_to_label[s] = (x_um, y_um, "StageLabel-order-map")
        else:
            for s in full_res_indices:
                sl = None
                try:
                    sl = try_ome_stage_labels_from_xml(ome_xml, reader, s)
                except:
                    sl = None
                if sl:
                    series_to_label[s] = (sl[0], sl[1], sl[2])
                else:
                    series_to_label[s] = (None, None, None)

        tiles = []; fx=[]; fy=[]
        for s in full_res_indices:
            x_s,y_s,m = series_to_label.get(s,(None,None,None))
            if x_s is None: x_s = 0.0
            if y_s is None: y_s = 0.0
            if m is None: m = "fallback-zero"
            tiles.append({'i': s, 'x_s': x_s, 'y_s': y_s, 'method': m})
            fx.append(x_s); fy.append(y_s)
            if LOG_TILE_POS:
                log(u"Series {} -> raw pos ({}, {}) via {}".format(s, x_s, y_s, m))

        min_x = min(fx) if fx else 0.0
        min_y = min(fy) if fy else 0.0
        for t in tiles:
            t['x'] = (t['x_s'] - min_x) / px_um_eff
            t['y'] = (t['y_s'] - min_y) / px_um_eff
        xs = [t['x'] for t in tiles]; ys = [t['y'] for t in tiles]
        if xs and ys:
            log(u"Tiles: {} | px-range x=[{:.1f},{:.1f}] y=[{:.1f},{:.1f}]".format(len(tiles), min(xs), max(xs), min(ys), max(ys)))

        reg_local = reg_thresh
        disp_local = disp_thresh
        if auto_adjust and len(tiles)>1:
            deltas = []
            for i in range(1, len(tiles)):
                dx = tiles[i]['x_s'] - tiles[i-1]['x_s']
                dy = tiles[i]['y_s'] - tiles[i-1]['y_s']
                deltas.append(math.hypot(dx, dy))
            if deltas:
                avg_sep_um = sum(deltas) / len(deltas)
                avg_sep_px = avg_sep_um / px_um_eff
                try:
                    sx = int(reader.getSizeX(0)); sy = int(reader.getSizeY(0))
                except:
                    sx, sy = 1216, 1028
                sug = suggest_stitcher_thresholds(sx, sy, avg_sep_px)
                reg_local = sug['suggested_regression_threshold']
                disp_local = sug['suggested_max_disp_px']
                log(u"Auto-adjust: avg_sep {:.1f}px, overlap {:.1%}, reg={}, max_disp={}".format(avg_sep_px, sug['avg_overlap'], reg_local, disp_local))

        num_threads = min(self.t_limit, Runtime.getRuntime().availableProcessors())
        exc = Executors.newFixedThreadPool(num_threads)
        futs = [exc.submit(TileWorker(czi_path, t['i'], t['x'], t['y'], file_dst, rb_radius)) for t in tiles]
        exc.shutdown()
        while not exc.isTerminated():
            Thread.sleep(200)
        res = [f.get() for f in futs if f.get() is not None]

        if not res:
            log(u"No tile outputs were produced for {}. Skipping file.".format(base_name))
            try: reader.close()
            except: pass
            if proc:
                try: proc.close()
                except: pass
            if do_clean:
                try: shutil.rmtree(file_dst)
                except: pass
            return False

        if len(res) < 2:
            log(u"Only {} tile(s) for {} — skip stitching.".format(len(res), base_name))
            try:
                for r in res:
                    mip_name, nr = r[0], r[1]
                    src_mip = os.path.join(file_dst, mip_name)
                    src_3d = os.path.join(file_dst, nr)
                    try: shutil.copy(src_mip, os.path.join(self.dst, base_name + "_" + mip_name))
                    except: pass
                    try: shutil.copy(src_3d, os.path.join(self.dst, base_name + "_" + nr))
                    except: pass
            except Exception as e:
                logv(u"Copy single-tile outputs failed: {}".format(e))
            try: reader.close()
            except: pass
            if proc:
                try: proc.close()
                except: pass
            if do_clean:
                try: shutil.rmtree(file_dst)
                except: pass
            return True

        conf = os.path.join(file_dst, u"TileConfiguration.txt")
        with codecs.open(conf, 'w', encoding='utf-8') as f:
            f.write(u"dim = 2\n")
            for r in res:
                f.write(u"{}; ; ({:.3f}, {:.3f})\n".format(r[0], r[2], r[3]))

        clean_dir = file_dst.replace(u"\\",u"/")
        try:
            IJ.run("Grid/Collection stitching", "type=[Positions from file] order=[Defined by TileConfiguration] directory=[" + clean_dir + "] layout_file=TileConfiguration.txt fusion_method=[" + fusion_method + "] regression_threshold=" + str(reg_local) + " max/avg_displacement_threshold=" + str(disp_local) + " absolute_displacement_threshold=" + str(disp_local + 1.0) + " compute_overlap subpixel_accuracy image_output=[Fuse and display]")
        except Exception as e:
            log(u"Stitching (2D) failed: {}".format(e))

        if WindowManager.getCurrentImage(): WindowManager.getCurrentImage().close()

        final_conf = os.path.join(file_dst, u"TileConfiguration_3D.txt")
        reg_conf = os.path.join(file_dst, u"TileConfiguration.registered.txt")
        mip_to_3d = {r[0]: r[1] for r in res}
        src_c = reg_conf if os.path.exists(reg_conf) else conf

        def extract_xy_from_parentheses(s):
            try:
                a = s.index('('); b = s.index(')', a+1)
                inner = s[a+1:b]; parts = [p.strip() for p in inner.split(',')]
                nums = []
                for p in parts:
                    m = FLOAT_RE.search(p)
                    if m: nums.append(m.group(0))
                    if len(nums) >= 2: break
                if len(nums) >= 2: return float(nums[0]), float(nums[1])
            except:
                pass
            return None

        with codecs.open(src_c, 'r', encoding='utf-8') as fr, codecs.open(final_conf, 'w', encoding='utf-8') as fw:
            fw.write(u"dim = 3\n")
            for line in fr:
                if ".tif" in line and "(" in line and ")" in line:
                    xy = extract_xy_from_parentheses(line)
                    if xy is None:
                        logv(u"Could not parse coordinates: {}".format(line.strip()))
                        continue
                    name = line.split(";")[0].strip()
                    name3d = mip_to_3d.get(name, name)
                    fw.write(u"{}; ; ({:.6f}, {:.6f}, 0.0)\n".format(name3d, xy[0], xy[1]))
                else:
                    if line.strip().lower().startswith("dim"):
                        continue
                    fw.write(line)

        try:
            IJ.run("Grid/Collection stitching", "type=[Positions from file] order=[Defined by TileConfiguration] directory=[" + clean_dir + "] layout_file=TileConfiguration_3D.txt fusion_method=[" + fusion_method + "] subpixel_accuracy image_output=[Fuse and display]")
        except Exception as e:
            log(u"Stitching (3D) failed: {}".format(e))

        imp = WindowManager.getCurrentImage()
        if imp is None:
            log(u"No fused image produced; skipping save for {}.".format(base_name))
            try: reader.close()
            except: pass
            if proc:
                try: proc.close()
                except: pass
            if do_clean:
                try: shutil.rmtree(file_dst)
                except Exception as e:
                    logv(u"Cleanup temp dir failed: {}".format(e))
            return False

        imp.setTitle(base_name + "_stitched")
        try:
            c_cnt, z_cnt = res[0][4][2], res[0][4][3]
            if imp.getStackSize() == (c_cnt * z_cnt):
                imp = HyperStackConverter.toHyperStack(imp, c_cnt, z_cnt, 1, "grayscale", "Composite")
        except Exception:
            pass
        try:
            imp = apply_channel_luts_to_image(imp, ome_xml, gMeta, use_standard_luts)
        except Exception as e:
            logv(u"LUT application failed: {}".format(e))
        # Note: setDisplayMode is now called inside apply_channel_luts_to_image
        if isinstance(imp, CompositeImage):
            imp.setDisplayMode(IJ.COMPOSITE)
        imp.updateAndDraw()

        if do_save:
            if imp is None or imp.getProcessor() is None:
                log(u"Skipping save: image or processor is None for {}.".format(base_name))
            else:
                # Build filename suffix with processing parameters
                filename_suffix = u"_stitched"
                if rb_radius > 0:
                    filename_suffix += u"_rb{}".format(rb_radius)
                
                # Apply sharp-slice detection if enabled
                sharp_range_str = ""
                if enable_sharp_detection and imp.getNSlices() > 1:
                    try:
                        if sharp_detection_mode == "ROI-based":
                            start_z, end_z = detect_sharp_slices_roi(imp, sharp_threshold, sharp_method, roi_grid_size)
                        else:
                            start_z, end_z = detect_sharp_slices_global(imp, sharp_threshold, sharp_method)
                        
                        # Create substack with only sharp slices
                        if start_z > 1 or end_z < imp.getNSlices():
                            log("Extracting sharp z-slices %d to %d..." % (start_z, end_z))
                            original_title = imp.getTitle()
                            IJ.run(imp, "Make Substack...", "slices=%d-%d" % (start_z, end_z))
                            # Get the newly created substack by title
                            imp_sharp = WindowManager.getImage(original_title + " Substack (%d-%d)" % (start_z, end_z))
                            if not imp_sharp:
                                # Fallback to current image if title-based retrieval fails
                                imp_sharp = WindowManager.getCurrentImage()
                            if imp_sharp and imp_sharp != imp:
                                imp.close()
                                imp = imp_sharp
                                sharp_range_str = "_z%d-%d" % (start_z, end_z)
                            else:
                                log("Warning: Could not extract substack, using full stack")
                    except Exception as e:
                        log("Sharp-slice detection failed: %s" % str(e))
                
                # Determine if BigTIFF is needed automatically
                use_bigtiff = needs_bigtiff(imp)
                if use_bigtiff:
                    log(u"File size exceeds 2GB threshold, using BigTIFF format")
                
                # Save 3D volume if requested
                if save_3d:
                    out_3d = os.path.join(self.dst, base_name + filename_suffix + sharp_range_str + u".tif")
                    try:
                        if use_bigtiff:
                            # Use Bio-Formats exporter for BigTIFF
                            IJ.run(imp, "Bio-Formats Exporter", "save=[" + out_3d + "] compression=Uncompressed")
                        else:
                            IJ.saveAs(imp, "Tiff", out_3d)
                        log(u"Saved 3D stitched: {}".format(out_3d))
                    except Exception as e:
                        log(u"Saving 3D stitched failed: {}".format(e))
                
                # Create Z-projection if save or view is requested
                if (save_zprojection or view_zprojection) and imp.getNSlices() > 1:
                    try:
                        proj_imp = create_zprojection(imp, zprojection_method)
                        if proj_imp:
                            # Apply same LUTs to projection
                            try:
                                proj_imp = apply_channel_luts_to_image(proj_imp, ome_xml, gMeta, use_standard_luts)
                                if isinstance(proj_imp, CompositeImage):
                                    proj_imp.setDisplayMode(IJ.COMPOSITE)
                            except:
                                pass
                            
                            # Build projection filename with method and sharp range
                            proj_method_short = zprojection_method.replace(" ", "").replace("Intensity", "").lower()
                            out_proj = os.path.join(self.dst, base_name + filename_suffix + sharp_range_str + u"_{}_projection.tif".format(proj_method_short))
                            
                            # Save if requested
                            if save_zprojection:
                                try:
                                    IJ.saveAs(proj_imp, "Tiff", out_proj)
                                    log(u"Saved Z-projection ({}): {}".format(zprojection_method, out_proj))
                                except Exception as e:
                                    log(u"Saving Z-projection failed: {}".format(e))
                            
                            # Show if requested
                            if view_zprojection:
                                proj_imp.setTitle(os.path.basename(out_proj))
                                proj_imp.show()
                                log(u"Displaying Z-projection ({})".format(zprojection_method))
                            elif save_zprojection:
                                # Close and flush if only saving (not viewing)
                                proj_imp.flush()
                                proj_imp.close()
                    except Exception as e:
                        log(u"Z-projection creation failed: {}".format(e))
        
        # Show or close the stitched image based on user preference
        if do_show:
            imp.show()
            log(u"Displaying stitched image")
        else:
            imp.flush()
            imp.close()
        
        # Force garbage collection after processing large files
        IJ.freeMemory()
        
        try:
            reader.close()
        except:
            pass
        if proc:
            try:
                proc.close()
            except:
                pass
        if do_clean:
            System.gc()
            Thread.sleep(1000)
            try:
                shutil.rmtree(file_dst)
            except Exception as e:
                logv(u"Cleanup temp dir failed: {}".format(e))
        
        # Log memory status
        runtime = Runtime.getRuntime()
        used_mb = (runtime.totalMemory() - runtime.freeMemory()) / 1048576.0
        max_mb = runtime.maxMemory() / 1048576.0
        log(u"Memory: {:.0f} MB used / {:.0f} MB max".format(used_mb, max_mb))
        
        return True

def main():
    IJ.log("\\Clear")
    s_dir, t_dir = get_safe_path(input_dir_raw), get_safe_path(output_dir_raw)
    files = sorted([os.path.join(s_dir, f) for f in os.listdir(s_dir) if f.lower().endswith(".czi")])
    
    # Sort files by size (largest first) for fail-fast stability testing
    try:
        files_with_size = [(f, os.path.getsize(f)) for f in files]
        files_with_size.sort(key=lambda x: x[1], reverse=True)
        files = [f for f, size in files_with_size]
        log(u"Processing order: Largest file first (fail-fast strategy)")
        for f, size in files_with_size:
            log(u"  - {} ({:.1f} MB)".format(os.path.basename(f), size / 1048576.0))
    except Exception as e:
        logv(u"File size sorting failed, using alphabetical order: {}".format(e))
    
    temp_root = choose_temp_root(t_dir, files)
    t_lim = int(compute_threads())
    try:
        log(u"Source: {} , Target: {} , Threads: {} , TempRoot: {}".format(unicode(s_dir), unicode(t_dir), t_lim, temp_root))
    except:
        log("Source: {} , Target: {} , Threads: {} , TempRoot: {}".format(s_dir, t_dir, t_lim, temp_root))
    flush_log()
    
    stitcher = UltimateStitcher(s_dir, t_dir, t_lim, temp_root)
    for f in files:
        try:
            stitcher.process_file(f)
            flush_log()  # Flush after each file
        except Exception as e:
            log(u"Processing file {} failed: {}".format(f, e))
            flush_log()
    
    log("Batch Done.")
    flush_log()
    
    if PLAY_JINGLE_ON_DONE:
        play_clear_jingle()

if __name__ in [None, "__main__"]:
    main()
